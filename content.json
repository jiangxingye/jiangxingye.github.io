{"meta":{"title":"姜兴业非官方网站","subtitle":"","description":null,"author":"姜兴业","url":"https://jiangxingye.github.io"},"pages":[{"title":"","date":"2019-08-16T03:08:23.823Z","updated":"2019-08-09T10:39:09.131Z","comments":true,"path":"index.html","permalink":"https://jiangxingye.github.io/index.html","excerpt":"","text":"layui-select-multiple /* 下拉多选样式 需要引用*/ select[multiple]+.layui-form-select>.layui-select-title>input.layui-input{ border-bottom: 0} select[multiple]+.layui-form-select dd{ padding:0;} select[multiple]+.layui-form-select .layui-form-checkbox[lay-skin=primary]{ margin:0 !important; display:block; line-height:36px !important; position:relative; padding-left:26px;} select[multiple]+.layui-form-select .layui-form-checkbox[lay-skin=primary] span{line-height:36px !important; float:none;} select[multiple]+.layui-form-select .layui-form-checkbox[lay-skin=primary] i{ position:absolute; left:10px; top:0; margin-top:9px;} .multiSelect{ line-height:normal; height:auto; padding:4px 10px; overflow:hidden;min-height:38px; margin-top:-38px; left:0; z-index:99;position:relative;background:none;} .multiSelect a{ padding:2px 5px; background:#908e8e; border-radius:2px; color:#fff; display:block; line-height:20px; height:20px; margin:2px 5px 2px 0; float:left;} .multiSelect a span{ float:left;} .multiSelect a i {float:left;display:block;margin:2px 0 0 2px;border-radius:2px;width:8px;height:8px;padding:4px;position:relative;-webkit-transition:all .3s;transition:all .3s} .multiSelect a i:before, .multiSelect a i:after {position:absolute;left:8px;top:2px;content:'';height:12px;width:1px;background-color:#fff} .multiSelect a i:before {-webkit-transform:rotate(45deg);transform:rotate(45deg)} .multiSelect a i:after {-webkit-transform:rotate(-45deg);transform:rotate(-45deg)} .multiSelect a i:hover{ background-color:#545556;} /* 下面是页面内样式，无需引用 */ .layui-block { margin-bottom: 10px; } .layui-form-label { width: 180px; } .code { color: gray; margin-left: 10px; } .unshow>#result { display: none; } pre { padding: 5px; margin: 5px; } .string { color: green; } .number { color: darkorange; } .boolean { color: blue; } .null { color: magenta; } .key { color: red; } 基础属性 属性名 属性值 备注 multiple 无 开启多选 lay-search 无 开启搜索 lay-case 无 大小写敏感 lay-omit 无 开启多选简写，显示勾选条数 单选select 单选 请选择您的兴趣爱好 sing1 sing2 SING1-大写 movie1 movie2 movie3 MOVIE4 swim moon &ltselect> 单选+搜索+大小写不敏感 请选择您的兴趣爱好 sing1 sing2 SING1-大写 movie1 movie2 movie3 MOVIE4 swim moon &ltselect lay-search> 单选+搜索+大小写敏感 请选择您的兴趣爱好 sing1 sing2 SING1-大写 movie1 movie2 movie3 MOVIE4 swim moon &ltselect lay-search lay-case> 查看表单信息 多选select 多选 请选择您的兴趣爱好 sing1 sing2 SING1-大写 movie1 movie2 movie3 MOVIE4 swim moon &ltselect multiple> 简化多选 请选择您的兴趣爱好 sing1 sing2 SING1-大写 movie1 movie2 movie3 MOVIE4 swim moon &ltselect multiple lay-omit> 多选+搜索+大小写不敏感 请选择您的兴趣爱好 sing1 sing2 SING1-大写 movie1 movie2 movie3 MOVIE4 swim moon &ltselect multiple lay-search> 简化多选+搜索+大小写敏感 请选择您的兴趣爱好 sing1 sing2 SING1-大写 movie1 movie2 movie3 MOVIE4 swim moon &ltselect multiple lay-search lay-case lay-omit> 查看表单信息 赋值 // 有两种赋值方式： 1. 直接在option中写selected。 2. 通过 js 赋值。 // 1. 直接在option中写selected 请选择您的兴趣爱好 sing1 sing2 SING1-大写 movie1 movie2 movie3 MOVIE4 swim moon // 2. 通过 js 赋值。 请选择您的兴趣爱好 sing1 sing2 SING1-大写 movie1 movie2 movie3 MOVIE4 swim moon &ltscript> // 手动赋值 $('select[name=\"简化多选+搜索+大小写敏感\"]').val(['sing1', 'movie2']); form.render(); &lt/script> layui.use(['form','code'], function () { var form = layui.form, $ = layui.$; // 代码块 layui.code({ title: 'html', encode: true, about: false }); // 手动赋值 $('select[name=\"简化多选+搜索+大小写敏感\"]').val(['sing1', 'movie2']); form.render(); // 提交事件 form.on(\"submit(*)\", function (data) { $('#result').html(syntaxHighlight(data.field)); layer.open({ type: 1, title: '提交信息', shadeClose: true, content:$('#result') }); return false; }); // json 格式化+高亮 function syntaxHighlight(json) { if (typeof json != 'string') { json = JSON.stringify(json, undefined, 2); } json = json.replace(/&/g, '&').replace(//g, '>'); return json.replace(/(\"(\\\\u[a-zA-Z0-9]{4}|\\\\[^u]|[^\\\\\"])*\"(\\s*:)?|\\b(true|false|null)\\b|-?\\d+(?:\\.\\d*)?(?:[eE][+\\-]?\\d+)?)/g, function(match) { var cls = 'number'; if (/^\"/.test(match)) { if (/:$/.test(match)) { cls = 'key'; } else { cls = 'string'; } } else if (/true|false/.test(match)) { cls = 'boolean'; } else if (/null/.test(match)) { cls = 'null'; } return '' + match + ''; }); } })"},{"title":"","date":"2019-08-20T13:05:08.031Z","updated":"2019-08-09T10:39:08.961Z","comments":true,"path":"README.html","permalink":"https://jiangxingye.github.io/README.html","excerpt":"","text":"为 layui 扩展的 下拉多选select在线demo： http://yelog.org/layui-select-multiple/ 这个在线 demo就是本项目的 index.html。 可将项目 clone 到本地查看效果。 效果图 参数 属性名 属性值 备注 multiple 无 开启多选 lay-search 无 开启搜索 lay-case 无 大小写敏感 lay-omit 无 开启多选简写，显示勾选条数 使用 将项目中的 form.js 覆盖自己项目中的 form.js。 引入下面cssselect[multiple]+.layui-form-select&gt;.layui-select-title&gt;input.layui-input{ border-bottom: 0} select[multiple]+.layui-form-select dd{ padding:0;} select[multiple]+.layui-form-select .layui-form-checkbox[lay-skin=primary]{ margin:0 !important; display:block; line-height:36px !important; position:relative; padding-left:26px;} select[multiple]+.layui-form-select .layui-form-checkbox[lay-skin=primary] span{line-height:36px !important; float:none;} select[multiple]+.layui-form-select .layui-form-checkbox[lay-skin=primary] i{ position:absolute; left:10px; top:0; margin-top:9px;} .multiSelect{ line-height:normal; height:auto; padding:4px 10px; overflow:hidden;min-height:38px; margin-top:-38px; left:0; z-index:99;position:relative;background:none;} .multiSelect a{ padding:2px 5px; background:#908e8e; border-radius:2px; color:#fff; display:block; line-height:20px; height:20px; margin:2px 5px 2px 0; float:left;} .multiSelect a span{ float:left;} .multiSelect a i {float:left;display:block;margin:2px 0 0 2px;border-radius:2px;width:8px;height:8px;padding:4px;position:relative;-webkit-transition:all .3s;transition:all .3s} .multiSelect a i:before, .multiSelect a i:after {position:absolute;left:8px;top:2px;content:&#39;&#39;;height:12px;width:1px;background-color:#fff} .multiSelect a i:before {-webkit-transform:rotate(45deg);transform:rotate(45deg)} .multiSelect a i:after {-webkit-transform:rotate(-45deg);transform:rotate(-45deg)} .multiSelect a i:hover{ background-color:#545556;} 使用实例下面实例 开启了下拉多选（multiple）, 并开启了检索功能（lay-search）。效果可以参考 在线实例 的 多选+搜索+大小写不敏感 模块 &lt;select name=&quot;多选+搜索+大小写不敏感&quot; lay-verify=&quot;required&quot; multiple lay-search&gt; &lt;option value=&quot;&quot;&gt;请选择您的兴趣爱好&lt;/option&gt; &lt;option&gt;sing1&lt;/option&gt; &lt;option selected&gt;sing2&lt;/option&gt; &lt;option&gt;SING1-大写&lt;/option&gt; &lt;option&gt;movie1&lt;/option&gt; &lt;option selected&gt;movie2&lt;/option&gt; &lt;option&gt;movie3&lt;/option&gt; &lt;option&gt;MOVIE4&lt;/option&gt; &lt;option&gt;swim&lt;/option&gt; &lt;option&gt;moon&lt;/option&gt; &lt;/select&gt; 更多实例参考 在线实例、或 index.html。 声明此项目基于 https://gitee.com/layuicms/XiaLaDuoXuan 项目修改得来，修复了一些bug，扩展了 简化多选、多选搜索、大小写敏感控制等功能。"},{"title":"404 Not Found：该页无法显示","date":"2016-09-27T03:31:01.000Z","updated":"2019-08-09T10:39:08.961Z","comments":true,"path":"/404.html","permalink":"https://jiangxingye.github.io//404.html","excerpt":"","text":"很抱歉，您所访问的地址并不存在"},{"title":"About Me","date":"2019-08-09T10:10:52.000Z","updated":"2019-08-28T08:34:06.395Z","comments":true,"path":"about/index.html","permalink":"https://jiangxingye.github.io/about/index.html","excerpt":"","text":"不是啥程序员，自己利用空闲时间写点东西，有技术，也有一些岁月感悟。 毕业于吉林省万顺中学，目前在做IT智能和硬件服务器这个行当。 想买的朋友，可以用下面的联系方式和我联系。 最近在看《独裁者手册》这本书。 联系方式 QQ : 174762929 Wechat:jiangxingye 邮箱 : jiangxingye@outlook.com"}],"posts":[{"title":"Write a letter to parents","slug":"Write a letter to parents","date":"2019-09-02T12:41:12.000Z","updated":"2019-09-02T13:10:50.261Z","comments":true,"path":"2019/09/02/Write a letter to parents/","link":"","permalink":"https://jiangxingye.github.io/2019/09/02/Write a letter to parents/","excerpt":"","text":"思明区 观音山音乐学校 课后延时服务工作致家长一封信 家长您好： 为认真贯彻落实《思明区关于推进小学、幼儿园课后延时服务工作实施方案（试行）》的要求，认真做好我校课后延时服务工作，现将相关情况告知如下： 课后延时服务工作，是为解决部分小学生家长难以按时接孩子的问题，为正常放学后按时离校有困难（如父母双职工且无其他家人照看等）的小学生提供的延时照顾服务。 ​ 1.服务对象。在家长和孩子都自愿参与情况下，经家长（监护人）提出正式申请并获学校审核通过的，下午正常放学后有延时服务需要的学生。 2.服务内容。以学生自主阅读、完成作业为主。学校安排专人照管学生自行复习、作业、预习和课外阅读等，严格遵守义务教育学校办学行为规范，严禁借机组织开展学科性集中教学，严禁以导优辅差等名义组织或变相组织集体补课。 3.服务时段。 （1）本学期课后延时服务从2019年9月9日至2020年1月16日。 （2）课后延时服务从下午放学后开始，具体时段如下： a.课后延时服务结束时间原则上为18:00； b.周三为校教职工大会，所以不进行课后延时服务。 备注：家长应在服务时段结束后，根据学校规定在校门口有序排队接孩子离校。如本时段接孩子离校确有困难，请慎重申请课后延时服务。 4.制度保障。管理教师将教育敦促学生严格遵守在校的规章制度并做好看管记录，出现紧急情况时及时救助并通知学生监护人，确保学生安全。对个别不遵守纪律且教育劝阻无效者将约谈学生家长，约谈次数达到三次以上的，以及无故缺席或无特殊情况请假者一个月内三次以上的，学校将暂停为该学生家长提供课后延时服务。 5.收费标准。每生每月50元，按学期收取、按学期结算，每学期按4个月计算。 6.如遇特殊情况，学生未能参加当天的课后延时服务，家长需要提前向班主任老师请假。 7.请您仔细阅读以上条款，如您的孩子正常放学后按时离校确有困难，学生监护人根据学校通知要求填写《思明区观音山音乐学校学生课后延时服务申请表》，向学校提交课后延时服务的书面申请，经学校审核同意后，方可参加课后延时服务。 ​ 厦门市思明区观音山音乐学校 日 期： 2019年 9月 2 日 ………………………………………………………………………………………………………学生： 年 班 本人已收到学校发放的《思明区观音山音乐学校课后延时服务工作致家长一封信》，并已仔细阅读所有条款。 监护人签名：联系电话： 日 期： 年 月 日","categories":[{"name":"edu","slug":"edu","permalink":"https://jiangxingye.github.io/categories/edu/"}],"tags":[{"name":"Write a letter to parents","slug":"Write-a-letter-to-parents","permalink":"https://jiangxingye.github.io/tags/Write-a-letter-to-parents/"}]},{"title":"server support OS list","slug":"server support OS list","date":"2019-09-02T12:20:22.000Z","updated":"2019-09-03T01:18:10.751Z","comments":true,"path":"2019/09/02/server support OS list/","link":"","permalink":"https://jiangxingye.github.io/2019/09/02/server support OS list/","excerpt":"","text":"PM 说明 邓克武 单路C系列产品（PR1280C/2280C/6280C/1285C/2285C/1280C4/1285C4）桌面级系统不支持WIN7，支持WIN10,企业级系统最低支持Windows 2012系统，不兼容Windows 2008版本。 图站C系列（PT6610C/PR4610C）/P系列(6620P)/W系列(6630W)系列不支持WIN7，只支持WIN10，不支持Windows服务器级操作系统 曾柳雄 双路3/5/7系列（PRX510P/PRX710P/PR2012P/PR2715P/PR2750P/PR6510P）桌面级系统不支持WIN7，支持WIN10,企业级系统最低支持Windows 2012系统，不兼容Windows 2008版本。 李世伟 AI**系列（PR2906P/2908P/4904P/4908P/4910P/4920P/1904PV/4908PV）桌面级不支持WIN7，支持WIN10,上多张显卡不支持Windows Server系列系统** 李海鸥 PLSphere**虚拟化软件当前版本暂不支持vGPU，但可以支持直通模式使用，后续版本会升级支持vGPU特性** 刘磊 双路3/5/7系列（PR4024P/PR4036P/PR2720TP/PR2725TP/PR2740TP/PR2745TP/PR4740TP/PR4785TP）企业级系统最低支持Windows 2012系统，不兼容Windows 2008版本。 邵武 四路Purely 系列（PR2865P）桌面级系统不支持WIN7，支持WIN10；企业级系统最低支持Windows 2012系统，不兼容Windows 2008版本。 符芳裕 工控机系列（NAS-200H/918H/922H/941H/RNB-1402S），企业级系统最低支持Windows 2008系统，桌面系统支持Win7，Win10；（IPC-909C）,企业级系统最低支持Windows 2012系统，桌面系统只支持Win10/64位；网安机器（903B/916B/918S/928S/915S/925S/926G）,企业级系统最低支持Windows 2008系统，桌面系统支持Win7，Win10。","categories":[{"name":"it","slug":"it","permalink":"https://jiangxingye.github.io/categories/it/"},{"name":"server","slug":"it/server","permalink":"https://jiangxingye.github.io/categories/it/server/"},{"name":"Compatibility list","slug":"it/server/Compatibility-list","permalink":"https://jiangxingye.github.io/categories/it/server/Compatibility-list/"}],"tags":[{"name":"Compatibility list","slug":"Compatibility-list","permalink":"https://jiangxingye.github.io/tags/Compatibility-list/"}]},{"title":"宝德PR2865P","slug":"PR2865P","date":"2019-09-02T10:09:26.000Z","updated":"2019-09-03T01:18:29.263Z","comments":true,"path":"2019/09/02/PR2865P/","link":"","permalink":"https://jiangxingye.github.io/2019/09/02/PR2865P/","excerpt":"","text":"宝德PR2865P是基于Intel Purley平台研发的高密度2U4路服务器，具有突出的高性能，高可靠性，易扩展等优点。PR2865P支持最新的英特尔®至强®处理器可扩展家族，支持最大205W功率的CPU。PR2865P可提供更高效的计算性能，最大支持内存可达6TB，支持24块热插拔硬盘，扩展IO方面最大支持11个PCIE标准扩展槽，可同时支持2个双宽GPU计算卡 宝德PR2865P是商业关键负载，虚拟化，超融合，数据库，商业业务处理，以及对空间和性能要求严苛的数据密集型数据中心应用。 特性 PR2865P技术规格 形态 2U机架服务器 处理器数量 4个 处理器型号 英特尔® 至强® 处理器可扩展家族铂金8100 系列和黄金6100/5100系列，最高205W。 内存 48个插槽，最大支持6TB容量，最大频率 2666 MHz,支持Apache Pass (AEP) DIMMs 硬盘 24个2.5英寸SAS/SATA/SSD硬盘 可支持4个NVMe SSD硬盘 板载存储控制器 英特尔® C621，支持14个 SATA3 (6 Gbps)接口; RAID 0，1，5，10 同时，支持Intel VROC，可实现NVMe raid控制。 板载网络 支持4个千兆网口 PCIE扩展 最大支持11个PCIE 3.0 插槽，包含5个PCIE3.0 x8和6个 PCIE3.0 x16，选择165W一下CPU，可支持2个主动散热GPU卡 其他端口 后置：1个VGA接口, 1个串口, 2个USB 3.0，4个千兆网口，1个千兆IPMI2.0管理网口 内置：1个TPM2.0接口，1个VROC Key接口，1个USB3.0接口，2个SATA DOM接口，3个x4 mini SATA接口（支持12个SATA接口） 风扇 4个8CM热插拔冗余风扇 电源 标配2x 1600W钛金级热插拔冗余电源，支持1+1 冗余 管理 板载 Aspeed AST2500管理模块，支持IPMI2.0，英特尔® Node Manager，NMI，SMCBU，SMM，看门狗; 安全模块 支持TPM2.0 显示控制器 集成AST2500显示控制器 支持的操作系统 Windows Server 2012Enterprise Edition SP2 Red Hat* Enterprise Advanced Server 6.0 SuSE Linux Enterprise Server 11 供电 110V/220V AC 箱体尺寸 437 x 89 x 780mm (17.2” x 3.5” x 30.7”) 环境及规范 环境温度 运行时10℃至35℃ 非运行时-40℃至+70°C 周围环境 相对湿度 运行时：8% to 90%，不凝结 非运行时：5% to 95%，不凝结 静电释放 每项英特尔环境温度测试规范15KV 安全标准（中国） CCC 服务及支持 PowerLeader提供全国联保，由分布在全国各地PowerLeader专业售后服务网点提供“一站式”服务响应与支持。 - 3年有限现场保修以及现场支持服务 - 4008-870-872热线响应和支持 欲了解更多信息：请访问：http://www.powerleader.com.cn 通信地址：深圳市龙华新区观澜高新技术产业园宝德科技研发生产基地（观澜街道环观南路南侧） 宝德集团保留对产品规格或其他产品信息（包含但不限于产品重量，外观，尺寸或其他物理因素）不经通知予以更改的权利；本文中所提到的信息，如因产品升级或其他原因而导致的变更，恕不另行通知。本文中所涉及的产品图片均以产品实物为准。 2017年8月中国印刷 P/N:DPPR2865P V1.0","categories":[{"name":"it","slug":"it","permalink":"https://jiangxingye.github.io/categories/it/"},{"name":"server","slug":"it/server","permalink":"https://jiangxingye.github.io/categories/it/server/"}],"tags":[{"name":"PR2865P","slug":"PR2865P","permalink":"https://jiangxingye.github.io/tags/PR2865P/"}]},{"title":"关闭服务器CPU节能模式","slug":"关闭服务器CPU节能模式","date":"2019-08-16T09:58:37.000Z","updated":"2019-09-03T01:18:53.645Z","comments":true,"path":"2019/08/16/关闭服务器CPU节能模式/","link":"","permalink":"https://jiangxingye.github.io/2019/08/16/关闭服务器CPU节能模式/","excerpt":"","text":"OS系统总关闭P-state模式 CentOS7.x OS中使用了 IntelP-state ，导致机器BIOS关闭节电设置后，处理器的频率依旧处于频繁跳动状态。通过grub禁用Intel P-state解决OS控制处理器频率问题。操作如下： 使用root账号进入系统打开终端，两种方式， 第一种：右键 –> Open in Terminal 第二种，左上角Applications –> Utilities -> Terminal （蓝色字体部分为需要执行的命令） 在命令行执行lscpu |grep “Hz”，查看CPU是否处于额定主频（红色框中数值是否相等或非常相近，2.10GHz=2100MHz，图中明显不相等），然后执行下列命令： 将更改脚本放到/tmp/目录下。在终端执行sh change_grub.sh 如果成功，会自动重启，如果失败，会报错”更改失敗，需要手動進行更改”，请联系运维人员 主板BIOS中设置关闭节能模式 BIOS关闭节能，方法如下： 在上一步执行reboot之后会进行重启操作，过程中进入bios系统后 (按Delete键进入) CPU configuration Advanced Power Managerment Configuretion 在Power Technology 中选择Custom &amp;&amp; 返回 3．CPU P state Cotrol -> Disable &amp;&amp; 返回 4.CPU Cstat Cotrol -> Package C State Limit：C0/C1 state &amp;&amp; 返回 5.关闭QPI 总线的节能: advanced –> Chipset Configuration -> North Bridge ->QPI Configuration -> QPI General Configuretion —> LINK L0p /L1enable更改为disable 。 F4 保存退出执行重启 7、重启完成以后输入账户密码进入系统，打开终端，在命令行执行 lscpu |grep“Hz”查看CPU是否处于额定主频（下图中共色框中两个数值是否相等或非常相近，2.10GHz=2100MHz），如是说明修改成功。 change_grub.sh 脚本如下 #!/bin/sh cmd=&quot;intel_pstate=disable intel_idle.max_cstate=0 processor.max_cstate=1 idle=poll quiet&quot; check=$(cat /etc/default/grub |grep &quot;intel_pstate=disable intel_idle.max_cstate=0 processor.max_cstate=1 idle=poll&quot; | wc -l ) if [ $check -eq 0 ] then sed -i &quot;/GRUB_CMDLINE_LINUX/ s/quiet/$cmd/g&quot; /etc/default/grub else printf &quot;the file has been edited at a earlier time&quot; exit 0 fi if [ $? -ne 0 ] then printf &quot;faild,please change it by edit the file&quot; exit 1 fi grub2-mkconfig -o /boot/grub2/grub.cfg &amp;&amp; reboot","categories":[{"name":"it","slug":"it","permalink":"https://jiangxingye.github.io/categories/it/"},{"name":"server","slug":"it/server","permalink":"https://jiangxingye.github.io/categories/it/server/"}],"tags":[{"name":"关闭服务器CPU节能模式","slug":"关闭服务器CPU节能模式","permalink":"https://jiangxingye.github.io/tags/关闭服务器CPU节能模式/"}]},{"title":"meiyatest","slug":"meiyatest","date":"2019-08-15T07:25:06.000Z","updated":"2019-09-02T13:17:24.057Z","comments":true,"path":"2019/08/15/meiyatest/","link":"","permalink":"https://jiangxingye.github.io/2019/08/15/meiyatest/","excerpt":"","text":"美亚CH服务器性能基准测试 硬件配置一览表 型号 内部名称 技术规格 刀片机 还原（配套智能网卡）-低配 高密多节点服务器，每U≥2节点，总高度≤4U/每节点配置:2颗英特尔至强银牌4110 CPU（2.1GHz，8核）/128G DDR4内存/1*600G 15K SAS希捷硬盘/按厂商需求配备raid（有些品牌不配raid没法识别硬盘）/至少配备2个千兆网口，1个独立MGMT带外管理口（支持远程KVM功能)/预留至少1个半高半长pcie3.0*8网卡的插槽（长167mm，高68mm,厚16mm）/支持CentOS7.3，同时支持更高版本/带导轨/机箱冗余电源/备注功耗 还原（配套智能网卡）-中配 高密多节点服务器，每U≥2节点，总高度≤4U/每节点配置：2颗英特尔至强银牌4114 CPU（2.2GHz，10核）/256G DDR4内存/1*600G 15K SAS希捷硬盘/按厂商需求配备raid（有些品牌不配raid没法识别硬盘）/至少配备2个千兆网口，1个独立MGMT带外管理口（支持远程KVM功能/预留至少1个半高半长pcie3.0*8网卡的插槽（长167mm，高68mm,厚16mm）/支持CentOS7.3，同时支持更高版本/带导轨/机箱冗余电源/备注功耗 还原（配套智能网卡）-高配 高密多节点服务器，每U≥2节点，总高度≤4U/每节点配置为：2颗英特尔至强金牌6126 CPU（2.6GHz，12核）/512G DDR4内存/1*600G 15K SAS希捷硬盘/按厂商需求配备raid（有些品牌不配raid没法识别硬盘）/至少配备2个千兆网口，1个独立MGMT带外管理口（支持远程KVM功能）/预留至少1个半高半长pcie3.0*8网卡的插槽（长167mm，高68mm,厚16mm）/支持CentOS7.3，同时支持更高版本/带导轨/机箱冗余电源/备注功耗 索引服务器 索引 2U服务器/2颗英特尔至强银牌4110 CPU（2.1GHz，8核）/64G DDR4/8*900G SAS 10000rpm/ Raid0、1、5、6（1G缓存带超级电容）/双万兆和双千兆网口，不配万兆光模块（要求都是Intel的网卡，并且千兆支持支持IGB驱动，igb-3.2.10、igb-3.4.7、igb-5.1.2 这些版本都可以，万兆支持IXGBE驱动）、1个独立带外管理端口（支持远程KVM）/支持CentOS7.3，同时支持更高版本/带导轨，单电源/ 存储服务器 存储 2U服务器/2颗英特尔至强银牌4110 CPU（2.1GHz，8核）/128G DDR4/12*8T SATA 7200RPM/Raid0,1,5,6（1G或以上缓存，带超级电容，支持12个硬盘做1组Raid6）/每服务器双万兆和双千兆网口，不配万兆光模块（要求都是Intel的网卡，并且千兆支持支持IGB驱动，igb-3.2.10、igb-3.4.7、igb-5.1.2 这些版本都可以，万兆支持IXGBE驱动），1个独立MGMT带外管理口（支持远程KVM功能）/支持CentOS7.3及以上版本/带导轨，单电源/要求使用希捷企业级热插拔服务器硬盘/ 系统安装要求出厂预安装:做好raid5、划分VD、安装Centos 7.364位、安装图形化界面等操作。（避免现场安装失败问题） 1、刀片机 ：直接安装系统，无需做raid，按厂商需求配备raid（有些品牌不配raid没法识别硬盘）； 2、SOLR : raid5，划分2个VD （VD0 ：600G VD1 ：剩余空间 ，挂载为/data） 3、HBase : raid5，划分2个VD （VD0 ：600G VD1 ：16T ，挂载为/data,其余空间不用挂载） 测试环境准备准备工作 以下要求适用于sorl、存储的CentOS V7.3及以上版本的服务器。 操作系统参数 vi /etc/security/limits.conf * hard nofile 1000000 * soft nofile 1000000 * hard nproc 409600 * soft nproc 409600 vi /etc/security/limits.d/20-nproc.conf * soft nproc 409600 echo 0 > /proc/sys/vm/swappiness; echo vm.swappiness=0 >> /etc/sysctl.conf 设置linux内核参数： vi /etc/sysctl.conf net.core.somaxconn = 8192 net.ipv4.tcp_max_syn_backlog = 8192 net.ipv4.tcp_synack_retries = 2 net.ipv4.tcp_syn_retries = 2 net.ipv4.tcp_timestamps = 0 net.ipv4.tcp_window_scaling = 1 net.core.rmem_max = 16777216 net.core.wmem_max = 16777216 net.ipv4.tcp_rmem = 4096 87380 16777216 net.ipv4.tcp_wmem = 4096 87380 16777216 kernel.pid_max = 200000 vm.max_map_count = 400000 并执行： sysctl -p 禁用SELINUX { 或 /etc/sysconfig/selinux disabled } vi /etc/selinux/config SELINUX=disabled 并执行： setenforce 0 禁用iptables systemctl stop firewalld #关闭防火墙 systemctl disable firewalld #禁止开机启动 HBase: gcc-c++安装 CentOS7.3 gcc-c++ 将依赖的包放在ee文件夹上传到/opt目录或者从系统盘中安装 cd /opt/ee 执行如下操作： rpm -ivh glibc-common-2.17-157.el7.x86_64.rpm rpm -ivh kernel-headers-3.10.0-514.el7.x86_64.rpm rpm -ivh libgcc-4.8.5-11.el7.x86_64.rpm rpm -ivh libgcc-4.8.5-11.el7.i686.rpm rpm -ivh glibc-2.17-157.el7.x86_64.rpm rpm -ivh mpfr-3.1.1-4.el7.x86_64.rpm rpm -ivh libgomp-4.8.5-11.el7.x86_64.rpm rpm -ivh nscd-2.17-157.el7.x86_64.rpm rpm -ivh glibc-headers-2.17-157.el7.x86_64.rpm rpm -ivh glibc-devel-2.17-157.el7.x86_64.rpm rpm -ivh libstdc++-4.8.5-11.el7.x86_64.rpm rpm -ivh libstdc++-devel-4.8.5-11.el7.x86_64.rpm rpm -ivh libmpc-1.0.1-3.el7.x86_64.rpm rpm -ivh cpp-4.8.5-11.el7.x86_64.rpm rpm -ivh gcc-4.8.5-11.el7.x86_64.rpm rpm -ivh gcc-c++-4.8.5-11.el7.x86_64.rpm [\\@more\\@] gcc -v （查看是否安装成功） [root\\@localhost ee]# gcc -v Using built-in specs. COLLECT_GCC=gcc COLLECT_LTO_WRAPPER=/usr/libexec/gcc/x86_64-redhat-linux/4.8.5/lto-wrapper Target: x86_64-redhat-linux Configured with: ../configure –prefix=/usr –mandir=/usr/share/man–infodir=/usr/share/info –with-bugurl=http://bugzilla.redhat.com/bugzilla–enable-bootstrap –enable-shared –enable-threads=posix–enable-checking=release –with-system-zlib –enable-__cxa_atexit–disable-libunwind-exceptions –enable-gnu-unique-object–enable-linker-build-id –with-linker-hash-style=gnu–enable-languages=c,c++,objc,obj-c++,java,fortran,ada,go,lto –enable-plugin–enable-initfini-array –disable-libgcj–with-isl=/builddir/build/BUILD/gcc-4.8.5-20150702/obj-x86_64-redhat-linux/isl-install–with-cloog=/builddir/build/BUILD/gcc-4.8.5-20150702/obj-x86_64-redhat-linux/cloog-install–enable-gnu-indirect-function –with-tune=generic –with-arch_32=x86-64–build=x86_64-redhat-linux Thread model: posix gcc version 4.8.5 20150623 (Red Hat 4.8.5-11) (GCC) (说明安装成功) JDK安装 cd /usr/local 将jdk1.7.0_25.tar.gz放在/usr/local解压. ln -s /usr/local/jdk1.7.0_25/ /usr/local/java7 vi /etc/profile 添加： export JAVA_HOME=/usr/local/java7 export PATH=\\$JAVA_HOME/bin:\\$PATH export HADOOP_HOME=/usr/local/hadoop export PATH=\\$HADOOP_HOME/bin:\\$PATH export HBASE_HOME=/usr/local/hbase export PATH=\\$HBASE_HOME/bin:\\$PATH 并执行： source /etc/profile FIO测试1、fio安装fio-2.1.10.tar.gz解压至/usr/local/ cd /usr/local tar zxvf fio-2.1.10.tar.gz cd fio-2.0.7makemake install fio测试 2、还原机FIO随机写50MB ，bs 2k fio -filename=/dev/sda -direct=1 -iodepth 8 -thread -rw=randwrite-ioengine=psync -bs=2k -size=50MB -numjobs=30 -runtime=300 -group_reporting-name=mytest 随机写1G ，bs 4k fio -filename=/dev/sda -direct=1 -iodepth 8 -thread -rw=randwrite-ioengine=psync -bs=4k -size=1G -numjobs=30 -runtime=300 -group_reporting-name=mytest 顺序读50M ，bs 2k fio -filename=/dev/sda -direct=1 -iodepth 8 -thread -rw=read -ioengine=psync-bs=2k -size=50MB -numjobs=30 -runtime=300 -group_reporting -name=mytest 顺序读1G ，bs 4k fio -filename=/dev/sda -direct=1 -iodepth 8 -thread -rw=read -ioengine=psync-bs=4k -size=1G -numjobs=30 -runtime=300 -group_reporting -name=mytest 3、索引FIO顺序写500MB ，bs 512k fio -filename=/dev/sdb -direct=1 -iodepth 8 -thread -rw=write -ioengine=psync-bs=512K -size=500MB -numjobs=30 -runtime=300 -group_reporting -name=mytest 顺序写1G，bs 1MB fio -filename=/dev/sdb -direct=1 -iodepth 8 -thread -rw=write -ioengine=psync-bs=1MB -size=1G -numjobs=30 -runtime=300 -group_reporting -name=mytest 随机读500MB ，bs 512k fio -filename=/dev/sdb -direct=1 -iodepth 8 -thread -rw=randread -ioengine=psync-bs=512K -size=500MB -numjobs=30 -runtime=300 -group_reporting -name=mytest 随机读1G ，bs 1MB fio -filename=/dev/sdb -direct=1 -iodepth 8 -thread -rw=randread -ioengine=psync-bs=1MB -size=1G -numjobs=30 -runtime=300 -group_reporting -name=mytest 4、存储FIO顺序写500MB ，bs 512k fio -filename=/dev/sdb -direct=1 -iodepth 8 -thread -rw=write -ioengine=psync-bs=512K -size=500MB -numjobs=30 -runtime=300 -group_reporting -name=mytest 顺序写1G，bs 1MB fio -filename=/dev/sdb -direct=1 -iodepth 8 -thread -rw=write -ioengine=psync-bs=1MB -size=1G -numjobs=30 -runtime=300 -group_reporting -name=mytest 随机读500MB ，bs 512k fio -filename=/dev/sdb -direct=1 -iodepth 8 -thread -rw=randread -ioengine=psync-bs=512K -size=500MB -numjobs=30 -runtime=300 -group_reporting -name=mytest 随机读1G ，bs 1MB fio -filename=/dev/sdb -direct=1 -iodepth 8 -thread -rw=randread -ioengine=psync-bs=1MB -size=1G -numjobs=30 -runtime=300 -group_reporting -name=mytest 索引基准测试SOLR安装solrs.tar 解压至/usr/local/ tar xvf solrs.tar solrs_data.tar 解压至/data tar xvf solrs_data.tar 将数据解压至/datascp ip:/home/benchmark_solr.tar /data cd /data tar xvf benchmark_solr.tar solr基准测试启动solr killall java; /data/benchmark/solrs/yk/bin/startup.sh 清空系统缓存 echo 3 > /proc/sys/vm/drop_caches 验证http://**ip**:8900/solr/yk/select?q=\\*%3A\\*&amp;wt=json&amp;indent=true确保访问正常，返回如下结果 登录任意一台服务器（如：172.16.20.159，与solr服务器同一网段），安装perl环境（perl为系统盘对应的版本） 将benchmark.tar.gz文件解压到/opt目录后执行如下操作： cd /opt/benchmark/solr/ 修改benchmark.perl一些参数配置： forkCount:并发数 测试并发数为：100 queryCount:查询次数 测试并发数为：1000 urlHost：目标主机ip 根据实际SOLR服务器的ip配置 执行benchmark文件：perl benchmark.perl，运行结果： Req/s:(每秒请求数) Avg:平均耗时 Median:中间耗时 95th:95%的查询耗在2.604范围 99th:99%的查询耗时在5.498范围 Max：最大耗时 存储基准测试1、主机名配置vi /etc/sysconfig/network 并执行hostname HBase-01 2、主机名查询静态表配置 3、snappy安装snappy-1.1.2.tar.gz解压至/opt/下 cd /opt; tar zxvf snappy-1.1.2.tar.gz cd /snappy-1.1.2 ./configure make make install 4、ssh无密码登陆ssh-keygen -t rsa （回车到底） cat /root/.ssh/id_rsa.pub >> /root/.ssh/authorized_keys 5、hadoop安装 解压hadoop.tar至/usr/local/ tar xvf hadoop.tar ln -s /usr/local/hadoop-1.0.3/ /usr/local/hadoop ln -s /usr/local/hbase-0.94.1/ /usr/local/hbase 6、hadoop启动killall -s 9 java rm -rf /data/hadoop/ hadoop namenode -format start-all.sh 7、hadoop验证 查看http://172.16.20.232:50070/dfshealth.jsp页面，确保访问正常，同时 DeadNodes为0 执行jps命令,确保有以下的进程 9、HBase基准测试测试工具（yscb安装） mkdir -p /opt/benchmark/hbase/; 解压yscb至/opt/benchmark/hbase/ cd /opt/benchmark/hbase/ tar zxvf ycsb-0.1.4.tar.gz 10、HBase启动清空系统缓存: echo 3 > /proc/sys/vm/drop_caches killall -s 9 java rm -rf /data/hadoop/ hadoop namenode -format start-dfs.sh start-hbase.sh 11、HBase验证 查看http://172.16.20.232:60010/master-status页面，确保访问正常，同时没有DeadRegion Servers 执行jps命令,确保有以下的进程： 12、HBase基准测试创建hbase表 echo “create ‘usertable’,’f1’,’f2’,’f3’”|hbase shell 查看表是否已经创建 echo list|hbase shell 清空系统缓存: echo 3 > /proc/sys/vm/drop_caches cd /opt/benchmark/hbase/ycsb-0.1.4/bin; 执行插入测试，创建100个线程,插入100w条记录： ./ycsb load hbase -P ../workloads/workloada -p threads=100 -pcolumnfamily=f1 -p recordcount=1000000 -s > load.dat 测试结果存取在load.dat中,查看load.dat有如下结果 grep -v -E ‘UPDATE|CLEANUP’ load.dat|more Runtime:执行时间(ms) Throughput(ops/sec):吞吐量(每秒操作次数) Operations：操作总数 AverageLatency：平均耗时(us) MinLatency:最小耗时(us) MaxLatency:最大耗时(us) 95thPercentileLatency(ms):95%的执行时间范围 99thPercentileLatency(ms):99%的执行时间范围 执行事务操作(95%的读操作 5%的写操作) 创建100个线程,操作100w次 ./ycsb run hbase -P ../workloads/workloadb -threads 100 -pmeasurementtype=timeseries -p columnfamily=f1 -p operationcount=1000000 -ptimeseries.granularity=2000 > transactions.dat 测试结果存取在transactions.dat中 查看更新操作测试结果 grep UPDATE transactions.dat 查看读取操作测试结果 grep READ transactions.dat NMON监控在做SOLR或HBase基准测试时，使用nmon监控服务器的CPU、内存、磁盘资源使用情况 1、安装nmon 解压nmon至/usr/local/ cd /usr/local tar zxvf nmon.tar.gz 2、修改nmon参数 cd nmon vi nmon_start.sh 修改频率为10秒一次，监控5000次： 3、运行nmon 做基准测试同时，运行nmon，监控测试时的硬件资源使用情况 ./nmon_start.sh 同一目录下会生成nmon文件 4、关掉nmon 基准测试结束时，停掉nmon Killall nmon 5、生成图形化结果 打开nmon analyser v34a.xls，点击Analyse nmon data按键，加载nmon文件，生成图形化结果：","categories":[{"name":"IT","slug":"IT","permalink":"https://jiangxingye.github.io/categories/IT/"},{"name":"server","slug":"IT/server","permalink":"https://jiangxingye.github.io/categories/IT/server/"}],"tags":[{"name":"美亚测试机","slug":"美亚测试机","permalink":"https://jiangxingye.github.io/tags/美亚测试机/"}]},{"title":"苏联解体的启示","slug":"苏联解体的启示","date":"2019-08-12T11:15:19.000Z","updated":"2019-09-03T02:59:33.722Z","comments":true,"path":"2019/08/12/苏联解体的启示/","link":"","permalink":"https://jiangxingye.github.io/2019/08/12/苏联解体的启示/","excerpt":"","text":"从1989春至1991年底，短短两年，人类历史上最强大的专政机器——苏联东欧红色帝国土崩瓦解。这是二十世纪最伟大的故事。 一个皇朝的解体，一般可以概括为：“生于不义，死于耻辱。” 皇朝倒台前会有几个特点： 货币急速贬值，老百姓爱做梦。 美国当年成立特殊金融小组制裁前苏联，导致苏联解体。 表面强大的前苏联，就这样既无外敌入侵，又没有天灾，自己就玩不下去了，就解体了。 朝鲜经济短时间内很难稳定，楼市、基建、政府各种债务出清，国有资产私有化， 区域自治的各地关税统一等等，这些问题牵扯到的利益博弈将是及其复杂， 没有十几年的争吵很难达成统一，毕竟是各方都有选票，财富无论怎么划分， 都会有人不满意，这就注定了未来朝鲜金融系统将会长期动荡。 总之，生活在百姓无知，爱做梦的国家，挺难的，不确定性太大。","categories":[{"name":"read","slug":"read","permalink":"https://jiangxingye.github.io/categories/read/"}],"tags":[{"name":"苏联解体","slug":"苏联解体","permalink":"https://jiangxingye.github.io/tags/苏联解体/"}]},{"title":"如何在服务器的BIOS中设置上电自启动","slug":"如何在服务器的BIOS中设置上电自启动","date":"2019-08-12T06:36:33.000Z","updated":"2019-09-03T01:18:47.131Z","comments":true,"path":"2019/08/12/如何在服务器的BIOS中设置上电自启动/","link":"","permalink":"https://jiangxingye.github.io/2019/08/12/如何在服务器的BIOS中设置上电自启动/","excerpt":"","text":"说明： 1、为什么要实现这种功能，很多时候在民间都基本用普通PC来做小型服务器，公司的私服等等，而这些普通PC在民用电环境中经常会停电，一停就会导致服务器不能自动来电重启，所以这个功能来点开机是必须的。 2、普通PC基本都是以下这些配置方式，但不要和服务器主板做比较，服务器主板有专业的配置选项以及专业的来电自动启动设备。 下面根据不同的BIOS列出相应的设置方法： 1：首先进入BIOS的设置主界面，选择[POWER MANAGEMENT SETUP]，再选择[PWR Lost Resume State]，这一项有三个选择项。 选择[Keep OFF]项，代表停电后再来电时，电脑不会自动启动。 选择[Turn On]项，代表停电后再来电时，电脑会自动启动。 选择的[Last State]，那么代表停电后再来电时，电脑恢复到停电前电脑的状态。断电前如果电脑是处于开机状态，那么来电后就会自动开机。断电前是处于关机状态，那么来电后电脑不会自动开机。 2：首先进入Power Management Setup（电源管理设定）→Power Again（再来电状态），此项决定了开机时意外断电之后，电力供应恢复时系统电源的状态。设定值有：Power Off（保持系统处于关机状态）Power On（保持系统处于开机状态）Last State（恢复到系统断电前的状态）进入挂起/睡眠模式，但若按钮被揿下超过4秒，机器关机。若想来电自动开机把上面的这项改成power on就行了！ 3：有的BIOS中[POWER MANAGEMENT SETUP]没有上面说的[PWR Lost Resume State]，可以在[PWRON After PWR-Fail]→[Integrated Peripherals]选项中找到两个选项：ON(打开自动开机)和OFF(关闭自动开机)，设置为OFF即可。不同的主板及BIOS型号相对应的选项会有所不同，但我想应该会差不多，一般都在[POWER MANAGEMENT SETUP]这个选项中可以找到相应的设置选项！","categories":[{"name":"it","slug":"it","permalink":"https://jiangxingye.github.io/categories/it/"},{"name":"server","slug":"it/server","permalink":"https://jiangxingye.github.io/categories/it/server/"}],"tags":[{"name":"如何在服务器的BIOS中设置上电自启动","slug":"如何在服务器的BIOS中设置上电自启动","permalink":"https://jiangxingye.github.io/tags/如何在服务器的BIOS中设置上电自启动/"}]},{"title":"raid丢失系统恢复案例","slug":"raid丢失系统恢复案例","date":"2019-08-12T04:31:04.000Z","updated":"2019-09-03T01:18:21.817Z","comments":true,"path":"2019/08/12/raid丢失系统恢复案例/","link":"","permalink":"https://jiangxingye.github.io/2019/08/12/raid丢失系统恢复案例/","excerpt":"","text":"How to fix “No Bootable Device” issue on server?故障现象： 原因分析：客户机器有独立的RAID卡，2块物理磁盘做的RAID0，和客户沟通，RAID卡进去状态不正常，不想重新安装系统。因为上面的环境配置很麻烦。 处理过程： 重新在RAID卡里做同级别RAID的话，不在raid里做clear操作的话，数据不丢失的话，理论上系统是有办法恢复的，如果数据会消失，那就要重做了。经验证，做同级别RAID系统恢复，数据并未消失。 问题解决： 建议： 如果系统上有重要数据的话，还是建议使用RAID1会安全一些。 如果你忙觉得上述案例帮助了您，给个赞哦，当然也可以打赏杯可乐，我就不用喝酱油兑水了,^_^ 么么哒！ 服务器购买也可以通过下面的联系方式向我咨询。","categories":[{"name":"it","slug":"it","permalink":"https://jiangxingye.github.io/categories/it/"},{"name":"server","slug":"it/server","permalink":"https://jiangxingye.github.io/categories/it/server/"}],"tags":[{"name":"bootable device were deteced.","slug":"bootable-device-were-deteced","permalink":"https://jiangxingye.github.io/tags/bootable-device-were-deteced/"}]},{"title":"shell速查表","slug":"shell-command","date":"2018-09-08T03:48:24.000Z","updated":"2019-09-02T13:02:59.999Z","comments":true,"path":"2018/09/08/shell-command/","link":"","permalink":"https://jiangxingye.github.io/2018/09/08/shell-command/","excerpt":"","text":"1. 变量#!/bin/bash msg=&quot;hello world&quot; echo $msg 变量名的命名须遵循如下规则： 命名只能使用英文字母，数字和下划线，首个字符不能以数字开头。 中间不能有空格，可以使用下划线（_）。 不能使用标点符号。 不能使用bash里的关键字（可用help命令查看保留关键字）。 2. 传参#!/bin/bash echo &quot;执行的文件名：$0&quot;; echo &quot;第一个参数为：$1&quot;; echo &quot;第二个参数为：$2&quot;; echo &quot;第三个参数为：$3&quot;; 脚本内获取参数的格式为：$n。n 代表一个数字，1 为执行脚本的第一个参数，2 为执行脚本的第二个参数，以此类推……另外，还有几个特殊字符用来处理参数： 参数 说明 $# 传递到脚本的参数个数 $* 以一个单字符串显示所有向脚本传递的参数。如&quot;$*&quot;用「”」括起来的情况、以”$1 $2 … $n”的形式输出所有参数。 $$ 脚本运行的当前进程ID号 $! 后台运行的最后一个进程的ID号 $@ 与$*相同，但是使用时加引号，并在引号中返回每个参数。如”$@”用「”」括起来的情况、以”$1” “$2” … “$n” 的形式输出所有参数。 $- 显示Shell使用的当前选项，与set命令功能相同。 $? 显示最后命令的退出状态。0表示没有错误，其他任何值表明有错误。 3. 数组#!/bin/bash my_array=(A B &quot;C&quot; D) echo &quot;第一个元素为: ${my_array[0]}&quot; echo &quot;第二个元素为: ${my_array[1]}&quot; echo &quot;第三个元素为: ${my_array[2]}&quot; echo &quot;第四个元素为: ${my_array[3]}&quot; echo &quot;数组的元素为: ${my_array[*]}&quot; echo &quot;数组的元素为: ${my_array[@]}&quot; echo &quot;数组元素个数为: ${#my_array[*]}&quot; echo &quot;数组元素个数为: ${#my_array[@]}&quot; 执行结果如下： 第一个元素为: A 第二个元素为: B 第三个元素为: C 第四个元素为: D 数组的元素为: A B C D 数组的元素为: A B C D 数组元素个数为: 4 数组元素个数为: 4 4. 基本运算符 原生 bash 不支持简单的数学运算，但是可以通过其他命令来实现，例如 awk 和 expr，expr 最常用。 expr 是一款表达式计算工具，使用它能完成表达式的求值操作。 ① 算数运算符#!/bin/bash echo &quot;2加2等于&quot;`expr 2 + 2` echo &quot;2减2等于&quot;`expr 2 - 2` echo &quot;2乘2等于&quot;`expr 2 \\* 2` echo &quot;2除2等于&quot;`expr 2 / 2` echo &quot;2除2取余&quot;`expr 2 % 2` ② 关系运算符#!/bin/bash a=10 b=20 if [ $a -eq $b ] # 检测两个数是否相等，相等返回 true。 if [ $a -ne $b ] # 检测两个数是否不相等，不相等返回 true。 if [ $a -gt $b ] # 检测左边的数是否大于右边的，如果是，则返回 true。 if [ $a -lt $b ] # 检测左边的数是否小于右边的，如果是，则返回 true。 if [ $a -ge $b ] # 检测左边的数是否大于等于右边的，如果是，则返回 true。 if [ $a -le $b ] # 检测左边的数是否小于等于右边的，如果是，则返回 true。 ③ 布尔运算符#!/bin/bash if [ ! false ] # 非运算，返回 true if [ true -o false ] # 或运算，返回 true if [ true -a false ] # 与运算，返回 false ④ 逻辑运算符#!/bin/bash a=10 b=20 if [[ $a -lt $b &amp;&amp; $a -gt $b ]] # 逻辑的 AND, 返回 false if [ $a -lt $b ] &amp;&amp; [ $a -gt $b ] # 逻辑的 AND, 返回 false if [[ $a -lt $b || $a -gt $b ]] # 逻辑的 OR, 返回 true if [ $a -lt $b ] || [ $a -gt $b ] # 逻辑的 OR, 返回 true ⑤ 字符串运算符#!/bin/bash a=&quot;abc&quot; b=&quot;efg&quot; if [ $a = $b ] # 检测两个字符串是否相等，相等返回 true。 if [ $a != $b ] # 检测两个字符串是否相等，不相等返回 true。 if [ -z $a ] # 检测字符串长度是否为0，为0返回 true。 if [ -n &quot;$a&quot; ] # 检测字符串长度是否为0，不为0返回 true。 if [ $a ] # 检测字符串是否为空，不为空返回 true。 ⑥ 文件测试运算符文件测试运算符用于检测 Unix 文件的各种属性。 操作符 说明 -b file 检测文件是否是块设备文件，如果是，则返回 true。 -c file 检测文件是否是字符设备文件，如果是，则返回 true。 -d file 检测文件是否是目录，如果是，则返回 true。 -f file 检测文件是否是普通文件（既不是目录，也不是设备文件），如果是，则返回 true。 -g file 检测文件是否设置了 SGID 位，如果是，则返回 true。 -k file 检测文件是否设置了粘着位(Sticky Bit)，如果是，则返回 true。 -p file 检测文件是否是有名管道，如果是，则返回 true。 -u file 检测文件是否设置了 SUID 位，如果是，则返回 true。 -r file 检测文件是否可读，如果是，则返回 true。 -w file 检测文件是否可写，如果是，则返回 true。 -x file 检测文件是否可执行，如果是，则返回 true。 -s file 检测文件是否为空（文件大小是否大于0），不为空返回 true。 -e file 检测文件（包括目录）是否存在，如果是，则返回 true。 5. echo① 命令格式#!/bin/bash echo &quot;It is a test&quot; echo It is a test echo &quot;\\&quot;It is a test\\&quot;&quot; # 转义 name=Chris echo &quot;$name is handsome&quot; echo -e &quot;OK! \\n&quot; # 显示换行 -e 开启转义 echo &quot;It is a test&quot; &gt; myfile # 显示结果定向至文件 echo &#39;$name\\&quot;&#39; # 原样输入字符串，不进行转义或取变量（使用单引号） echo `date` # 显示命令执行结构 ② 颜色显示echo -e &quot;\\033[字背景颜色；文字颜色m字符串\\033[0m&quot; echo -e “\\033[30m 黑色字 \\033[0m” echo -e “\\033[31m 红色字 \\033[0m” echo -e “\\033[32m 绿色字 \\033[0m” echo -e “\\033[33m 黄色字 \\033[0m” echo -e “\\033[34m 蓝色字 \\033[0m” echo -e “\\033[35m 紫色字 \\033[0m” echo -e “\\033[36m 天蓝字 \\033[0m” echo -e “\\033[37m 白色字 \\033[0m” echo -e “\\033[40;37m 黑底白字 \\033[0m” echo -e “\\033[41;37m 红底白字 \\033[0m” echo -e “\\033[42;37m 绿底白字 \\033[0m” echo -e “\\033[43;37m 黄底白字 \\033[0m” echo -e “\\033[44;37m 蓝底白字 \\033[0m” echo -e “\\033[45;37m 紫底白字 \\033[0m” echo -e “\\033[46;37m 天蓝底白字 \\033[0m” echo -e “\\033[47;30m 白底黑字 \\033[0m” \\33[0m 关闭所有属性 \\33[1m 设置高亮度 \\33[4m 下划线 \\33[5m 闪烁 \\33[7m 反显 \\33[8m 消隐 \\33[30m — \\33[37m 设置前景色 \\33[40m — \\33[47m 设置背景色 \\33[nA 光标上移n行 \\33[nB 光标下移n行 \\33[nC 光标右移n行 \\33[nD 光标左移n行 \\33[y;xH设置光标位置 \\33[2J 清屏 \\33[K 清除从光标到行尾的内容 \\33[s 保存光标位置 \\33[u 恢复光标位置 \\33[?25l 隐藏光标 \\33[?25h 显示光标 6. sprintf#!/bin/bash printf &quot;%-10s %-8s %-4s\\n&quot; 姓名 性别 体重kg printf &quot;%-10s %-8s %-4.2f\\n&quot; 郭靖 男 66.1234 printf &quot;%-10s %-8s %-4.2f\\n&quot; 杨过 男 48.6543 printf &quot;%-10s %-8s %-4.2f\\n&quot; 郭芙 女 47.9876 结果： 姓名 性别 体重kg 郭靖 男 66.12 杨过 男 48.65 郭芙 女 47.99 %s %c %d %f 都是格式替代符d: Decimal 十进制整数 – 对应位置参数必须是十进制整数，否则报错！s: String 字符串 – 对应位置参数必须是字符串或者字符型，否则报错！c: Char 字符 – 对应位置参数必须是字符串或者字符型，否则报错！f: Float 浮点 – 对应位置参数必须是数字型，否则报错！%-10s 指一个宽度为10个字符（-表示左对齐，没有则表示右对齐）,任何字符都会被显示在10个字符宽的字符内，如果不足则自动以空格填充，超过也会将内容全部显示出来。%-4.2f 指格式化为小数，其中.2指保留2位小数。 7. testShell中的 test 命令用于检查某个条件是否成立，它可以进行数值、字符和文件三个方面的测试。 #!/bin/bash num1=100 num2=100 if test $[num1] -eq $[num2] 8. 流程控制① if-else#!/bin/bash a=10 b=20 if [ $a == $b ] then echo &quot;a 等于 b&quot; elif [ $a -gt $b ] then echo &quot;a 大于 b&quot; elif [ $a -lt $b ] then echo &quot;a 小于 b&quot; else echo &quot;没有符合的条件&quot; fi ② for#!/bin/bash for loop in 1 2 3 4 5 do echo &quot;The value is: $loop&quot; done ③ while#!/bin/bash int=1 while(( $int&lt;=5 )) do echo $int let &quot;int++&quot; done ④ case#!/bin/bash echo &#39;输入 1 到 4 之间的数字:&#39; echo &#39;你输入的数字为:&#39; read aNum case $aNum in 1) echo &#39;你选择了 1&#39; ;; 2) echo &#39;你选择了 2&#39; ;; 3) echo &#39;你选择了 3&#39; ;; 4) echo &#39;你选择了 4&#39; ;; *) echo &#39;你没有输入 1 到 4 之间的数字&#39; ;; esac ⑤ breakbreak命令允许跳出所有循环（终止执行后面的所有循环）。 #!/bin/bash while : do echo -n &quot;输入 1 到 5 之间的数字:&quot; read aNum case $aNum in 1|2|3|4|5) echo &quot;你输入的数字为 $aNum!&quot; ;; *) echo &quot;你输入的数字不是 1 到 5 之间的! 游戏结束&quot; break ;; esac done ⑥ continue跳出当前循环。 #!/bin/bash while : do echo -n &quot;输入 1 到 5 之间的数字: &quot; read aNum case $aNum in 1|2|3|4|5) echo &quot;你输入的数字为 $aNum!&quot; ;; *) echo &quot;你输入的数字不是 1 到 5 之间的!&quot; continue echo &quot;游戏结束&quot; ;; esac done ⑦ until#!/bin/bash a=0 until [ ! $a -lt 10 ] do echo $a a=`expr $a + 1` done 9. 函数#!/bin/bash funWithParam(){ echo &quot;第一个参数为 $1 !&quot; echo &quot;第二个参数为 $2 !&quot; echo &quot;第十个参数为 $10 !&quot; echo &quot;第十个参数为 ${10} !&quot; echo &quot;第十一个参数为 ${11} !&quot; echo &quot;参数总数有 $# 个!&quot; echo &quot;作为一个字符串输出所有参数 $* !&quot; } funWithParam 1 2 3 4 5 6 7 8 9 34 73 结果： 第一个参数为 1 ! 第二个参数为 2 ! 第十个参数为 10 ! 第十个参数为 34 ! 第十一个参数为 73 ! 参数总数有 11 个! 作为一个字符串输出所有参数 1 2 3 4 5 6 7 8 9 34 73 ! 10. 输入输出#!/bin/bash who &gt; today.log # 执行结果覆盖到文件 today.log echo &quot;菜鸟教程：www.runoob.com&quot; &gt;&gt; today.log # 执行结果追加到文件 today.log wc -l &lt; today.log # 统计 today.log 行数 wc -l &lt;&lt; EOF 李白 苏轼 王勃 EOF 11. 文件包含test1.sh #!/bin/bash name=&quot;Chris&quot; test2.sh #!/bin/bash #使用 . 号来引用test1.sh 文件 . ./test1.sh # 或者使用以下包含文件代码 # source ./test1.sh echo $name 注：被包含的文件 test1.sh 不需要可执行权限。 reference:[1] http://www.runoob.com/linux/linux-shell.html","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://jiangxingye.github.io/tags/linux/"},{"name":"shell","slug":"shell","permalink":"https://jiangxingye.github.io/tags/shell/"}]},{"title":"nginx配置记录","slug":"nginx-config","date":"2018-02-08T01:19:09.000Z","updated":"2019-09-02T13:02:59.998Z","comments":true,"path":"2018/02/08/nginx-config/","link":"","permalink":"https://jiangxingye.github.io/2018/02/08/nginx-config/","excerpt":"","text":"启用https1.购买免费证书登录阿里云 -&gt; 控制台 -&gt; 安全（云盾） -&gt; CA证书服务 -&gt; 购买证书 2.补全证书信息点击补全，绑定域名 3.下载并配置选择下载 证书for nginx 上面这个页面有相关的配置信息，下面简单介绍： ① 将下载文件中的 *.pem、*.key, 拷贝到 nginx 目录下 的 cert , 当然也可以是其他目录② 修改 nginx.conf server { listen 443 ssl; server_name xiangzhangshugongyi.com; ssl_certificate cert/214487958220243.pem; ssl_certificate_key cert/214487958220243.key; ssl_session_cache shared:SSL:1m; ssl_session_timeout 5m; ssl_ciphers HIGH:!aNULL:!MD5; ssl_prefer_server_ciphers on; location / { proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Host $http_host; proxy_set_header X-Forwarded-Proto https; proxy_redirect off; proxy_connect_timeout 240; proxy_send_timeout 240; proxy_read_timeout 240; # note, there is not SSL here! plain HTTP is used proxy_pass http://127.0.0.1:8080; } } ③ 重启 nginx，通过 证书绑定域名进行 https 访问到 服务器跑在 8080 的服务","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://jiangxingye.github.io/tags/nginx/"}]},{"title":"[转]谈谈Java中的语法糖","slug":"java-grammatical-sugar","date":"2017-11-27T14:51:45.000Z","updated":"2019-09-02T13:02:59.978Z","comments":true,"path":"2017/11/27/java-grammatical-sugar/","link":"","permalink":"https://jiangxingye.github.io/2017/11/27/java-grammatical-sugar/","excerpt":"","text":"语法糖（Syntactic Sugar），也称糖衣语法，指在计算机语言中添加的某种语法，这种语法对语言本身功能来说没有什么影响，只是为了方便程序员的开发，提高开发效率。说白了，语法糖就是对现有语法的一个封装。 Java作为一种与平台无关的高级语言，当然也含有语法糖，这些语法糖并不被虚拟机所支持，在编译成字节码阶段就自动转换成简单常用语法。一般来说Java中的语法糖主要有以下几种： 泛型与类型擦除 自动装箱与拆箱，变长参数、 增强for循环 内部类与枚举类 泛型与类型擦除Java语言并不是一开始就支持泛型的。在早期的JDK中，只能通过Object类是所有类型的父类和强制类型转换来实现泛型的功能。强制类型转换的缺点就是把编译期间的问题延迟到运行时，JVM并不能为我们提供编译期间的检查。 在JDK1.5中，Java语言引入了泛型机制。但是这种泛型机制是通过类型擦除来实现的，即Java中的泛型只在程序源代码中有效（源代码阶段提供类型检查），在编译后的字节码中自动用强制类型转换进行替代。也就是说，Java语言中的泛型机制其实就是一颗语法糖，相较与C++、C#相比，其泛型实现实在是不那么优雅。 /** * 在源代码中存在泛型 */ public static void main(String[] args) { Map&lt;String,String&gt; map = new HashMap&lt;String,String&gt;(); map.put(&quot;hello&quot;,&quot;你好&quot;); String hello = map.get(&quot;hello&quot;); System.out.println(hello); } 当上述源代码被编译为class文件后，泛型被擦除且引入强制类型转换 public static void main(String[] args) { HashMap map = new HashMap(); //类型擦除 map.put(&quot;hello&quot;, &quot;你好&quot;); String hello = (String)map.get(&quot;hello&quot;);//强制转换 System.out.println(hello); } 自动装箱与拆箱 Java中的自动装箱与拆箱指的是基本数据类型与他们的包装类型之间的相互转换。 我们知道Java是一门面向对象的语言，在Java世界中有一句话是这么说的：“万物皆对象”。但是Java中的基本数据类型却不是对象，他们不需要进行new操作，也不能调用任何方法，这在使用的时候有诸多不便。因此Java为这些基本类型提供了包装类，并且为了使用方便，提供了自动装箱与拆箱功能。自动装箱与拆箱在使用的过程中，其实是一个语法糖，内部还是调用了相应的函数进行转换。 下面代码演示了自动装箱和拆箱功能 public static void main(String[] args) { Integer a = 1; int b = 2; int c = a + b; System.out.println(c); } 经过编译后，代码如下 public static void main(String[] args) { Integer a = Integer.valueOf(1); // 自动装箱 byte b = 2; int c = a.intValue() + b;//自动拆箱 System.out.println(c); } 变长参数 所谓变长参数，就是方法可以接受长度不定确定的参数 变长参数特性是在JDK1.5中引入的，使用变长参数有两个条件，一是变长的那一部分参数具有相同的类型，二是变长参数必须位于方法参数列表的最后面。变长参数同样是Java中的语法糖，其内部实现是Java数组。 public class Varargs { public static void print(String... args) { for(String str : args){ System.out.println(str); } } public static void main(String[] args) { print(&quot;hello&quot;, &quot;world&quot;); } } 编译为class文件后如下，从中可以很明显的看出变长参数内部是通过数组实现的 public class Varargs { public Varargs() { } public static void print(String... args) { String[] var1 = args; int var2 = args.length; //增强for循环的数组实现方式 for(int var3 = 0; var3 &lt; var2; ++var3) { String str = var1[var3]; System.out.println(str); } } public static void main(String[] args) { //变长参数转换为数组 print(new String[]{&quot;hello&quot;, &quot;world&quot;}); } } 增强for循环 增强for循环与普通for循环相比，功能更强并且代码更简洁 增强for循环的对象要么是一个数组，要么实现了Iterable接口。这个语法糖主要用来对数组或者集合进行遍历，其在循环过程中不能改变集合的大小。 public static void main(String[] args) { String[] params = new String[]{&quot;hello&quot;,&quot;world&quot;}; //增强for循环对象为数组 for(String str : params){ System.out.println(str); } List&lt;String&gt; lists = Arrays.asList(&quot;hello&quot;,&quot;world&quot;); //增强for循环对象实现Iterable接口 for(String str : lists){ System.out.println(str); } } 编译后的class文件为 public static void main(String[] args) { String[] params = new String[]{&quot;hello&quot;, &quot;world&quot;}; String[] lists = params; int var3 = params.length; //数组形式的增强for退化为普通for for(int str = 0; str &lt; var3; ++str) { String str1 = lists[str]; System.out.println(str1); } List var6 = Arrays.asList(new String[]{&quot;hello&quot;, &quot;world&quot;}); Iterator var7 = var6.iterator(); //实现Iterable接口的增强for使用iterator接口进行遍历 while(var7.hasNext()) { String var8 = (String)var7.next(); System.out.println(var8); } } 内部类 内部类就是定义在一个类内部的类 Java语言中之所以引入内部类，是因为有些时候一个类只在另一个类中有用，我们不想让其在另外一个地方被使用。内部类之所以是语法糖，是因为其只是一个编译时的概念，一旦编译完成，编译器就会为内部类生成一个单独的class文件，名为outer$innter.class。 public class Outer { class Inner{ } } 使用javac编译后，生成两个class文件Outer.class和Outer$Inner.class，其中Outer$Inner.class的内容如下： class Outer$Inner { Outer$Inner(Outer var1) { this.this$0 = var1; } } 内部类分为四种：成员内部类、局部内部类、匿名内部类、静态内部类，每一种都有其用法，这里就不介绍了 枚举类型 枚举类型就是一些具有相同特性的类常量 java中类的定义使用class，枚举类的定义使用enum。在Java的字节码结构中，其实并没有枚举类型，枚举类型只是一个语法糖，在编译完成后被编译成一个普通的类。这个类继承java.lang.Enum，并被final关键字修饰。 public enum Fruit { APPLE,ORINGE } 使用jad对编译后的class文件进行反编译后得到 //继承java.lang.Enum并声明为final public final class Fruit extends Enum { public static Fruit[] values() { return (Fruit[])$VALUES.clone(); } public static Fruit valueOf(String s) { return (Fruit)Enum.valueOf(Fruit, s); } private Fruit(String s, int i) { super(s, i); } //枚举类型常量 public static final Fruit APPLE; public static final Fruit ORANGE; private static final Fruit $VALUES[];//使用数组进行维护 static { APPLE = new Fruit(&quot;APPLE&quot;, 0); ORANGE = new Fruit(&quot;ORANGE&quot;, 1); $VALUES = (new Fruit[] { APPLE, ORANGE }); } }","categories":[{"name":"后端","slug":"后端","permalink":"https://jiangxingye.github.io/categories/后端/"}],"tags":[{"name":"java","slug":"java","permalink":"https://jiangxingye.github.io/tags/java/"}]},{"title":"PostgreSQL事务及隔离级别","slug":"PostgreSQL事物及隔离级别","date":"2017-11-08T16:07:33.000Z","updated":"2019-09-02T13:02:59.980Z","comments":true,"path":"2017/11/09/PostgreSQL事物及隔离级别/","link":"","permalink":"https://jiangxingye.github.io/2017/11/09/PostgreSQL事物及隔离级别/","excerpt":"","text":"介绍PostgreSQL中提供了多种数据完整性的保证机制。如：约束、触发器、事务和锁管理等。 事务主要是为了保证一组相关数据库的操作能全部执行成功，从而保证数据的完整性。锁机制主要是控制多个用户对同一数据进行操作，使用锁机制可以解决并发问题。 事务事务是用户对一个数据库操作的一个序列，这些操作要么全做，要么全不做，是一个不可分割的单位。 事务管理的常用语句如下： BEGIN; SQL语句1; SQL语句2; ... COMMIT; 事务块是指包围在BEGIN和COMMIT之间的语句。在PostgreSQL9中，常用的事务块管理语句含义如下： START TRANSACTION：此命令表示开始一个新的事务块.BEGIN：初始化一个事务块。在BEGIN命令后的语句都将在一个事务里面执行，知道遇见COMMIT或ROLLBACK。它和START TRANSACTION是一样的。COMMIT：提交事务。ROLLBACK：事务失败时执行回滚操作。SET TRANSACTION：设置当前事务的特性。对后面的事务没有影响。 事务隔离及并发控制PostgreSQL是一个支持多用户的数据库，当多个用户操作同一数据库时，并发控制要保证所有用户可以高效的访问的同时不破坏数据的完整性。 数据库中数据的并发操作经常发生，而对数据的并发操作会带来下面的一些问题： 脏读一个事务读取了另一个未提交事务写入的数据。 不可重复读一个事务重新读取前面读取过的数据，发现该数据已经被另一个已经提交的事务修改。 幻读一个事务重新执行一个查询，返回符合查询条件的行的集合，发现满足查询条件的行的集合因为其它最近提交的事务而发生了改变。 SQL标准定义了四个级别的事务隔离。 隔离级别 脏读 幻读 不可重复性读取 读未提交 可能 可能 可能 读已提交 不可能 可能 可能 可重复读 不可能 可能 不可能 可串行读 不可能 不可能 不可能 在PostgreSQL中，可以请求4种隔离级别中的任意一种。但是在内部，实际上只有两种独立的隔离级别，分别对应已提交和可串行化。如果选择了读未提交的级别，实际上使用的是读已提交，在选择可重复读级别的时候，实际上用的是可串行化，所以实际的隔离级别可能比选择的更严格。这是SQL标准允许的：4种隔离级别只定义了哪种现象不能发生，但是没有定义哪种现象一定发生。 PostgreSQL只提供两种隔离级别的原因是，这是把标准的隔离级别与多版本并发控制架构映射相关的唯一合理方法。 读已提交这是PostgreSQL中默认的隔离级别，当一个事务运行在这个隔离级别时，一个SELECT查询只能看到查询开始前已提交的数据，而无法看到未提交的数据或者在查询期间其他的事务已提交的数据。 可串行化可串行化提供最严格的事务隔离。这个级别模拟串行的事务执行，就好像事务是一个接着一个串行的执行。不过，这个级别的应用必须准备在串行化失败的时候重新启动事务。","categories":[{"name":"数据库","slug":"数据库","permalink":"https://jiangxingye.github.io/categories/数据库/"}],"tags":[{"name":"PostgreSQL","slug":"PostgreSQL","permalink":"https://jiangxingye.github.io/tags/PostgreSQL/"}]},{"title":"[转]字符编解码的故事（ASCII，ANSI，Unicode，Utf-8区别）","slug":"ascii-ansi-unicode-utf-8）","date":"2017-09-25T11:15:00.000Z","updated":"2019-09-02T13:03:00.032Z","comments":true,"path":"2017/09/25/ascii-ansi-unicode-utf-8）/","link":"","permalink":"https://jiangxingye.github.io/2017/09/25/ascii-ansi-unicode-utf-8）/","excerpt":"","text":"很久很久以前，有一群人，他们决定用8个可以开合的晶体管来组合成不同的状态，以表示世界上的万物。他们认为8个开关状态作为原子单位很好，于是他们把这称为”字节”。 再后来，他们又做了一些可以处理这些字节的机器，机器开动了，可以用字节来组合出更多的状态，状态开始变来变去。他们看到这样是好的，于是它们就这机器称为”计算机”。 开始计算机只在美国用。八位的字节一共可以组合出256（2的8次方）种不同的状态。 他们把其中的编号从0开始的32种状态分别规定了特殊的用途，一但终端设备或者打印机遇上这些约定好的字节时，就要做一些约定的动作。遇上 00x10, 终端就换行，遇上0x07, 终端就向人们嘟嘟叫，例好遇上0x1b, 打印机就打印反白的字，对于终端就用彩色显示字母。他们看到这样很好，于是就把这些0x20（十进制32）以下的字节状态称为”控制码”。 他们又把所有的空格、标点符号、数字、大小写字母分别用连续的字节状态表示，一直编到了第127号，这样计算机就可以用不同字节来存储英语的 文字了。大家看到这样，都感觉很好，于是大家都把这个方案叫做 ANSI 的”Ascii”编码（American Standard Code for Information Interchange，美国信息互换标准代码）。当时世界上所有的计算机都用同样的ASCII方案来保存英文文字。 后来，就像建造巴比伦塔一样，世界各地的都开始使用计算机，但是很多国家用的不是英文，他们用到的许多字母在ASCII中根本没有，为了也可以在计算机中保存他们的文字，他们决定采用127号之后的空位来表示这些新的字母、符号，还加入了很多画表格时需要用下到的横线、竖线、交叉等形状，一直把序号编到了最后一个状态255。从128到255这一页的字符集被称”扩展字符集”。从此之后，贪婪的人类再没有新的状态可以用了，美帝国主义可能没有想到还有第三世界国家的人们也希望可以用到计算机吧！ 等中国人们得到计算机时，已经没有可以利用的字节状态来表示汉字，况且有6000多个常用汉字需要保存呢。但是这难不倒智慧的中国人民，我们不客气地把那些127号之后的奇异符号们直接取消掉，并且规定：一个小于127的字符的意义与原来相同，但两个大于127的字符连在一起时，就表示一个汉字，前面的一个字节（他称之为高字节）从0xA1用到 0xF7，后面一个字节（低字节）从0xA1到0xFE，这样我们就可以组合出大约7000多个简体汉字了。在这些编码里，我们还把数学符号、罗马希腊的字母、日文的假名们都编进去了，连在 ASCII 里本来就有的数字、标点、字母都统统重新编了两个字节长的编码，这就是常说的”全角”字符，而原来在127号以下的那些就叫”半角”字符了。 中国人民看到这样很不错，于是就把这种汉字方案叫做”GB2312”。GB2312 是对 ASCII 的中文扩展。 但是中国的汉字太多了，我们很快就就发现有许多人的人名没有办法在这里打出来，特别是某些很会麻烦别人的国家领导人（如朱镕基的“镕”字）。于是我们不得不继续把 GB2312 没有用到的码位找出来老实不客气地用上。 后来还是不够用，于是干脆不再要求低字节一定是127号之后的内码，只要第一个字节是大于127就固定表示这是一个汉字的开始，不管后面跟的是不是扩展字符集里的内容。结果扩展之后的编码方案被称为 GBK 标准，GBK 包括了 GB2312 的所有内容，同时又增加了近20000个新的汉字（包括繁体字）和符号。 后来少数民族也要用电脑了，于是我们再扩展，又加了几千个新的少数民族的字，GBK 扩成了 GB18030。从此之后，中华民族的文化就可以在计算机时代中传承了。 中国的程序员们看到这一系列汉字编码的标准是好的，于是通称他们叫做 “DBCS”（Double Byte Charecter Set 双字节字符集）。在DBCS系列标准里，最大的特点是两字节长的汉字字符和一字节长的英文字符并存于同一套编码方案里，因此他们写的程序为了支持中文处理，必须要注意字串里的每一个字节的值，如果这个值是大于127的，那么就认为一个双字节字符集里的字符出现了。那时候凡是受过加持，会编程的计算机僧侣们都要每天念下面这个咒语数百遍： “一个汉字算两个英文字符！一个汉字算两个英文字符……” 因为当时各个国家都像中国这样搞出一套自己的编码标准，结果互相之间谁也不懂谁的编码，谁也不支持别人的编码，连大陆和台湾这样只相隔了150海里，使用着同一种语言的兄弟地区，也分别采用了不同的 DBCS 编码方案——当时的中国人想让电脑显示汉字，就必须装上一个”汉字系统”，专门用来处理汉字的显示、输入的问题，但是那个台湾的愚昧封建人士写的算命程序就必须加装另一套支持 BIG5 编码的什么”倚天汉字系统”才可以用，装错了字符系统，显示就会乱了套！这怎么办？而且世界民族之林中还有那些一时用不上电脑的穷苦人民，他们的文字又怎么办？ 真是计算机的巴比伦塔命题啊！ 正在这时，大天使加百列及时出现了——一个叫 ISO （国际标谁化组织）的国际组织决定着手解决这个问题。他们采用的方法很简单：废了所有的地区性编码方案，重新搞一个包括了地球上所有文化、所有字母和符号的编码！他们打算叫它”Universal Multiple-Octet Coded Character Set”，简称 UCS, 俗称 “UNICODE”。 UNICODE 开始制订时，计算机的存储器容量极大地发展了，空间再也不成为问题了。于是 ISO 就直接规定必须用两个字节，也就是16位来统一表示所有的字符，对于ascii里的那些”半角”字符，UNICODE 包持其原编码不变，只是将其长度由原来的8位扩展为16位，而其他文化和语言的字符则全部重新统一编码。由于”半角”英文符号只需要用到低8位，所以其高 8位永远是0，因此这种大气的方案在保存英文文本时会多浪费一倍的空间。 这时候，从旧社会里走过来的程序员开始发现一个奇怪的现象：他们的strlen函数靠不住了，一个汉字不再是相当于两个字符了，而是一个！是 的，从 UNICODE 开始，无论是半角的英文字母，还是全角的汉字，它们都是统一的”一个字符”！同时，也都是统一的”两个字节”，请注意”字符”和”字节”两个术语的不同， “字节”是一个8位的物理存贮单元，而”字符”则是一个文化相关的符号。在UNICODE 中，一个字符就是两个字节。一个汉字算两个英文字符的时代已经快过去了。 从前多种字符集存在时，那些做多语言软件的公司遇上过很大麻烦，他们为了在不同的国家销售同一套软件，就不得不在区域化软件时也加持那个双字节字符集咒语，不仅要处处小心不要搞错，还要把软件中的文字在不同的字符集中转来转去。UNICODE 对于他们来说是一个很好的一揽子解决方案，于是从 Windows NT 开始，MS 趁机把它们的操作系统改了一遍，把所有的核心代码都改成了用 UNICODE 方式工作的版本，从这时开始，WINDOWS 系统终于无需要加装各种本土语言系统，就可以显示全世界上所有文化的字符了。 但是，UNICODE 在制订时没有考虑与任何一种现有的编码方案保持兼容，这使得 GBK 与UNICODE 在汉字的内码编排上完全是不一样的，没有一种简单的算术方法可以把文本内容从UNICODE编码和另一种编码进行转换，这种转换必须通过查表来进行。 如前所述，UNICODE 是用两个字节来表示为一个字符，他总共可以组合出65535不同的字符，这大概已经可以覆盖世界上所有文化的符号。如果还不够也没有关系，ISO已经准备了UCS-4方案，说简单了就是四个字节来表示一个字符，这样我们就可以组合出21亿个不同的字符出来（最高位有其他用途），这大概可以用到银河联邦成立那一天吧！ UNICODE 来到时，一起到来的还有计算机网络的兴起，UNICODE 如何在网络上传输也是一个必须考虑的问题，于是面向传输的众多 UTF（UCS Transfer Format）标准出现了，顾名思义，UTF8就是每次8个位传输数据，而UTF16就是每次16个位，只不过为了传输时的可靠性，从UNICODE到 UTF时并不是直接的对应，而是要过一些算法和规则来转换。 受到过网络编程加持的计算机僧侣们都知道，在网络里传递信息时有一个很重要的问题，就是对于数据高低位的解读方式，一些计算机是采用低位先发送的方法，例如我们PC机采用的 INTEL 架构；而另一些是采用高位先发送的方式。在网络中交换数据时，为了核对双方对于高低位的认识是否是一致的，采用了一种很简便的方法，就是在文本流的开始时向对方发送一个标志符——如果之后的文本是高位在位，那就发送”FEFF”，反之，则发送”FFFE”。不信你可以用二进制方式打开一个UTF-X格式的文件，看看开头两个字节是不是这两个字节？ 下面是Unicode和UTF-8转换的规则 Unicode UTF-8 0000 - 007F 0xxxxxxx 0080 - 07FF 110xxxxx 10xxxxxx 0800 - FFFF 1110xxxx 10xxxxxx 10xxxxxx 例如”汉”字的Unicode编码是6C49。6C49在0800-FFFF之间，所以要用3字节模板：1110xxxx 10xxxxxx 10xxxxxx。将6C49写成二进制是：0110 1100 0100 1001，将这个比特流按三字节模板的分段方法分为0110 110001 001001，依次代替模板中的x，得到：1110-0110 10-110001 10-001001，即E6 B1 89，这就是其UTF8的编码。 讲到这里，我们再顺便说说一个很著名的奇怪现象：当你在 windows 的记事本里新建一个文件，输入”联通”两个字之后，保存，关闭，然后再次打开，你会发现这两个字已经消失了，代之的是几个乱码！呵呵，有人说这就是联通之所以拼不过移动的原因。 其实这是因为GB2312编码与UTF8编码产生了编码冲撞的原因。 当一个软件打开一个文本时，它要做的第一件事是决定这个文本究竟是使用哪种字符集的哪种编码保存的。软件一般采用三种方式来决定文本的字符集和编码： 检测文件头标识，提示用户选择，根据一定的规则猜测 最标准的途径是检测文本最开头的几个字节，开头字节 Charset/encoding,如下表： EF BB BF UTF-8 FF FE UTF-16/UCS-2, little endian FE FF UTF-16/UCS-2, big endian FF FE 00 00 UTF-32/UCS-4, little endian. 00 00 FE FF UTF-32/UCS-4, big-endian. 当你新建一个文本文件时，记事本的编码默认是ANSI（代表系统默认编码，在中文系统中一般是GB系列编码）, 如果你在ANSI的编码输入汉字，那么他实际就是GB系列的编码方式，在这种编码下，”联通”的内码是： c1 1100 0001 aa 1010 1010 cd 1100 1101 a8 1010 1000 注意到了吗？第一二个字节、第三四个字节的起始部分的都是”110”和”10”，正好与UTF8规则里的两字节模板是一致的， 于是当我们再次打开记事本时，记事本就误认为这是一个UTF8编码的文件，让我们把第一个字节的110和第二个字节的10去掉，我们就得到了”00001 101010”，再把各位对齐，补上前导的0，就得到了”0000 0000 0110 1010”，不好意思，这是UNICODE的006A，也就是小写的字母”j”，而之后的两字节用UTF8解码之后是0368，这个字符什么也不是。这就是只有”联通”两个字的文件没有办法在记事本里正常显示的原因。 而如果你在”联通”之后多输入几个字，其他的字的编码不见得又恰好是110和10开始的字节，这样再次打开时，记事本就不会坚持这是一个utf8编码的文件，而会用ANSI的方式解读之，这时乱码又不出现了。","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"encoding","slug":"encoding","permalink":"https://jiangxingye.github.io/tags/encoding/"}]},{"title":"搭建dubbo+zookeeper平台","slug":"搭建dubbo+zookeeper平台","date":"2017-09-25T08:29:07.000Z","updated":"2019-09-02T13:02:59.977Z","comments":true,"path":"2017/09/25/搭建dubbo+zookeeper平台/","link":"","permalink":"https://jiangxingye.github.io/2017/09/25/搭建dubbo+zookeeper平台/","excerpt":"","text":"前言本文将介绍在SpringMVC+Spring+Mybatis项目中添加 dubbo 作为 rpc 服务。 文末有项目代码地址。 一.搭建zookeeper使用 docker 一句话创建： docker run -dit --name zookeeper --hostname zookeeper-host -v /data:/data -p 2181:2181 jplock/zookeeper:latest 二.安装zkui（非必须）这个项目为 zookeeper 提供一个 web 的管理界面。当然我们也可以直接在zookeeper中使用命令查看，所以此步骤可以忽略 在开始前需要安装 Java 环境、Maven 环境。 到 zkui 的项目中下载代码。git clone https://github.com/DeemOpen/zkui.git 执行 mvn clean install 生成jar文件。 将config.cfg复制到上一步生成的jar文件所在目录，然后修改配置文件中的zookeeper地址。 执行 nohup java -jar zkui-2.0-SNAPSHOT-jar-with-dependencies.jar &amp; 测试 http://localhost:9090，如果能看到如下页面，表示安装成功。 三.使用dubbo 在原来 SpringMVC+Spring+Mybatis 项目中，除了原来 spring 相关依赖外，还需要加入以下依赖&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;dubbo&lt;/artifactId&gt; &lt;version&gt;2.5.5&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;3.4.9&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.101tec&lt;/groupId&gt; &lt;artifactId&gt;zkclient&lt;/artifactId&gt; &lt;version&gt;0.2&lt;/version&gt; &lt;/dependency&gt; 定义服务接口public interface IPersonService { List&lt;Person&gt; listAll(); Person getById(Integer id); Integer delById(Person person); Integer updatePerson(Person person); } 定义服务实现类 @Service public class PersonService implements IPersonService { @Autowired PersonMapper personMapper; public List&lt;Person&gt; listAll() { return personMapper.findAll(); } public Person getById(Integer id) { return personMapper.findOneById(id); } public Integer delById(Person person) { return personMapper.del(person); } public Integer updatePerson(Person person) { return personMapper.update(person); } } 配置生产者，注册服务信息 &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;beans xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:dubbo=&quot;http://code.alibabatech.com/schema/dubbo&quot; xmlns=&quot;http://www.springframework.org/schema/beans&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-2.5.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd&quot;&gt; &lt;!--定义了提供方应用信息，用于计算依赖关系；--&gt; &lt;dubbo:application name=&quot;demotest-provider&quot; /&gt; &lt;!-- 使用 zookeeper 注册中心暴露服务地址 --&gt; &lt;dubbo:registry address=&quot;zookeeper://192.168.0.86:2181&quot;/&gt; &lt;!-- 用dubbo协议在20880端口暴露服务 --&gt; &lt;dubbo:protocol name=&quot;dubbo&quot; port=&quot;20880&quot;/&gt; &lt;!-- 和本地bean一样实现服务 --&gt; &lt;bean id=&quot;personService&quot; class=&quot;com.ssm.service.PersonService&quot;/&gt; &lt;!-- 声明需要暴露的服务接口 --&gt; &lt;dubbo:service interface=&quot;com.ssm.iservice.IPersonService&quot; ref=&quot;personService&quot;/&gt; &lt;/beans&gt; 配置消费者，订阅服务 &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;beans xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:dubbo=&quot;http://code.alibabatech.com/schema/dubbo&quot; xmlns=&quot;http://www.springframework.org/schema/beans&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-2.5.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd&quot;&gt; &lt;!-- 消费方应用名，用于计算依赖关系，不是匹配条件，不要与提供方一样 --&gt; &lt;dubbo:application name=&quot;demo-consumer&quot;/&gt; &lt;!-- 使用 zookeeper 注册中心暴露发现服务地址 --&gt; &lt;dubbo:registry address=&quot;zookeeper://192.168.0.86:2181&quot;/&gt; &lt;!-- 生成远程服务代理，可以和本地bean一样使用demoService --&gt; &lt;dubbo:reference id=&quot;personService&quot; check=&quot;false&quot; interface=&quot;com.ssm.iservice.IPersonService&quot;/&gt; &lt;/beans&gt; 调用远程服务配置完成后，我们就可以像使用本地 bean 一样，使用 rpc 的 service； @Controller public class IndexController { @Autowired IPersonService personService; @RequestMapping(&quot;/index.html&quot;) public String index(Model model) { RpcContext.getContext().setAttachment(&quot;index&quot;, &quot;1&quot;);//测试ThreadLocal List&lt;Person&gt; list = personService.listAll(); model.addAttribute(&quot;command&quot;,list); return &quot;index&quot;; } } 最后至此，单机运行的 rpc 服务已搭建完成。 代码传送文 ssm","categories":[{"name":"后端","slug":"后端","permalink":"https://jiangxingye.github.io/categories/后端/"}],"tags":[{"name":"dubbo","slug":"dubbo","permalink":"https://jiangxingye.github.io/tags/dubbo/"},{"name":"zookeeper","slug":"zookeeper","permalink":"https://jiangxingye.github.io/tags/zookeeper/"}]},{"title":"docker报错集锦","slug":"docker-errors","date":"2017-09-25T02:03:50.000Z","updated":"2019-09-02T13:02:59.997Z","comments":true,"path":"2017/09/25/docker-errors/","link":"","permalink":"https://jiangxingye.github.io/2017/09/25/docker-errors/","excerpt":"","text":"docker创建容器1. iptables failed创建 tale 容器时，如下命令： docker run -d --privileged --hostname tale --name tale \\ -v /etc/localtime:/etc/localtime:ro \\ -v /home/tale:/var/tale_home -p 127.0.0.1:234:9000 \\ -m 1024m --memory-swap -1 tale:1.0 然后就报了以下错误： docker: Error response from daemon: driver failed programming external connectivity on endpoint tale (263775ff559176224428ec44dcec416a1c20e6c69198d9760b38f35849914260): iptables failed: iptables --wait -t nat -A DOCKER -p tcp -d 127.0.0.1 --dport 234 -j DNAT --to-destination 172.17.0.4:9000 ! -i docker0: iptables: No chain/target/match by that name. (exit status 1). 解决办法：重启 docker 服务： $ service docker restart","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://jiangxingye.github.io/tags/docker/"}]},{"title":"[转]浏览器前进/后退缓存（BF Cache）","slug":"bf-cache","date":"2017-09-21T07:35:24.000Z","updated":"2019-09-02T13:02:59.991Z","comments":true,"path":"2017/09/21/bf-cache/","link":"","permalink":"https://jiangxingye.github.io/2017/09/21/bf-cache/","excerpt":"","text":"浏览器前进/后退缓存（Backward/Forward Cache，BF Cache）是指浏览器在前进后退过程中， 会应用更强的缓存策略，表现为 DOM、window、甚至 JavaScript 对象被缓存，以及同步 XHR 也被缓存。 这一现象在移动端浏览器尤为常见，除 Chrome for Android、Android Browser 之外的浏览器基本都会触发。 BF Cache 本来是一项浏览器优化，但在某些情况下（比如前端路由的 Web App）会引起困惑。 本文主要讨论 BF Cache 的行为、如何检测 BF Cache 缓存、以及如何 workaround。 缓存行为BF Cache 是一种浏览器优化，HTML 标准并未指定其如何进行缓存，因此缓存行为是与浏览器实现相关的。 User agents may discard the Document objects of entries other than the current entry that are not referenced from any script, reloading the pages afresh when the user or script navigates back to such pages. This specification does not specify when user agents should discard Document objects and when they should cache them. – Session history and navigation, WHATWG Desktop Chrome：阻塞的资源和同步发出的 XHR 都会被缓存，但不缓存渲染结果。因此可以看到明显的载入过程，此时脚本也会重新执行。 Chrome for Android：有些情况下不会缓存，缓存时与 Desktop Chrome 行为一致。 Desktop Firefox：页面会被 Frozen，定时器会被暂停，DOM、Window、JavaScript 对象会被缓存，返回时页面脚本重新开始运行。 iOS Safari：渲染结果也会被缓存，因此才能支持左右滑动手势来前进/后退。 Desktop Firefox 暂停计时器的行为非常有趣，以下 HTML 中显示一个每秒加一的数字。 当页面导航时就会暂停，返回时继续增加（因此直接使用 setInterval 倒计时不仅不精确，而且不可靠）： &lt;span id=&quot;timer-tick&quot;&gt;&lt;/span&gt; &lt;a href=&quot;http://harttle.com&quot;&gt;External Link&lt;/a&gt; &lt;script&gt; var i = 0 setInterval(() =&gt; document.querySelector(&#39;#timer-tick&#39;).innerHTML = i++, 1000) &lt;/script&gt; pagehide/pageshow 事件会话（Session）中的某一个页面显示/隐藏时，会触发 pagehide 和 pageshow 事件。 这两个事件都有一个 persisted 属性用来指示当前页面是否被 BF Cache 缓存。 因此可以通过 persisted 属性来达到禁用 BF Cache 的效果： window.onpageshow = function(event) { if (event.persisted) { window.location.reload() } }; 注意无论页面是否被缓存 pageshow 总会触发，因此需要检测器 persisted 属性。 另外 pageshow 的时机总是在 load 事件之后。 这一点很容易检测，下面的 pageshow 日志总在 load 之前： window.addEventListener(&#39;pageshow&#39;, function () { console.log(&#39;on pageshow&#39;) }) window.addEventListener(&#39;load&#39;, function () { console.log(&#39;load&#39;) }) XHR 缓存同步（阻塞加载的）脚本发出的 XMLHttpRequest 也会被 Chrome 强制缓存， 因此即使在断网的情况下后退到访问过的页面仍然是可以完美渲染的。 如果页面中有这样一段外部脚本： sendXHR(); function sendXHR () { var xhr = new XMLHttpRequest() xhr.open(&#39;GET&#39;, &#39;/data.json&#39;) xhr.onreadystatechange = function () { if (xhr.readyState === XMLHttpRequest.DONE &amp;&amp; xhr.status === 200) { console.log(&#39;xhr arrived&#39;, xhr.responseText) } } xhr.send() } 超链接跳转后回来，该 xhr 也会被缓存。注意下图中的 XHR 一项 size 为 “from disk cache”： 为了强制发送 xhr，可以将 xhr 改为异步发送，或者加一个不重要的 query。 setTimeout(sendXHR, 1000) 这样就能看到 xhr 真正发送出去了 :) 异步 xhr 缓存时机未经兼容性测试， 还是建议读者使用一个随机产生的 query。","categories":[{"name":"大前端","slug":"大前端","permalink":"https://jiangxingye.github.io/categories/大前端/"}],"tags":[{"name":"js","slug":"js","permalink":"https://jiangxingye.github.io/tags/js/"},{"name":"浏览器","slug":"浏览器","permalink":"https://jiangxingye.github.io/tags/浏览器/"}]},{"title":"解决iphone下后退不执行js的问题","slug":"iphone-bf-no-run-js","date":"2017-09-21T07:25:32.000Z","updated":"2019-09-02T13:02:59.991Z","comments":true,"path":"2017/09/21/iphone-bf-no-run-js/","link":"","permalink":"https://jiangxingye.github.io/2017/09/21/iphone-bf-no-run-js/","excerpt":"","text":"直接上解决方法不论页面是否被缓存，都会触发 pageshow，所以后退后需要执行的方法可以都放在下面事件内： window.addEventListener(&#39;pageshow&#39;, function () { console.log(&#39;on pageshow&#39;) }) 浏览器缓存行为 的详细介绍可以参考： [转]浏览器前进/后退缓存（BF Cache）","categories":[{"name":"大前端","slug":"大前端","permalink":"https://jiangxingye.github.io/categories/大前端/"}],"tags":[{"name":"js","slug":"js","permalink":"https://jiangxingye.github.io/tags/js/"}]},{"title":"CentOS7使用Firewalld","slug":"CentOS7使用Firewalld","date":"2017-09-19T01:53:53.000Z","updated":"2019-09-02T13:02:59.992Z","comments":true,"path":"2017/09/19/CentOS7使用Firewalld/","link":"","permalink":"https://jiangxingye.github.io/2017/09/19/CentOS7使用Firewalld/","excerpt":"","text":"介绍FirewallD 提供了支持网络/防火墙区域(zone)定义网络链接以及接口安全等级的动态防火墙管理工具。它支持 IPv4, IPv6 防火墙设置以及以太网桥接，并且拥有运行时配置和永久配置选项。它也支持允许服务或者应用程序直接添加防火墙规则的接口。 安装$ yum install firewalld # 如果需要图形界面的话，则再安装 $ yum install firewall-config zoneFirewall 能将不同的网络连接归类到不同的信任级别。 $ firewall-cmd --list-all-zones #查看所有zone信息 Zone 提供了以下几个级别： drop: 丢弃所有进入的包，而不给出任何响应 block: 拒绝所有外部发起的连接，允许内部发起的连接 public: 允许指定的进入连接 external: 同上，对伪装的进入连接，一般用于路由转发 dmz: 允许受限制的进入连接 work: 允许受信任的计算机被限制的进入连接，类似 workgroup home: 同上，类似 homegroup internal: 同上，范围针对所有互联网用户 trusted: 信任所有连接 过滤规则 source: 根据源地址过滤 interface: 根据网卡过滤 service: 根据服务名过滤 port: 根据端口过滤 icmp-block: icmp 报文过滤，按照 icmp 类型配置 masquerade: ip 地址伪装 forward-port: 端口转发 rule: 自定义规则 过滤规则的优先级遵循如下顺序 source interface firewalld.conf 使用$ systemctl start firewalld # 启动 $ systemctl stop firewalld # 关闭 $ systemctl enable firewalld # 开机启动 $ systemctl disable firewalld # 取消开机启动 具体的规则管理，可以使用 firewall-cmd,具体的使用方法 $ firewall-cmd --help --zone=NAME # 指定 zone --permanent # 永久修改，--reload 后生效 --timeout=seconds # 持续效果，到期后自动移除，用于调试，不能与 --permanent 同时使用 查看规则查看运行状态 $ firewall-cmd --state 查看已被激活的 Zone 信息 $ firewall-cmd --get-active-zones public interfaces: eth0 eth1 查看指定接口的 Zone 信息 $ firewall-cmd --get-zone-of-interface=eth0 public 查看指定级别的接口 $ firewall-cmd --zone=public --list-interfaces eth0 查看指定级别的所有信息，譬如 public $ firewall-cmd --zone=public --list-all public (default, active) interfaces: eth0 sources: services: dhcpv6-client http ssh ports: masquerade: no forward-ports: icmp-blocks: rich rules: 查看所有级别被允许的信息 $ firewall-cmd --get-service 查看重启后所有 Zones 级别中被允许的服务，即永久放行的服务 $ firewall-cmd --get-service --permanent 管理规则$ firewall-cmd --panic-on # 丢弃 $ firewall-cmd --panic-off # 取消丢弃 $ firewall-cmd --query-panic # 查看丢弃状态 $ firewall-cmd --reload # 更新规则，不重启服务 $ firewall-cmd --complete-reload # 更新规则，重启服务 添加某接口至某信任等级，譬如添加 eth0 至 public，永久修改 $ firewall-cmd --zone=public --add-interface=eth0 --permanent 设置 public 为默认的信任级别 $ firewall-cmd --set-default-zone=public a. 管理端口列出 dmz 级别的被允许的进入端口 $ firewall-cmd --zone=dmz --list-ports 允许 tcp 端口 8080 至 dmz 级别 $ firewall-cmd --zone=dmz --add-port=8080/tcp 允许某范围的 udp 端口至 public 级别，并永久生效 $ firewall-cmd --zone=public --add-port=5060-5059/udp --permanent b. 网卡接口列出 public zone 所有网卡 $ firewall-cmd --zone=public --list-interfaces 将 eth0 添加至 public zone，永久 $ firewall-cmd --zone=public --permanent --add-interface=eth0 eth0 存在与 public zone，将该网卡添加至 work zone，并将之从 public zone 中删除 $ firewall-cmd --zone=work --permanent --change-interface=eth0 删除 public zone 中的 eth0，永久 $ firewall-cmd --zone=public --permanent --remove-interface=eth0 c. 管理服务添加 smtp 服务至 work zone $ firewall-cmd --zone=work --add-service=smtp 移除 work zone 中的 smtp 服务 $ firewall-cmd --zone=work --remove-service=smtp d. 配置 external zone 中的 ip 地址伪装查看 $ firewall-cmd --zone=external --query-masquerade 打开伪装 $ firewall-cmd --zone=external --add-masquerade 关闭伪装 $ firewall-cmd --zone=external --remove-masquerade e. 配置 public zone 的端口转发要打开端口转发，则需要先 $ firewall-cmd --zone=public --add-masquerade 然后转发 tcp 22 端口至 3753 $ firewall-cmd --zone=public --add-forward-port=port=22:proto=tcp:toport=3753 转发 22 端口数据至另一个 ip 的相同端口上 $ firewall-cmd --zone=public --add-forward-port=port=22:proto=tcp:toaddr=192.168.1.100 转发 22 端口数据至另一 ip 的 2055 端口上 $ firewall-cmd --zone=public --add-forward-port=port=22:proto=tcp:toport=2055:toaddr=192.168.1.100 f. 配置 public zone 的 icmp查看所有支持的 icmp 类型 $ firewall-cmd --get-icmptypes destination-unreachable echo-reply echo-request parameter-problem redirect router-advertisement router-solicitation source-quench time-exceeded 列出 $ firewall-cmd --zone=public --list-icmp-blocks 添加 echo-request 屏蔽 $ firewall-cmd --zone=public --add-icmp-block=echo-request [--timeout=seconds] 移除 echo-reply 屏蔽 $ firewall-cmd --zone=public --remove-icmp-block=echo-reply g. IP 封禁 $ firewall-cmd --permanent --add-rich-rule=&quot;rule family=&#39;ipv4&#39; source address=&#39;222.222.222.222&#39; reject&quot; 当然，我们仍然可以通过 ipset 来封禁 ip 封禁 ip $ firewall-cmd --permanent --zone=public --new-ipset=blacklist --type=hash:ip $ firewall-cmd --permanent --zone=public --ipset=blacklist --add-entry=222.222.222.222 封禁网段 $ firewall-cmd --permanent --zone=public --new-ipset=blacklist --type=hash:net $ firewall-cmd --permanent --zone=public --ipset=blacklist --add-entry=222.222.222.0/24 倒入 ipset 规则 $ firewall-cmd --permanent --zone=public --new-ipset-from-file=/path/blacklist.xml 然后封禁 blacklist $ firewall-cmd --permanent --zone=public --add-rich-rule=&#39;rule source ipset=blacklist drop&#39; 重新载入以生效 $ firewall-cmd --reload","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"firewall","slug":"firewall","permalink":"https://jiangxingye.github.io/tags/firewall/"}]},{"title":"docker备份恢复之save与export","slug":"docker-save-export","date":"2017-09-18T14:38:52.000Z","updated":"2019-09-02T13:02:59.994Z","comments":true,"path":"2017/09/18/docker-save-export/","link":"","permalink":"https://jiangxingye.github.io/2017/09/18/docker-save-export/","excerpt":"","text":"docker save导出docker save 命令用于持久化 镜像，先获得镜像名称，再执行保存： # 通过此命令查出要持久化的镜像名称 $ docker images # 持久化镜像名为 image_name 的镜像， $ docker save image_name -o ~/save.tar 注意： 如果镜像是在远程仓库，执行保存镜像的时候可能会报 Cowardly refusing to save to a terminal. Use the -o flag or redirect. 的错，可以通过 docker save image_name &gt; image_name.tar 将镜像从远程仓库持久化到本地。 导入# 导入 save.tar $ docker load &lt; ~/save.tar # 查看镜像 $ docker images images docker export导出docker export 命令用于持久化 容器，先获取容器ID，再执行保存。 # 通过此命令查出要持久化的容器ID $ docker ps -a # 持久化容器id为 container_id 的容器 $ docker export container_id &gt; ~/export.tar 导入# 从 export.tar 导入镜像 $ cat ~/export.tar | docker import - my-images:latest # 查看镜像 $ sudo docker images 不同通过 sudo docker images --tree 可以查看到镜像的所有层，就会发现， docker export 丢失了所有的历史，而docker save 则会保存所有历史。","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://jiangxingye.github.io/tags/docker/"}]},{"title":"sudo命令免密码设置","slug":"sudo命令免密码设置","date":"2017-09-11T01:30:55.000Z","updated":"2019-09-02T13:02:59.999Z","comments":true,"path":"2017/09/11/sudo命令免密码设置/","link":"","permalink":"https://jiangxingye.github.io/2017/09/11/sudo命令免密码设置/","excerpt":"","text":"如果某台linux只有自己在使用，比如个人系统，每次调用 sudo 时都需要输入密码，长期下来着实厌烦，因此本文介绍如何配置 sudo 命令，使其在运行时不需要输入密码。 步骤 执行命令 $ sudo visudo 添加以下两行， 下面的 sys 表示 sys 组成员不用密码使用sudo aaronkilik ALL=(ALL) NOPASSWD: ALL %sys ALL=(ALL) NOPASSWD: ALL 现在在使用 sudo 命令， 将不再需要输入密码。 扩展如果只允许用户使用 kill 和 rm 命令时，不需要输入密码，见如下配置 %sys ALL=(ALL) NOPASSWD: /bin/kill, /bin/rm","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://jiangxingye.github.io/tags/linux/"}]},{"title":"搭建Maven私服-Nexus","slug":"build-Maven-Nexus","date":"2017-09-06T15:01:31.000Z","updated":"2019-09-02T13:03:00.000Z","comments":true,"path":"2017/09/06/build-Maven-Nexus/","link":"","permalink":"https://jiangxingye.github.io/2017/09/06/build-Maven-Nexus/","excerpt":"","text":"Maven 私服，可以代理远程仓库和部署自己或第三方构件。本文介绍使用最广泛搭建 Maven 私服的工具： Sonatype Nexus。 作者环境 本次搭建私服是在局域网的一台服务器上，操作系统为 CentOS 。 需要部署到私服的项目 soul ssm 项目需要引用 soul 安装Java 确保服务器已经安装了 java 环境，这个过程不是本文重点，安装过程自行百度。 安装Nexus 官网 pro 版本的是需要付费的。所以我们使用免费的 OSS 版本，下载地址 (https://www.sonatype.com/download-oss-sonatype) # 上传到服务器并解压 $ tar xvf nexus-3.5.1-02-unix.tar.gz 启动Nexus# 启动服务 $ cd /nexus-3.5.1-02/bin/ $ ./nexus start 验证打开网址：(http://192.168.0.86:8081/) , ip 为搭建私服的服务器 ip 。用户名/密码： admin/admin123出现一下画面，就说明安装成功了。 发布soul项目到私服创建仓库 创建yelog-release仓库（名字自定义）, type选择 ： release 创建yelog-snapshot仓库（名字自定义）， type选择 ： snapshot重复上面 ① 和 ② 步，根据下图选择类型: 两个都创建完成后，效果如下： pom中添加部署配置url 复制上图中新建的仓库的 copy 按钮，复制url。 &lt;distributionManagement&gt; &lt;repository&gt; &lt;id&gt;yelog-release&lt;/id&gt; &lt;name&gt;Release Repository of yelog&lt;/name&gt; &lt;url&gt;http://192.168.0.86:8081/repository/yelog-release/&lt;/url&gt; &lt;/repository&gt; &lt;snapshotRepository&gt; &lt;id&gt;yelog-snapshot&lt;/id&gt; &lt;name&gt;Snapshot Repository of yelog&lt;/name&gt; &lt;url&gt;http://192.168.0.86:8081/repository/yelog-snapshot/&lt;/url&gt; &lt;/snapshotRepository&gt; &lt;/distributionManagement&gt; 在maven的 settings.xml 中配置这里配置 maven 的账号密码，id 要与 distributionManagement 中的id一致。默认账号/密码：admin/admin123 &lt;servers&gt; &lt;server&gt; &lt;id&gt;yelog-realease&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt; &lt;/server&gt; &lt;server&gt; &lt;id&gt;yelog-snapshot&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt; &lt;/server&gt; &lt;/servers&gt; 执行maven命令部署项目到私服上我这里直接使用IDE的插件执行部署完成后，可以在 yelog-snapshot 仓库中，查看部署的情况，如下图所示 从私服拉去依赖库 上一步我们已经将项目 soul 部署到私服上了，这一步介绍项目 ssm 如何依赖引用 soul。私服中的 maven-central 可以链接远程仓库。这样，当有依赖在私服中找不到后，就可以通过远程仓库自动下载依赖。 pom 文件中添加如下配置 public库成员仓库中添加我们自定义的仓库 配置远程仓库为私服地址。&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;public&lt;/id&gt; &lt;name&gt;public Repository&lt;/name&gt; &lt;url&gt;http://192.168.0.86:8081/repository/maven-public/&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;public&lt;/id&gt; &lt;name&gt;Public Repositories&lt;/name&gt; &lt;url&gt;http://192.168.0.86:8081/repository/maven-public/&lt;/url&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt; 引入依赖&lt;dependency&gt; &lt;groupId&gt;org.soul&lt;/groupId&gt; &lt;artifactId&gt;commons&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; ssm项目就可以引用到soul代码 本文结束。","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"java","slug":"java","permalink":"https://jiangxingye.github.io/tags/java/"},{"name":"maven","slug":"maven","permalink":"https://jiangxingye.github.io/tags/maven/"},{"name":"nexus","slug":"nexus","permalink":"https://jiangxingye.github.io/tags/nexus/"}]},{"title":"Mybatis常用Mapper语句","slug":"mybatis-Mapper","date":"2017-08-04T07:54:47.000Z","updated":"2019-09-02T13:02:59.979Z","comments":true,"path":"2017/08/04/mybatis-Mapper/","link":"","permalink":"https://jiangxingye.github.io/2017/08/04/mybatis-Mapper/","excerpt":"","text":"插入/* 简单插入 */ &lt;insert id=&quot;insertOne&quot; parameterType=&quot;Person&quot;&gt; insert into person (id, name, age) VALUES(#{id}, #{name}, #{age}); &lt;/insert&gt; /* 插入并返回对象的主键（数据库序列） */ &lt;insert id=&quot;insertOne&quot; parameterType=&quot;Person&quot; useGeneratedKeys=&quot;true&quot; keyProperty=&quot;id&quot;&gt; insert into person (name, age) VALUES(#{name}, #{age}); &lt;/insert&gt; 更新/* 简单更新 */ &lt;update id=&quot;updateName&quot;&gt; update person set name = #{name} where id = #{id}; &lt;/update&gt; /* 更新值并返回 */ &lt;select id=&quot;updateAge&quot; parameterType=&quot;Person&quot;&gt; update person set age = age + #{age} where id = #{id} returning age; &lt;/select&gt; 插入或更新记录玩家在某种类型游戏下的统计记录： 如果没有记录，则从插入，count字段为1；如果有记录，则更新count字段+1； 方式一 &lt;insert id=&quot;addCount&quot; parameterType=&quot;CountRecord&quot;&gt; /*如果有记录，则更新；无记录，则noting*/ update count_record set &quot;count&quot; = &quot;count&quot;+1 where type_id = #{typeId} and user_id = #{userId}; /*如果有记录，则noting；无记录，则插入*/ insert into count_record(type_id, user_id, &quot;count&quot;) select #{typeId}, #{userId}, 1 where not exists (select * from count where type_id = #{typeId} and user_id = #{userId}); &lt;/insert&gt; 方式二 /* 利用 PostgreSQL 的 conflic 特性 */ &lt;insert id=&quot;addCount&quot; parameterType=&quot;CountRecord&quot;&gt; insert into count_record(type_id, user_id, &quot;count&quot;) VALUES (#{typeId}, #{userId}, #{count}) on conflict(type_id,user_id) do update set &quot;count&quot; = count_record.&quot;count&quot; + 1 &lt;/insert&gt;","categories":[{"name":"数据库","slug":"数据库","permalink":"https://jiangxingye.github.io/categories/数据库/"}],"tags":[{"name":"mybatis","slug":"mybatis","permalink":"https://jiangxingye.github.io/tags/mybatis/"}]},{"title":"CentOS7安装配置匿名访问Samba","slug":"CentOS7-anonymous-Samba","date":"2017-07-03T11:40:14.000Z","updated":"2019-09-02T13:02:59.992Z","comments":true,"path":"2017/07/03/CentOS7-anonymous-Samba/","link":"","permalink":"https://jiangxingye.github.io/2017/07/03/CentOS7-anonymous-Samba/","excerpt":"","text":"介绍 Samba，是种用来让UNIX系列的操作系统与微软Windows操作系统的SMB/CIFS（Server Message Block/Common Internet File System）网络协议做链接的自由软件 –wikipedia 本文就以 CentOS7 搭建 Samba 匿名完全访问（读/写）为目标，实现一个局域网内的文件共享平台。 1.安装Samba服务使用 yum 工具进行安装 $ yum install samba samba-client 2.检查是否安装成功$ rpm -qa | grep samba 3.防火墙开放端口在 /etc/sysconfig/iptables 中添加配置 -A INPUT -p tcp -m state --state NEW -m tcp --dport 137 -j ACCEPT -A INPUT -p tcp -m state --state NEW -m tcp --dport 138 -j ACCEPT -A INPUT -p tcp -m state --state NEW -m tcp --dport 139 -j ACCEPT -A INPUT -p tcp -m state --state NEW -m tcp --dport 389 -j ACCEPT -A INPUT -p tcp -m state --state NEW -m tcp --dport 445 -j ACCEPT -A INPUT -p tcp -m state --state NEW -m tcp --dport 901 -j ACCEPT 重启 iptables 服务 $ service iptables restart 设置开机自启动 $ chkconfig --level 35 smb on 4.共享配置Samba Server的验证方式有四种： share：匿名访问共享，不需要提供用户名和口令, 安全性能较低。 user：共享目录只能被授权的用户访问,由Samba Server负责检查账号和密码的正确性。账号和密码要在本Samba Server中建立。 server：依靠其他Windows Server或Samba Server来验证用户的账号和密码,是一种代理验证。此种安全模式下,系统管理员可以把所有的Windows用户和口令集中到一个Server系统上,使用 Windows Server进行Samba认证, 远程服务器可以自动认证全部用户和口令,如果认证失败,Samba将使用用户级安全模式作为替代的方式。 domain：域安全级别,使用主域控制器(PDC)来完成认证。 创建一个匿名共享访问，需要使用share模式，但在CentOS安装的samba4中share 和 server验证方式已被弃用 配置如下： [global] workgroup = MYGROUP server string = Samba Server Version %v log file = /var/log/samba/log.%m max log size = 50 security = user map to guest = Bad User load printers = yes cups options = raw [share] comment = share path = /home/samba directory mask = 0777 create mask = 0777 #不可视目录 #browseable = yes guest ok=yes writable=yes 创建 /home/samba 共享目录 $ mkdir /home/samba 重启 smb 服务 $ service smb restart 检查服务是否在运行 $ pgrep smbd 检查配置参数 $ testparm Load smb config files from /etc/samba/smb.conf Processing section &quot;[share]&quot; Loaded services file OK. Server role: ROLE_STANDALONE Press enter to see a dump of your service definitions # Global parameters [global] server string = Samba Server Version %v workgroup = MYGROUP log file = /var/log/samba/log.%m max log size = 50 map to guest = Bad User security = USER idmap config * : backend = tdb cups options = raw [share] comment = share path = /home/samba create mask = 0777 directory mask = 0777 guest ok = Yes read only = No 访问以上就配置完成，如服务器地址为192.168.0.87 windows 系统访问，直接运行 \\\\192.168.0.87\\share linux 系统访问， smb://192.168.0.87/share 遇到的问题 linux 系统可以正常读写修改，但 windows 系统只可以读写，直接打开修改时就，就为只读文件了。解决办法：修改 /etc/samba/smb.conf ,在 [share] 中加入以下内容create mask = 0777 访问部分文件可以正常访问，但部分文件无法访问。解决方法：修改文件访问权限$ chmod -R 1777 /home/samba $ chown nobody:nobody 参考 CentOS7 安装Samba服务 CentOS7 安装配置匿名访问Samba","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"samba","slug":"samba","permalink":"https://jiangxingye.github.io/tags/samba/"}]},{"title":"解决粘贴到vim缩进错乱问题","slug":"vim-paste","date":"2017-06-01T11:45:24.000Z","updated":"2019-09-02T13:03:00.032Z","comments":true,"path":"2017/06/01/vim-paste/","link":"","permalink":"https://jiangxingye.github.io/2017/06/01/vim-paste/","excerpt":"","text":"遇见当我使用vim，想要粘贴下面这段脚本到 xx.sh 文件中 #!/bin/bash if [ $1 ] then if [ $1 == &quot;help&quot; ]; then echo -e &quot;\\033[37m pay 参数1 [参数2] \\033[0m&quot; else if [ $2 ]; then filename = $2 fi fi else echo -e &quot;\\033[37m 缺少关键词，通过&#39;pay help&#39;查看帮助信息 \\033[0m&quot; fi 却出现了错乱,如下图所示 分析vim 没有相应的程序来处理这个从其他应用复制粘贴的过程，所以Vim通过插入键盘输入的buffer来模拟这个粘贴的过程，这个时候Vim会以为这是用户输入的。 所以问题是：当上一行结束，光标进入下一行时Vim会自动以上一行的的缩进为初始位置。这样就会破坏原始文件的缩进。 解决问题经过一番google，发现vim提供了 paste 选项，进入 paste 模式后，就可以正常缩进了。 # 进入 paste 模式 :set paste # 退出 paste 模式 :set nopaste 如果不想每次都执行这个命令，可以在 ～/.vimrc 中添加一行配置 set pastetoggle=&lt;F12&gt; ，这样就可以通过F12快速在paste模式中切换。","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"vim","slug":"vim","permalink":"https://jiangxingye.github.io/tags/vim/"}]},{"title":"进入docker容器命令制作","slug":"entering-docker","date":"2017-06-01T09:25:11.000Z","updated":"2019-09-02T13:03:00.033Z","comments":true,"path":"2017/06/01/entering-docker/","link":"","permalink":"https://jiangxingye.github.io/2017/06/01/entering-docker/","excerpt":"","text":"通过attach进入容器# 进入容器（Docker自带的命令） $ sudo docker attach [name] 通过这命令进入容器后，执行ctrl+d退出容器后发现容器也停止了。所以可以通过 先按，ctrl+p 再按，ctrl+q 退出 制作进入容器的命令既然attach退出很麻烦，一不小心容器就down掉了 通过 docker exec 进入容器是安全的，但是命令过长 所以我们可以通过下面操作，简化命令 1.创建文件 /usr/bin/ctn,内容如下 docker exec -it $1 /bin/bash 2.检查环境变量有没有配置目录 /usr/bin $PATH bash: /usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games: No such file or directory 配置环境变量的方式自行百度 3.完成上面两步即可通过命令 ctn 进入容器 $ ctn [name] 注意：如果是使用非root账号创建的命令，而docker命令是root权限，可能会存在权限问题可以设置 chmod 777 /usr/bin/ctn 设置权限使用 sudo ctn [name] 即可进入容器 4.自动补全docker名使用上面命令时，docker的名字都是手动输入，很麻烦，而且容易出错。 我们可以借助complete命令，来补全docker信息。 在~/.bashrc(作用于当前用户，如果所有用户，修改/etc/bashrc)文件中添加一行 # ctn auto complete complete -W &quot;$(docker ps --format &quot;{{.Names}}&quot;)&quot; ctn 再执行 source .bashrc 使之生效。 这样我们输入 ctn 后，按 Tab 就会提示或自动补全了。 注意： 由于提示的docker名是 .bashrc 生效时的列表，所以如果之后docker列表有变动，需重新执行 source .bashrc 使之更新提示列表","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://jiangxingye.github.io/tags/docker/"}]},{"title":"docker数据管理","slug":"docker-data-manager","date":"2017-05-23T13:43:06.000Z","updated":"2019-09-02T13:02:59.997Z","comments":true,"path":"2017/05/23/docker-data-manager/","link":"","permalink":"https://jiangxingye.github.io/2017/05/23/docker-data-manager/","excerpt":"","text":"数据卷数据卷是一个可供一个或多个容器使用的特殊目录，它绕过 UFS，可以提供很多有用的特性： 数据卷可以在容器之间共享和重用 对数据卷的修改会立马生效 对数据卷的更新，不会影响镜像 数据卷默认会一直存在，即使容器被删除 注意：数据卷的使用，类似于 Linux 下对目录或文件进行 mount，镜像中的被指定为挂载点的目录中的文件会隐藏掉，能显示看的是挂载的数据卷。 创建一个数据卷在用 docker run 命令的时候，使用 -v 标记来创建一个数据卷并挂载到容器里。在一次 run 中多次使用可以挂载多个数据卷。 下面创建一个名为 web 的容器，并加载一个数据卷到容器的 /webapp 目录。 $ sudo docker run -d -P --name web -v /webapp training/webapp python app.py 注意：也可以在 Dockerfile 中使用 VOLUME 来添加一个或者多个新的卷到由该镜像创建的任意容器。 删除数据卷数据卷是被设计用来持久化数据的，它的生命周期独立于容器，Docker不会在容器被删除后自动删除数据卷，并且也不存在垃圾回收这样的机制来处理没有任何容器引用的数据卷。如果需要在删除容器的同时移除数据卷。可以在删除容器的时候使用 docker rm -v 这个命令。无主的数据卷可能会占据很多空间，要清理会很麻烦。Docker官方正在试图解决这个问题，相关工作的进度可以查看这个PR。 挂载一个主机目录作为数据卷使用 -v 标记也可以指定挂载一个本地主机的目录到容器中去。 $ sudo docker run -d -P --name web -v /src/webapp:/opt/webapp training/webapp python app.py 上面的命令加载主机的 /src/webapp 目录到容器的 /opt/webapp 目录。这个功能在进行测试的时候十分方便，比如用户可以放置一些程序到本地目录中，来查看容器是否正常工作。本地目录的路径必须是绝对路径，如果目录不存在 Docker 会自动为你创建它。 注意：Dockerfile 中不支持这种用法，这是因为 Dockerfile 是为了移植和分享用的。然而，不同操作系统的路径格式不一样，所以目前还不能支持。 Docker 挂载数据卷的默认权限是读写，用户也可以通过 :ro 指定为只读。 $ sudo docker run -d -P --name web -v /src/webapp:/opt/webapp:ro training/webapp python app.py 加了 :ro 之后，就挂载为只读了。 查看数据卷的具体信息在主机里使用以下命令可以查看指定容器的信息 $ docker inspect web 在输出的内容中找到其中和数据卷相关的部分，可以看到所有的数据卷都是创建在主机的/var/lib/docker/volumes/下面的 &quot;Volumes&quot;: { &quot;/webapp&quot;: &quot;/var/lib/docker/volumes/fac362...80535&quot; }, &quot;VolumesRW&quot;: { &quot;/webapp&quot;: true } ... 注：从Docker 1.8.0起，数据卷配置在”Mounts”Key下面，可以看到所有的数据卷都是创建在主机的/mnt/sda1/var/lib/docker/volumes/….下面了。 &quot;Mounts&quot;: [ { &quot;Name&quot;: &quot;b53ebd40054dae599faf7c9666acfe205c3e922fc3e8bc3f2fd178ed788f1c29&quot;, &quot;Source&quot;: &quot;/mnt/sda1/var/lib/docker/volumes/b53ebd40054dae599faf7c9666acfe205c3e922fc3e8bc3f2fd178ed788f1c29/_data&quot;, &quot;Destination&quot;: &quot;/webapp&quot;, &quot;Driver&quot;: &quot;local&quot;, &quot;Mode&quot;: &quot;&quot;, &quot;RW&quot;: true, &quot;Propagation&quot;: &quot;&quot; } ] ... 挂载一个本地主机文件作为数据卷-v 标记也可以从主机挂载单个文件到容器中 $ sudo docker run --rm -it -v ~/.bash_history:/.bash_history ubuntu /bin/bash 这样就可以记录在容器输入过的命令了。 注意：如果直接挂载一个文件，很多文件编辑工具，包括 vi 或者 sed --in-place，可能会造成文件 inode 的改变，从 Docker 1.1 .0起，这会导致报错误信息。所以最简单的办法就直接挂载文件的父目录。 数据卷容器如果你有一些持续更新的数据需要在容器之间共享，最好创建数据卷容器。 数据卷容器，其实就是一个正常的容器，专门用来提供数据卷供其它容器挂载的。 首先，创建一个名为 dbdata 的数据卷容器： $ sudo docker run -d -v /dbdata --name dbdata training/postgres echo Data-only container for postgres 然后，在其他容器中使用 –volumes-from 来挂载 dbdata 容器中的数据卷。 $ sudo docker run -d --volumes-from dbdata --name db1 training/postgres $ sudo docker run -d --volumes-from dbdata --name db2 training/postgres 可以使用超过一个的 --volumes-from 参数来指定从多个容器挂载不同的数据卷。 也可以从其他已经挂载了数据卷的容器来级联挂载数据卷。 $ sudo docker run -d --name db3 --volumes-from db1 training/postgres 注意：使用 –volumes-from 参数所挂载数据卷的容器自己并不需要保持在运行状态。 如果删除了挂载的容器（包括 dbdata、db1 和 db2），数据卷并不会被自动删除。如果要删除一个数据卷，必须在删除最后一个还挂载着它的容器时使用 docker rm -v 命令来指定同时删除关联的容器。 这可以让用户在容器之间升级和移动数据卷。具体的操作将在下一节中进行讲解。 利用数据卷容器来备份、恢复、迁移数据卷可以利用数据卷对其中的数据进行进行备份、恢复和迁移。 备份首先使用 –volumes-from 标记来创建一个加载 dbdata 容器卷的容器，并从主机挂载当前目录到容器的 /backup 目录。命令如下： $ sudo docker run --volumes-from dbdata -v $(pwd):/backup ubuntu tar cvf /backup/backup.tar /dbdata 容器启动后，使用了 tar 命令来将 dbdata 卷备份为容器中 /backup/backup.tar 文件，也就是主机当前目录下的名为 backup.tar 的文件。 恢复如果要恢复数据到一个容器，首先创建一个带有空数据卷的容器 dbdata2。 $ sudo docker run -v /dbdata --name dbdata2 ubuntu /bin/bash 然后创建另一个容器，挂载 dbdata2 容器卷中的数据卷，并使用 untar 解压备份文件到挂载的容器卷中。 $ sudo docker run --volumes-from dbdata2 -v $(pwd):/backup busybox tar xvf /backup/backup.tar 为了查看/验证恢复的数据，可以再启动一个容器挂载同样的容器卷来查看 $ sudo docker run --volumes-from dbdata2 busybox /bin/ls /dbdata","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://jiangxingye.github.io/tags/docker/"}]},{"title":"docker容器","slug":"docker-container","date":"2017-05-23T13:29:38.000Z","updated":"2019-09-02T13:02:59.996Z","comments":true,"path":"2017/05/23/docker-container/","link":"","permalink":"https://jiangxingye.github.io/2017/05/23/docker-container/","excerpt":"","text":"容器镜像（Image）和容器（Container）的关系，就像是面向对象程序设计中的类和实例一样，镜像是静态的定义，容器是镜像运行时的实体。容器可以被创建、启动、停止、删除、暂停等。 容器的实质是进程，但与直接在宿主执行的进程不同，容器进程运行于属于自己的独立的 命名空间。因此容器可以拥有自己的 root 文件系统、自己的网络配置、自己的进程空间，甚至自己的用户 ID 空间。容器内的进程是运行在一个隔离的环境里，使用起来，就好像是在一个独立于宿主的系统下操作一样。这种特性使得容器封装的应用比直接在宿主运行更加安全。 命令# 创建一个名为myubuntu的容器 # -t:分配一个伪终端 -i:让容器的标准输入保持打开 $ docker run --name=myubuntu -t -i ubuntu /bin/bash # 创建一个名为webserver 的nginx容器，使用卷映射本机/home/faker/myspace/nginx目录到docker目录/usr/share/nginx/html $ docker run --name=webserver -d -v /home/faker/myspace/nginx:/usr/share/nginx/html -p 80:80 nginx # 查看容器的输出信息（打印信息，如 echo） # run的时候，使用-d将会不展示在宿主机上，可通过下面命令查看打印信息 $ docker run -d ubuntu:14.04 /bin/sh -c &quot;while true; do echo hello world; sleep 1; done&quot; $ docker logs [container ID or NAMES] # 启动容器 myubuntu $ docker start myubuntu # 关闭容器 myubuntu $ docker stop myubuntu # 查看已启动的容器 -a:查看包括未启动的容器在内的所有容器 $ docker ps [-a] # 进入容器（Docker自带的命令） $ docker attach [name] # 进入容器（通过exec） $ docker exec -it [name] /bin/bash # 导出容器快照到本地文件 $ docker export [container id] &gt; ubuntu.tar # 将容器快照导入为镜像 $ cat ubuntu.tar | docker import - test/ubuntu:v1.0 # 从制定 URL 或者某个目录导入 $ docker import http://example.com/exampleimage.tgz example/imagerepo # 删除容器 -f:删除正在运行的容器 $ docker [-f] rm myubuntu # 删除所有已关闭的容器 $ docker rm $(docker ps -a -q) # 查询各容器资源使用情况 $ docker stats $(docker ps --format={{.Names}})","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://jiangxingye.github.io/tags/docker/"}]},{"title":"docker仓库","slug":"docker-registry","date":"2017-05-23T13:15:52.000Z","updated":"2019-09-02T13:02:59.995Z","comments":true,"path":"2017/05/23/docker-registry/","link":"","permalink":"https://jiangxingye.github.io/2017/05/23/docker-registry/","excerpt":"","text":"Docker Hub目前 Docker 官方维护了一个公共仓库 Docker Hub，其中已经包括了超过 15,000 的镜像。大部分需求，都可以通过在 Docker Hub 中直接下载镜像来实现。 登录可以通过执行 docker login 命令来输入用户名、密码和邮箱来完成注册和登录。 注册成功后，本地用户目录的 .dockercfg 中将保存用户的认证信息。 基本操作用户无需登录即可通过 docker search 命令来查找官方仓库中的镜像，并利用 docker pull 命令来将它下载到本地。 例如以 centos 为关键词进行搜索： $ sudo docker search centos NAME DESCRIPTION STARS OFFICIAL AUTOMATED centos The official build of CentOS. 465 [OK] tianon/centos CentOS 5 and 6, created using rinse instea... 28 blalor/centos Bare-bones base CentOS 6.5 image 6 [OK] saltstack/centos-6-minimal 6 [OK] tutum/centos-6.4 DEPRECATED. Use tutum/centos:6.4 instead. ... 5 [OK] ... 可以看到返回了很多包含关键字的镜像，其中包括镜像名字、描述、星级（表示该镜像的受欢迎程度）、是否官方创建、是否自动创建。 官方的镜像说明是官方项目组创建和维护的，automated 资源允许用户验证镜像的来源和内容。 根据是否是官方提供，可将镜像资源分为两类。 一种是类似 centos 这样的基础镜像，被称为基础或根镜像。这些基础镜像是由 Docker 公司创建、验证、支持、提供。这样的镜像往往使用单个单词作为名字。 还有一种类型，比如 tianon/centos 镜像，它是由 Docker 的用户创建并维护的，往往带有用户名称前缀。可以通过前缀 user_name/ 来指定使用某个用户提供的镜像，比如 tianon 用户。 另外，在查找的时候通过 -s N 参数可以指定仅显示评价为 N 星以上的镜像。 下载官方 centos 镜像到本地。 $ sudo docker pull centos Pulling repository centos 0b443ba03958: Download complete 539c0211cd76: Download complete 511136ea3c5a: Download complete 7064731afe90: Download complete 用户也可以在登录后通过 docker push 命令来将镜像推送到 Docker Hub。 私有仓库安装 docker-registry容器运行在安装了 Docker 后，可以通过获取官方 registry 镜像来运行。 $ sudo docker run -d -p 5000:5000 registry 这将使用官方的 registry 镜像来启动本地的私有仓库。 用户可以通过指定参数来配置私有仓库位置，例如配置镜像存储到 Amazon S3 服务。 $ sudo docker run \\ -e SETTINGS_FLAVOR=s3 \\ -e AWS_BUCKET=acme-docker \\ -e STORAGE_PATH=/registry \\ -e AWS_KEY=AKIAHSHB43HS3J92MXZ \\ -e AWS_SECRET=xdDowwlK7TJajV1Y7EoOZrmuPEJlHYcNP2k4j49T \\ -e SEARCH_BACKEND=sqlalchemy \\ -p 5000:5000 \\ registry 此外，还可以指定本地路径（如 /home/user/registry-conf ）下的配置文件。 $ sudo docker run -d -p 5000:5000 -v /home/user/registry-conf:/registry-conf -e DOCKER_REGISTRY_CONFIG=/registry-conf/config.yml registry 默认情况下，仓库会被创建在容器的 /tmp/registry 下。可以通过 -v 参数来将镜像文件存放在本地的指定路径。 例如下面的例子将上传的镜像放到 /opt/data/registry 目录。 $ sudo docker run -d -p 5000:5000 -v /opt/data/registry:/tmp/registry registry 本地安装对于 Ubuntu 或 CentOS 等发行版，可以直接通过源安装。1.Ubuntu $ sudo apt-get install -y build-essential python-dev libevent-dev python-pip liblzma-dev $ sudo pip install docker-registry 2.CentOS $ sudo yum install -y python-devel libevent-devel python-pip gcc xz-devel $ sudo python-pip install docker-registry 3.源码安装 $ sudo apt-get install build-essential python-dev libevent-dev python-pip libssl-dev liblzma-dev libffi-dev $ git clone https://github.com/docker/docker-registry.git $ cd docker-registry $ sudo python setup.py install 然后修改配置文件，主要修改 dev 模板段的 storage_path 到本地的存储仓库的路径。 $ cp config/config_sample.yml config/config.yml 之后启动 Web 服务。 $ sudo gunicorn -c contrib/gunicorn.py docker_registry.wsgi:application 或者 $ sudo gunicorn --access-logfile - --error-logfile - -k gevent -b 0.0.0.0:5000 -w 4 --max-requests 100 docker_registry.wsgi:application 此时使用 curl 访问本地的 5000 端口，看到输出 docker-registry 的版本信息说明运行成功。 注：config/config_sample.yml 文件是示例配置文件。 在私有仓库上传、下载、搜索镜像创建好私有仓库之后，就可以使用 docker tag 来标记一个镜像，然后推送它到仓库，别的机器上就可以下载下来了。例如私有仓库地址为 192.168.7.26:5000。 先在本机查看已有的镜像。 $ sudo docker images REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE ubuntu latest ba5877dc9bec 6 weeks ago 192.7 MB ubuntu 14.04 ba5877dc9bec 6 weeks ago 192.7 MB 使用docker tag 将 ba58 这个镜像标记为 192.168.7.26:5000/test（格式为 docker tag IMAGE[:TAG] [REGISTRYHOST/][USERNAME/]NAME[:TAG]）。 $ sudo docker tag ba58 192.168.7.26:5000/test root ~ # docker images REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE ubuntu 14.04 ba5877dc9bec 6 weeks ago 192.7 MB ubuntu latest ba5877dc9bec 6 weeks ago 192.7 MB 192.168.7.26:5000/test latest ba5877dc9bec 6 weeks ago 192.7 MB 使用 docker push 上传标记的镜像。 $ sudo docker push 192.168.7.26:5000/test The push refers to a repository [192.168.7.26:5000/test] (len: 1) Sending image list Pushing repository 192.168.7.26:5000/test (1 tags) Image 511136ea3c5a already pushed, skipping Image 9bad880da3d2 already pushed, skipping Image 25f11f5fb0cb already pushed, skipping Image ebc34468f71d already pushed, skipping Image 2318d26665ef already pushed, skipping Image ba5877dc9bec already pushed, skipping Pushing tag for rev [ba5877dc9bec] on {http://192.168.7.26:5000/v1/repositories/test/tags/latest} 用 curl 查看仓库中的镜像。 $ curl http://192.168.7.26:5000/v1/search {&quot;num_results&quot;: 7, &quot;query&quot;: &quot;&quot;, &quot;results&quot;: [{&quot;description&quot;: &quot;&quot;, &quot;name&quot;: &quot;library/miaxis_j2ee&quot;}, {&quot;description&quot;: &quot;&quot;, &quot;name&quot;: &quot;library/tomcat&quot;}, {&quot;description&quot;: &quot;&quot;, &quot;name&quot;: &quot;library/ubuntu&quot;}, {&quot;description&quot;: &quot;&quot;, &quot;name&quot;: &quot;library/ubuntu_office&quot;}, {&quot;description&quot;: &quot;&quot;, &quot;name&quot;: &quot;library/desktop_ubu&quot;}, {&quot;description&quot;: &quot;&quot;, &quot;name&quot;: &quot;dockerfile/ubuntu&quot;}, {&quot;description&quot;: &quot;&quot;, &quot;name&quot;: &quot;library/test&quot;}]} 这里可以看到 {“description”: “”, “name”: “library/test”}，表明镜像已经被成功上传了。 现在可以到另外一台机器去下载这个镜像。 $ sudo docker pull 192.168.7.26:5000/test Pulling repository 192.168.7.26:5000/test ba5877dc9bec: Download complete 511136ea3c5a: Download complete 9bad880da3d2: Download complete 25f11f5fb0cb: Download complete ebc34468f71d: Download complete 2318d26665ef: Download complete $ sudo docker images REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE 192.168.7.26:5000/test latest ba5877dc9bec 6 weeks ago 192.7 MB 可以使用 这个脚本 批量上传本地的镜像到注册服务器中，默认是本地注册服务器 127.0.0.1:5000。例如： $ wget https://github.com/yeasy/docker_practice/raw/master/_local/push_images.sh; sudo chmod a+x push_images.sh $ ./push_images.sh ubuntu:latest centos:centos7 The registry server is 127.0.0.1 Uploading ubuntu:latest... The push refers to a repository [127.0.0.1:5000/ubuntu] (len: 1) Sending image list Pushing repository 127.0.0.1:5000/ubuntu (1 tags) Image 511136ea3c5a already pushed, skipping Image bfb8b5a2ad34 already pushed, skipping Image c1f3bdbd8355 already pushed, skipping Image 897578f527ae already pushed, skipping Image 9387bcc9826e already pushed, skipping Image 809ed259f845 already pushed, skipping Image 96864a7d2df3 already pushed, skipping Pushing tag for rev [96864a7d2df3] on {http://127.0.0.1:5000/v1/repositories/ubuntu/tags/latest} Untagged: 127.0.0.1:5000/ubuntu:latest Done Uploading centos:centos7... The push refers to a repository [127.0.0.1:5000/centos] (len: 1) Sending image list Pushing repository 127.0.0.1:5000/centos (1 tags) Image 511136ea3c5a already pushed, skipping 34e94e67e63a: Image successfully pushed 70214e5d0a90: Image successfully pushed Pushing tag for rev [70214e5d0a90] on {http://127.0.0.1:5000/v1/repositories/centos/tags/centos7} Untagged: 127.0.0.1:5000/centos:centos7 Done 仓库配置文件Docker 的 Registry 利用配置文件提供了一些仓库的模板（flavor），用户可以直接使用它们来进行开发或生产部署。 模板在 config_sample.yml 文件中，可以看到一些现成的模板段： common：基础配置 local：存储数据到本地文件系统 s3：存储数据到 AWS S3 中 dev：使用 local 模板的基本配置 test：单元测试使用 prod：生产环境配置（基本上跟s3配置类似） gcs：存储数据到 Google 的云存储 swift：存储数据到 OpenStack Swift 服务 glance：存储数据到 OpenStack Glance 服务，本地文件系统为后备 glance-swift：存储数据到 OpenStack Glance 服务，Swift 为后备 elliptics：存储数据到 Elliptics key/value 存储 用户也可以添加自定义的模版段。 默认情况下使用的模板是 dev，要使用某个模板作为默认值，可以添加 SETTINGS_FLAVOR 到环境变量中，例如 export SETTINGS_FLAVOR=dev 另外，配置文件中支持从环境变量中加载值，语法格式为 _env:VARIABLENAME[:DEFAULT]。 示例配置common: loglevel: info search_backend: &quot;_env:SEARCH_BACKEND:&quot; sqlalchemy_index_database: &quot;_env:SQLALCHEMY_INDEX_DATABASE:sqlite:////tmp/docker-registry.db&quot; prod: loglevel: warn storage: s3 s3_access_key: _env:AWS_S3_ACCESS_KEY s3_secret_key: _env:AWS_S3_SECRET_KEY s3_bucket: _env:AWS_S3_BUCKET boto_bucket: _env:AWS_S3_BUCKET storage_path: /srv/docker smtp_host: localhost from_addr: docker@myself.com to_addr: my@myself.com dev: loglevel: debug storage: local storage_path: /home/myself/docker test: storage: local storage_path: /tmp/tmpdockertmp","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://jiangxingye.github.io/tags/docker/"},{"name":"docker仓库","slug":"docker仓库","permalink":"https://jiangxingye.github.io/tags/docker仓库/"}]},{"title":"每天一个linux命令（58）: sort","slug":"linux-command（57）-sort","date":"2017-05-23T03:44:12.000Z","updated":"2019-09-02T13:03:00.029Z","comments":true,"path":"2017/05/23/linux-command（57）-sort/","link":"","permalink":"https://jiangxingye.github.io/2017/05/23/linux-command（57）-sort/","excerpt":"","text":"sort是在Linux里非常常用的一个命令，管排序的。 1.工作原理sort将文件的每一行作为一个单位，相互比较，比较原则是从首字符向后，依次按ASCII码值进行比较，最后将他们按升序输出。 $ cat seq.txt apple allow photo bowl peal check cheese $ sort seq.txt allow apple bowl check cheese peal photo 2.sort的-u选项它的作用很简单，就是在输出行中去除重复行。 3.sort的-r选项sort默认的排序方式是升序，如果想改成降序，就加个-r就搞定了。 4.sort的-o选项由于sort默认是把结果输出到标准输出，所以需要用重定向才能将结果写入文件，形如sort filename &gt; newfile。 但是，如果你想把排序结果输出到原文件中，用重定向可就不行了。 [rocrocket@rocrocket programming]$ sort -r number.txt &gt; number.txt [rocrocket@rocrocket programming]$ cat number.txt [rocrocket@rocrocket programming]$ 看，竟然将number清空了。 就在这个时候，-o选项出现了，它成功的解决了这个问题，让你放心的将结果写入原文件。这或许也是-o比重定向的唯一优势所在。 5.sort的-n选项你有没有遇到过10比2小的情况。我反正遇到过。出现这种情况是由于排序程序将这些数字按字符来排序了，排序程序会先比较1和2，显然1小，所以就将10放在2前面喽。这也是sort的一贯作风。 我们如果想改变这种现状，就要使用-n选项，来告诉sort，“要以数值来排序”！ 6.sort的-t选项和-k选项如果有一个文件的内容是这样： [rocrocket@rocrocket programming]$ cat facebook.txt banana:30:5.5 apple:10:2.5 pear:90:2.3 orange:20:3.4 这个文件有三列，列与列之间用冒号隔开了，第一列表示水果类型，第二列表示水果数量，第三列表示水果价格。 那么我想以水果数量来排序，也就是以第二列来排序，如何利用sort实现？ 幸好，sort提供了-t选项，后面可以设定间隔符。（是不是想起了cut和paste的-d选项，共鸣～～） 指定了间隔符之后，就可以用-k来指定列数了。 [rocrocket@rocrocket programming]$ sort -n -k 2 -t : facebook.txt apple:10:2.5 orange:20:3.4 banana:30:5.5 pear:90:2.3 我们使用冒号作为间隔符，并针对第二列来进行数值升序排序，结果很令人满意。 7.其他的sort常用选项-f会将小写字母都转换为大写字母来进行比较，亦即忽略大小写 -c会检查文件是否已排好序，如果乱序，则输出第一个乱序的行的相关信息，最后返回1 -C会检查文件是否已排好序，如果乱序，不输出内容，仅返回1 -M会以月份来排序，比如JAN小于FEB等等 -b会忽略每一行前面的所有空白部分，从第一个可见字符开始比较。","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"https://jiangxingye.github.io/tags/linux命令/"}]},{"title":"CentOS修改DNS/GW/IP","slug":"CentOS-DNS-GW-IP","date":"2017-05-23T01:53:52.000Z","updated":"2019-09-02T13:02:59.993Z","comments":true,"path":"2017/05/23/CentOS-DNS-GW-IP/","link":"","permalink":"https://jiangxingye.github.io/2017/05/23/CentOS-DNS-GW-IP/","excerpt":"","text":"1.修改DNS解决方案一：修改网卡的DNS的配置文件 $ vim /etc/resolv.conf 添加以下内容,设置两条dns nameserver 8.8.8.8 #google域名服务器 nameserver 8.8.4.4 #google域名服务器 若未生效，可执行 chattr +i /etc/resolv.conf 设置文件属性只有root用户才能修改然后执行 service NetworkManager restart 解决方案二：对接口添加dns信息；编辑/etc/sysconfig/network-scripts/ifcfg-xxx，xxx为你的网卡名，但一般是ifcfg-eth0的，具体的xxx根据你的网卡确定，在最下面添加： DNS1=8.8.8.8 #google dns服务器, 根据实际情况更换 DNS2=8.8.4.4 #google dns服务器, 根据实际情况更换 保存后重启网络 $ service network restart 2.修改网关修改网关的配置文件(第3部分也可以设置) $ vim /etc/sysconfig/network 修改为一下内容 NETWORKING=yes(表示系统是否使用网络，一般设置为yes。如果设为no，则不能使用网络，而且很多系统服务程序将无法启动) HOSTNAME=centos(设置本机的主机名，这里设置的主机名要和/etc/hosts中设置的主机名对应) GATEWAY=192.168.1.1(设置本机连接的网关的IP地址。例如，网关为10.0.0.2) 3.修改ip修改对应的网卡的IP地址的配置文件 $ vim /etc/sysconfig/network-scripts/ifcfg-eth0 修改为一下内容 DEVICE=eth0 #描述网卡对应的设备别名，例如ifcfg-eth0的文件中它为eth0 BOOTPROTO=static #设置网卡获得ip地址的方式，可能的选项为static，dhcp或bootp，分别对应静态指定的 ip地址，通过dhcp协议获得的ip地址，通过bootp协议获得的ip地址 BROADCAST=192.168.0.255 #对应的子网广播地址 HWADDR=00:07:E9:05:E8:B4 #对应的网卡物理地址 IPADDR=12.168.1.2 #如果设置网卡获得 ip地址的方式为静态指定，此字段就指定了网卡对应的ip地址 IPV6INIT=no IPV6_AUTOCONF=no NETMASK=255.255.255.0 #网卡对应的网络掩码 NETWORK=192.168.1.0 #网卡对应的网络地址 ONBOOT=yes #系统启动时是否设置此网络接口，设置为yes时，系统启动时激活此设备","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/tags/运维/"},{"name":"centos","slug":"centos","permalink":"https://jiangxingye.github.io/tags/centos/"}]},{"title":"Dockerfile指令详解","slug":"Dockerfile","date":"2017-05-22T11:11:42.000Z","updated":"2019-09-02T13:02:59.993Z","comments":true,"path":"2017/05/22/Dockerfile/","link":"","permalink":"https://jiangxingye.github.io/2017/05/22/Dockerfile/","excerpt":"","text":"Dockerfile 是一个文本文件，其内包含了一条条的指令(Instruction)，每一条指令构建一层，因此每一条指令的内容，就是描述该层应当如何构建。 构建镜像命令格式： $ docker build [选项] &lt;上下文路径/URL/-&gt; 示例： # 构建一个名为 nginx:v3 的镜像 $ docker build -t nginx:v3 . RUN 执行命令1) shell格式：RUN &lt;命令&gt;，就像直接在命令行中输入的命令一样。刚才写的 Dockrfile 中的 RUN 指令就是这种格式。 RUN echo &#39;&lt;h1&gt;Hello, Docker!&lt;/h1&gt;&#39; &gt; /usr/share/nginx/html/index.html 2) exec格式：RUN [“可执行文件”, “参数1”, “参数2”]，这更像是函数调用中的格式。 COPY 复制文件格式：1) COPY &lt;源路径&gt;... &lt;目标路径&gt;2) COPY [&quot;&lt;源路径1&gt;&quot;,... &quot;&lt;目标路径&gt;&quot;]和 RUN 指令一样，也有两种格式，一种类似于命令行，一种类似于函数调用。COPY 指令将从构建上下文目录中 &lt;源路径&gt; 的文件/目录复制到新的一层的镜像内的 &lt;目标路径&gt; 位置。比如： COPY package.json /usr/src/app/ &lt;源路径&gt; 可以是多个，甚至可以是通配符，其通配符规则要满足 Go 的 filepath.Match 规则，如： COPY hom* /mydir/ COPY hom?.txt /mydir/ &lt;目标路径&gt; 可以是容器内的绝对路径，也可以是相对于工作目录的相对路径（工作目录可以用 WORKDIR 指令来指定）。目标路径不需要事先创建，如果目录不存在会在复制文件前先行创建缺失目录。 此外，还需要注意一点，使用 COPY 指令，源文件的各种元数据都会保留。比如读、写、执行权限、文件变更时间等。这个特性对于镜像定制很有用。特别是构建相关文件都在使用 Git 进行管理的时候。 ADD更高级的复制文件ADD 指令和 COPY 的格式和性质基本一致。但是在 COPY 基础上增加了一些功能。 比如 &lt;源路径&gt; 可以是一个 URL，这种情况下，Docker 引擎会试图去下载这个链接的文件放到 &lt;目标路径&gt; 去。下载后的文件权限自动设置为 600，如果这并不是想要的权限，那么还需要增加额外的一层 RUN 进行权限调整，另外，如果下载的是个压缩包，需要解压缩，也一样还需要额外的一层 RUN 指令进行解压缩。所以不如直接使用 RUN 指令，然后使用 wget 或者 curl 工具下载，处理权限、解压缩、然后清理无用文件更合理。因此，这个功能其实并不实用，而且不推荐使用。 如果 &lt;源路径&gt; 为一个 tar 压缩文件的话，压缩格式为 gzip, bzip2 以及 xz 的情况下，ADD 指令将会自动解压缩这个压缩文件到 &lt;目标路径&gt; 去。 在 Docker 官方的最佳实践文档中要求，尽可能的使用 COPY 。 因此在 COPY 和 ADD 指令中选择的时候，可以遵循这样的原则，所有的文件复制均使用 COPY 指令，仅在需要自动解压缩的场合使用 ADD。 CMD 容器启动命令CMD 指令的格式和 RUN 相似，也是两种格式：1） shell 格式：CMD &lt;命令&gt;2） exec 格式：CMD [&quot;可执行文件&quot;, &quot;参数1&quot;, &quot;参数2&quot;...]3） 参数列表格式：CMD [&quot;参数1&quot;, &quot;参数2&quot;...]。在指定了 ENTRYPOINT 指令后，用 CMD 指定具体的参数。 Docker 不是虚拟机，容器就是进程。既然是进程，那么在启动容器的时候，需要指定所运行的程序及参数。CMD 指令就是用于指定默认的容器主进程的启动命令的。 在运行时可以指定新的命令来替代镜像设置中的这个默认命令，比如，ubuntu 镜像默认的 CMD 是 /bin/bash，如果我们直接 docker run -it ubuntu 的话，会直接进入 bash。我们也可以在运行时指定运行别的命令，如 docker run -it ubuntu cat /etc/os-release。这就是用 cat /etc/os-release 命令替换了默认的 /bin/bash 命令了，输出了系统版本信息。 在指令格式上，一般推荐使用 exec 格式，这类格式在解析时会被解析为 JSON 数组，因此一定要使用双引号 “，而不要使用单引号。 ENTRYPOINT 入口点ENTRYPOINT 的目的和 CMD 一样，都是在指定容器启动程序及参数。ENTRYPOINT 在运行时也可以替代，不过比 CMD 要略显繁琐，需要通过 docker run 的参数 –entrypoint 来指定。 当指定了 ENTRYPOINT 后，CMD 的含义就发生了改变，不再是直接的运行其命令，而是将 CMD 的内容作为参数传给 ENTRYPOINT 指令，换句话说实际执行时，将变为： &lt;ENTRYPOINT&gt; &quot;&lt;CMD&gt;&quot; 1) 场景一：让镜像变成像命令一样使用 FROM ubuntu:16.04 RUN apt-get update \\ &amp;&amp; apt-get install -y curl \\ &amp;&amp; rm -rf /var/lib/apt/lists/* ENTRYPOINT [ &quot;curl&quot;, &quot;-s&quot;, &quot;http://ip.cn&quot; ] $ docker run myip -i 这是因为当存在 ENTRYPOINT 后，CMD 的内容将会作为参数传给 ENTRYPOINT，而这里 -i 就是新的 CMD，因此会作为参数传给 curl，从而达到了我们预期的效果。 2) 场景二：应用运行前的准备工作可以写一个脚本，然后放入 ENTRYPOINT 中去执行，而这个脚本会将接到的参数（也就是 ）作为命令，在脚本最后执行。比如官方镜像 redis 中就是这么做的： FROM alpine:3.4 ... RUN addgroup -S redis &amp;&amp; adduser -S -G redis redis ... ENTRYPOINT [&quot;docker-entrypoint.sh&quot;] EXPOSE 6379 CMD [ &quot;redis-server&quot; ] 可以看到其中为了 redis 服务创建了 redis 用户，并在最后指定了 ENTRYPOINT 为 docker-entrypoint.sh 脚本。 #!/bin/sh ... # allow the container to be started with `--user` if [ &quot;$1&quot; = &#39;redis-server&#39; -a &quot;$(id -u)&quot; = &#39;0&#39; ]; then chown -R redis . exec su-exec redis &quot;$0&quot; &quot;$@&quot; fi exec &quot;$@&quot; 该脚本的内容就是根据 CMD 的内容来判断，如果是 redis-server 的话，则切换到 redis 用户身份启动服务器，否则依旧使用 root 身份执行。比如： $ docker run -it redis id uid=0(root) gid=0(root) groups=0(root) ENV 设置环境变量格式有两种：1) ENV &lt;key&gt; &lt;value&gt;2) ENV &lt;key1&gt;=&lt;value1&gt; &lt;key2&gt;=&lt;value2&gt;... 这个指令很简单，就是设置环境变量而已，无论是后面的其它指令，如 RUN，还是运行时的应用，都可以直接使用这里定义的环境变量。 ENV VERSION=1.0 DEBUG=on \\ NAME=&quot;Happy Feet&quot; 这个例子中演示了如何换行，以及对含有空格的值用双引号括起来的办法，这和 Shell 下的行为是一致的。 定义了环境变量，那么在后续的指令中，就可以使用这个环境变量。比如在官方 node 镜像 Dockerfile 中，就有类似这样的代码： ENV NODE_VERSION 7.2.0 RUN curl -SLO &quot;https://nodejs.org/dist/v$NODE_VERSION/node-v$NODE_VERSION-linux-x64.tar.xz&quot; \\ &amp;&amp; curl -SLO &quot;https://nodejs.org/dist/v$NODE_VERSION/SHASUMS256.txt.asc&quot; \\ &amp;&amp; gpg --batch --decrypt --output SHASUMS256.txt SHASUMS256.txt.asc \\ &amp;&amp; grep &quot; node-v$NODE_VERSION-linux-x64.tar.xz\\$&quot; SHASUMS256.txt | sha256sum -c - \\ &amp;&amp; tar -xJf &quot;node-v$NODE_VERSION-linux-x64.tar.xz&quot; -C /usr/local --strip-components=1 \\ &amp;&amp; rm &quot;node-v$NODE_VERSION-linux-x64.tar.xz&quot; SHASUMS256.txt.asc SHASUMS256.txt \\ &amp;&amp; ln -s /usr/local/bin/node /usr/local/bin/nodejs 在这里先定义了环境变量 NODE_VERSION，其后的 RUN 这层里，多次使用 $NODE_VERSION 来进行操作定制。可以看到，将来升级镜像构建版本的时候，只需要更新 7.2.0 即可，Dockerfile 构建维护变得更轻松了。 下列指令可以支持环境变量展开： ADD、COPY、ENV、EXPOSE、LABEL、USER、WORKDIR、VOLUME、STOPSIGNAL、ONBUILD。 可以从这个指令列表里感觉到，环境变量可以使用的地方很多，很强大。通过环境变量，我们可以让一份 Dockerfile 制作更多的镜像，只需使用不同的环境变量即可。 ARG 构建参数格式：ARG &lt;参数名&gt;[=&lt;默认值&gt;] 构建参数和 ENV 的效果一样，都是设置环境变量。所不同的是，ARG 所设置的构建环境的环境变量，在将来容器运行时是不会存在这些环境变量的。但是不要因此就使用 ARG 保存密码之类的信息，因为 docker history 还是可以看到所有值的。 Dockerfile 中的 ARG 指令是定义参数名称，以及定义其默认值。该默认值可以在构建命令 docker build 中用 –build-arg &lt;参数名&gt;=&lt;值&gt; 来覆盖。 在 1.13 之前的版本，要求 –build-arg 中的参数名，必须在 Dockerfile 中用 ARG 定义过了，换句话说，就是 –build-arg 指定的参数，必须在 Dockerfile 中使用了。如果对应参数没有被使用，则会报错退出构建。从 1.13 开始，这种严格的限制被放开，不再报错退出，而是显示警告信息，并继续构建。这对于使用 CI 系统，用同样的构建流程构建不同的 Dockerfile 的时候比较有帮助，避免构建命令必须根据每个 Dockerfile 的内容修改。 VOLUME 定义匿名卷格式为：1) VOLUME [&quot;&lt;路径1&gt;&quot;, &quot;&lt;路径2&gt;&quot;...]2) VOLUME &lt;路径&gt; 之前我们说过，容器运行时应该尽量保持容器存储层不发生写操作，对于数据库类需要保存动态数据的应用，其数据库文件应该保存于卷(volume)中，后面的章节我们会进一步介绍 Docker 卷的概念。为了防止运行时用户忘记将动态文件所保存目录挂载为卷，在 Dockerfile 中，我们可以事先指定某些目录挂载为匿名卷，这样在运行时如果用户不指定挂载，其应用也可以正常运行，不会向容器存储层写入大量数据。 VOLUME /data 这里的 /data 目录就会在运行时自动挂载为匿名卷，任何向 /data 中写入的信息都不会记录进容器存储层，从而保证了容器存储层的无状态化。当然，运行时可以覆盖这个挂载设置。比如： $ docker run -d -v mydata:/data xxxx 在这行命令中，就使用了 mydata 这个命名卷挂载到了 /data 这个位置，替代了 Dockerfile 中定义的匿名卷的挂载配置。 EXPOSE 声明端口格式为 EXPOSE &lt;端口1&gt; [&lt;端口2&gt;...]。 EXPOSE 指令是声明运行时容器提供服务端口，这只是一个声明，在运行时并不会因为这个声明应用就会开启这个端口的服务。在 Dockerfile 中写入这样的声明有两个好处，一个是帮助镜像使用者理解这个镜像服务的守护端口，以方便配置映射；另一个用处则是在运行时使用随机端口映射时，也就是 docker run -P 时，会自动随机映射 EXPOSE 的端口。 此外，在早期 Docker 版本中还有一个特殊的用处。以前所有容器都运行于默认桥接网络中，因此所有容器互相之间都可以直接访问，这样存在一定的安全性问题。于是有了一个 Docker 引擎参数 –icc=false，当指定该参数后，容器间将默认无法互访，除非互相间使用了 –links 参数的容器才可以互通，并且只有镜像中 EXPOSE 所声明的端口才可以被访问。这个 –icc=false 的用法，在引入了 docker network 后已经基本不用了，通过自定义网络可以很轻松的实现容器间的互联与隔离。 要将 EXPOSE 和在运行时使用 -p &lt;宿主端口&gt;:&lt;容器端口&gt; 区分开来。-p，是映射宿主端口和容器端口，换句话说，就是将容器的对应端口服务公开给外界访问，而 EXPOSE 仅仅是声明容器打算使用什么端口而已，并不会自动在宿主进行端口映射。 WORKDIR 指定工作目录格式为 WORKDIR &lt;工作目录路径&gt;。 使用 WORKDIR 指令可以来指定工作目录（或者称为当前目录），以后各层的当前目录就被改为指定的目录，如该目录不存在，WORKDIR 会帮你建立目录。 之前提到一些初学者常犯的错误是把 Dockerfile 等同于 Shell 脚本来书写，这种错误的理解还可能会导致出现下面这样的错误： RUN cd /app RUN echo &quot;hello&quot; &gt; world.txt 如果将这个 Dockerfile 进行构建镜像运行后，会发现找不到 /app/world.txt 文件，或者其内容不是 hello。原因其实很简单，在 Shell 中，连续两行是同一个进程执行环境，因此前一个命令修改的内存状态，会直接影响后一个命令；而在 Dockerfile 中，这两行 RUN 命令的执行环境根本不同，是两个完全不同的容器。这就是对 Dokerfile 构建分层存储的概念不了解所导致的错误。 之前说过每一个 RUN 都是启动一个容器、执行命令、然后提交存储层文件变更。第一层 RUN cd /app 的执行仅仅是当前进程的工作目录变更，一个内存上的变化而已，其结果不会造成任何文件变更。而到第二层的时候，启动的是一个全新的容器，跟第一层的容器更完全没关系，自然不可能继承前一层构建过程中的内存变化。 因此如果需要改变以后各层的工作目录的位置，那么应该使用 WORKDIR 指令。 USER 指定当前用户格式：USER &lt;用户名&gt; USER 指令和 WORKDIR 相似，都是改变环境状态并影响以后的层。WORKDIR 是改变工作目录，USER 则是改变之后层的执行 RUN, CMD 以及 ENTRYPOINT 这类命令的身份。 当然，和 WORKDIR 一样，USER 只是帮助你切换到指定用户而已，这个用户必须是事先建立好的，否则无法切换。 RUN groupadd -r redis &amp;&amp; useradd -r -g redis redis USER redis RUN [ &quot;redis-server&quot; ] 如果以 root 执行的脚本，在执行期间希望改变身份，比如希望以某个已经建立好的用户来运行某个服务进程，不要使用 su 或者 sudo，这些都需要比较麻烦的配置，而且在 TTY 缺失的环境下经常出错。建议使用 gosu，可以从其项目网站看到进一步的信息：https://github.com/tianon/gosu # 建立 redis 用户，并使用 gosu 换另一个用户执行命令 RUN groupadd -r redis &amp;&amp; useradd -r -g redis redis # 下载 gosu RUN wget -O /usr/local/bin/gosu &quot;https://github.com/tianon/gosu/releases/download/1.7/gosu-amd64&quot; \\ &amp;&amp; chmod +x /usr/local/bin/gosu \\ &amp;&amp; gosu nobody true # 设置 CMD，并以另外的用户执行 CMD [ &quot;exec&quot;, &quot;gosu&quot;, &quot;redis&quot;, &quot;redis-server&quot; ] HEALTHCHECK 健康检查格式： 1) HEALTHCHECK [选项] CMD &lt;命令&gt;：设置检查容器健康状况的命令2) HEALTHCHECK NONE：如果基础镜像有健康检查指令，使用这行可以屏蔽掉其健康检查指令 HEALTHCHECK 指令是告诉 Docker 应该如何进行判断容器的状态是否正常，这是 Docker 1.12 引入的新指令。 在没有 HEALTHCHECK 指令前，Docker 引擎只可以通过容器内主进程是否退出来判断容器是否状态异常。很多情况下这没问题，但是如果程序进入死锁状态，或者死循环状态，应用进程并不退出，但是该容器已经无法提供服务了。在 1.12 以前，Docker 不会检测到容器的这种状态，从而不会重新调度，导致可能会有部分容器已经无法提供服务了却还在接受用户请求。 而自 1.12 之后，Docker 提供了 HEALTHCHECK 指令，通过该指令指定一行命令，用这行命令来判断容器主进程的服务状态是否还正常，从而比较真实的反应容器实际状态。 当在一个镜像指定了 HEALTHCHECK 指令后，用其启动容器，初始状态会为 starting，在 HEALTHCHECK 指令检查成功后变为 healthy，如果连续一定次数失败，则会变为 unhealthy。 HEALTHCHECK 支持下列选项：1) --interval=&lt;间隔&gt;：两次健康检查的间隔，默认为 30 秒；2) --timeout=&lt;时长&gt;：健康检查命令运行超时时间，如果超过这个时间，本次健康检查就被视为失败，默认 30 秒；3)--retries=&lt;次数&gt;：当连续失败指定次数后，则将容器状态视为 unhealthy，默认 3 次。 和 CMD, ENTRYPOINT 一样，HEALTHCHECK 只可以出现一次，如果写了多个，只有最后一个生效。 在 HEALTHCHECK [选项] CMD 后面的命令，格式和 ENTRYPOINT 一样，分为 shell 格式，和 exec 格式。命令的返回值决定了该次健康检查的成功与否：0：成功；1：失败；2：保留，不要使用这个值。 假设我们有个镜像是个最简单的 Web 服务，我们希望增加健康检查来判断其 Web 服务是否在正常工作，我们可以用 curl 来帮助判断，其 Dockerfile 的 HEALTHCHECK 可以这么写： FROM nginx RUN apt-get update &amp;&amp; apt-get install -y curl &amp;&amp; rm -rf /var/lib/apt/lists/* HEALTHCHECK --interval=5s --timeout=3s \\ CMD curl -fs http://localhost/ || exit 1 这里我们设置了每 5 秒检查一次（这里为了试验所以间隔非常短，实际应该相对较长），如果健康检查命令超过 3 秒没响应就视为失败，并且使用 curl -fs http://localhost/ || exit 1 作为健康检查命令。 使用 docker build 来构建这个镜像： $ docker build -t myweb:v1 . 构建好了后，我们启动一个容器： $ docker run -d --name web -p 80:80 myweb:v1 当运行该镜像后，可以通过 docker ps 看到最初的状态为 (health: starting)： $ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 03e28eb00bd0 myweb:v1 &quot;nginx -g &#39;daemon off&quot; 3 seconds ago Up 2 seconds (health: starting) 80/tcp, 443/tcp web 在等待几秒钟后，再次 docker ps，就会看到健康状态变化为了 (healthy)： $ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 03e28eb00bd0 myweb:v1 &quot;nginx -g &#39;daemon off&quot; 18 seconds ago Up 16 seconds (healthy) 80/tcp, 443/tcp web 如果健康检查连续失败超过了重试次数，状态就会变为 (unhealthy)。 为了帮助排障，健康检查命令的输出（包括 stdout 以及 stderr）都会被存储于健康状态里，可以用 docker inspect 来查看。 $ docker inspect --format &#39;{{json .State.Health}}&#39; web | python -m json.tool { &quot;FailingStreak&quot;: 0, &quot;Log&quot;: [ { &quot;End&quot;: &quot;2016-11-25T14:35:37.940957051Z&quot;, &quot;ExitCode&quot;: 0, &quot;Output&quot;: &quot;&lt;!DOCTYPE html&gt;\\n&lt;html&gt;\\n&lt;head&gt;\\n&lt;title&gt;Welcome to nginx!&lt;/title&gt;\\n&lt;style&gt;\\n body {\\n width: 35em;\\n margin: 0 auto;\\n font-family: Tahoma, Verdana, Arial, sans-serif;\\n }\\n&lt;/style&gt;\\n&lt;/head&gt;\\n&lt;body&gt;\\n&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;\\n&lt;p&gt;If you see this page, the nginx web server is successfully installed and\\nworking. Further configuration is required.&lt;/p&gt;\\n\\n&lt;p&gt;For online documentation and support please refer to\\n&lt;a href=\\&quot;http://nginx.org/\\&quot;&gt;nginx.org&lt;/a&gt;.&lt;br/&gt;\\nCommercial support is available at\\n&lt;a href=\\&quot;http://nginx.com/\\&quot;&gt;nginx.com&lt;/a&gt;.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;em&gt;Thank you for using nginx.&lt;/em&gt;&lt;/p&gt;\\n&lt;/body&gt;\\n&lt;/html&gt;\\n&quot;, &quot;Start&quot;: &quot;2016-11-25T14:35:37.780192565Z&quot; } ], &quot;Status&quot;: &quot;healthy&quot; } ONBUILD 为他人做嫁衣裳格式：ONBUILD &lt;其它指令&gt;。 ONBUILD 是一个特殊的指令，它后面跟的是其它指令，比如 RUN, COPY 等，而这些指令，在当前镜像构建时并不会被执行。只有当以当前镜像为基础镜像，去构建下一级镜像的时候才会被执行。 Dockerfile 中的其它指令都是为了定制当前镜像而准备的，唯有 ONBUILD 是为了帮助别人定制自己而准备的。 假设我们要制作 Node.js 所写的应用的镜像。我们都知道 Node.js 使用 npm 进行包管理，所有依赖、配置、启动信息等会放到 package.json 文件里。在拿到程序代码后，需要先进行 npm install 才可以获得所有需要的依赖。然后就可以通过 npm start 来启动应用。因此，一般来说会这样写 Dockerfile： FROM node:slim RUN &quot;mkdir /app&quot; WORKDIR /app COPY ./package.json /app RUN [ &quot;npm&quot;, &quot;install&quot; ] COPY . /app/ CMD [ &quot;npm&quot;, &quot;start&quot; ] 把这个 Dockerfile 放到 Node.js 项目的根目录，构建好镜像后，就可以直接拿来启动容器运行。但是如果我们还有第二个 Node.js 项目也差不多呢？好吧，那就再把这个 Dockerfile 复制到第二个项目里。那如果有第三个项目呢？再复制么？文件的副本越多，版本控制就越困难，让我们继续看这样的场景维护的问题。 如果第一个 Node.js 项目在开发过程中，发现这个 Dockerfile 里存在问题，比如敲错字了、或者需要安装额外的包，然后开发人员修复了这个 Dockerfile，再次构建，问题解决。第一个项目没问题了，但是第二个项目呢？虽然最初 Dockerfile 是复制、粘贴自第一个项目的，但是并不会因为第一个项目修复了他们的 Dockerfile，而第二个项目的 Dockerfile 就会被自动修复。 那么我们可不可以做一个基础镜像，然后各个项目使用这个基础镜像呢？这样基础镜像更新，各个项目不用同步 Dockerfile 的变化，重新构建后就继承了基础镜像的更新？好吧，可以，让我们看看这样的结果。那么上面的这个 Dockerfile 就会变为： FROM node:slim RUN &quot;mkdir /app&quot; WORKDIR /app CMD [ &quot;npm&quot;, &quot;start&quot; ] 这里我们把项目相关的构建指令拿出来，放到子项目里去。假设这个基础镜像的名字为 my-node 的话，各个项目内的自己的 Dockerfile 就变为： FROM my-node COPY ./package.json /app RUN [ &quot;npm&quot;, &quot;install&quot; ] COPY . /app/ 基础镜像变化后，各个项目都用这个 Dockerfile 重新构建镜像，会继承基础镜像的更新。 那么，问题解决了么？没有。准确说，只解决了一半。如果这个 Dockerfile 里面有些东西需要调整呢？比如 npm install 都需要加一些参数，那怎么办？这一行 RUN 是不可能放入基础镜像的，因为涉及到了当前项目的 ./package.json，难道又要一个个修改么？所以说，这样制作基础镜像，只解决了原来的 Dockerfile 的前4条指令的变化问题，而后面三条指令的变化则完全没办法处理。 ONBUILD 可以解决这个问题。让我们用 ONBUILD 重新写一下基础镜像的 Dockerfile: FROM node:slim RUN &quot;mkdir /app&quot; WORKDIR /app ONBUILD COPY ./package.json /app ONBUILD RUN [ &quot;npm&quot;, &quot;install&quot; ] ONBUILD COPY . /app/ CMD [ &quot;npm&quot;, &quot;start&quot; ] 这次我们回到原始的 Dockerfile，但是这次将项目相关的指令加上 ONBUILD，这样在构建基础镜像的时候，这三行并不会被执行。然后各个项目的 Dockerfile 就变成了简单地： FROM my-node 是的，只有这么一行。当在各个项目目录中，用这个只有一行的 Dockerfile 构建镜像时，之前基础镜像的那三行 ONBUILD 就会开始执行，成功的将当前项目的代码复制进镜像、并且针对本项目执行 npm install，生成应用镜像。 ReferenceDocker–从入门到实践: https://yeasy.gitbooks.io/docker_practice/content/Dockerfie 官方文档：https://docs.docker.com/engine/reference/builder/Dockerfile 最佳实践文档：https://docs.docker.com/engine/userguide/eng-image/dockerfile_best-practices/","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://jiangxingye.github.io/tags/docker/"}]},{"title":"docker镜像","slug":"docker-image","date":"2017-05-19T08:47:33.000Z","updated":"2019-09-02T13:02:59.998Z","comments":true,"path":"2017/05/19/docker-image/","link":"","permalink":"https://jiangxingye.github.io/2017/05/19/docker-image/","excerpt":"","text":"WhatDocker 镜像是一个特殊的文件系统，除了提供容器运行时所需的程序、库、资源、配置等文件外，还包含了一些为运行时准备的一些配置参数（如匿名卷、环境变量、用户等）。镜像不包含任何动态数据，其内容在构建之后也不会被改变。 因为镜像包含操作系统完整的 root 文件系统，其体积往往是庞大的，因此在 Docker 设计时，就充分利用 Union FS 的技术，将其设计为分层存储的架构。所以严格来说，镜像并非是像一个 ISO 那样的打包文件，镜像只是一个虚拟的概念，其实际体现并非由一个文件组成，而是由一组文件系统组成，或者说，由多层文件系统联合组成。 安装# 官方 的安装脚本 $ curl -sSL https://get.docker.com/ | sh # 阿里云 的安装脚本 $ curl -sSL http://acs-public-mirror.oss-cn-hangzhou.aliyuncs.com/docker-engine/internet | sh - # DaoCloud 的安装脚本 $ curl -sSL https://get.daocloud.io/docker | sh 镜像# 获取镜像，registry为空默认从Docker Hub上获取 docker pull [选项] [Docker Registry地址]&lt;仓库名&gt;:&lt;标签&gt; # 交互式运行，退出删除: -i:交互式 ,-t:终端,--rm 退出删除 ,bash 启动bash窗口 $ docker run -it --rm ubuntu:14.04 bash # 列出已下载的镜像（只显示顶层镜像） -a:显示所有镜像 image_name:指定列出某个镜像 $ docker images [-a] [image_name] # 只显示虚悬镜像(dangling image) -f:--filter 过滤 $ docker images -f dangling=true # 过滤从mongo:3.2建立之后的镜像 $ docker images -f since=mongo:3.2 # 通过label过滤 $ docker images -f label=com.example.version=0.1 # 只显示镜像id $ docker images -q # 只包含镜像ID和仓库名 $ docker images --format &quot;{{.ID}}: {{.Repository}}&quot; # 以表格等距显示 有标题行，和默认一样，不过自己定义列 $ docker images --format &quot;table {{.ID}}\\t{{.Repository}}\\t{{.Tag}}&quot; # 删除镜像ID为image_id的镜像 $ docker rmi &lt;image_id&gt; # 删除虚悬镜像 $ docker rmi $(docker images -q -f dangling=true) # 将容器保存为镜像 $ docker commit [选项] &lt;容器ID或容器名&gt; [&lt;仓库名&gt;[:&lt;标签&gt;]] # 将容器保存为镜像 $ docker commit \\ --author &quot;Tao Wang &lt;twang2218@gmail.com&gt;&quot; \\ --message &quot;修改了默认网页&quot; \\ webserver \\ nginx:v2 $ docker history nginx:v2","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://jiangxingye.github.io/tags/docker/"}]},{"title":"docker初体验","slug":"docker-first","date":"2017-05-19T08:32:23.000Z","updated":"2019-09-02T13:02:59.996Z","comments":true,"path":"2017/05/19/docker-first/","link":"","permalink":"https://jiangxingye.github.io/2017/05/19/docker-first/","excerpt":"","text":"笔者环境操作系统：deepin 15.4 Desktop 64Bit 安装# 官方 的安装脚本 $ curl -sSL https://get.docker.com/ | sh # 阿里云 的安装脚本 $ curl -sSL http://acs-public-mirror.oss-cn-hangzhou.aliyuncs.com/docker-engine/internet | sh - # DaoCloud 的安装脚本 $ curl -sSL https://get.daocloud.io/docker | sh 获取镜像Docker Hub 上有大量的高质量的镜像可以用，这里我们就说一下怎么获取这些镜像并运行。从 Docker Registry 获取镜像的命令是 docker pull。其命令格式为： $ docker pull [选项] [Docker Registry地址]&lt;仓库名&gt;:&lt;标签&gt; 具体的选项可以通过 docker pull --help 命令看到，这里我们说一下镜像名称的格式。 Docker Registry地址：地址的格式一般是 &lt;域名/IP&gt;[:端口号]。默认地址是 Docker Hub。 仓库名：如之前所说，这里的仓库名是两段式名称，既 &lt;用户名&gt;/&lt;软件名&gt;。对于 Docker Hub，如果不给出用户名，则默认为 library，也就是官方镜像。 $ sudo docker pull ubuntu 运行有了镜像后，我们就可以以这个镜像为基础启动一个容器来运行。以上面的 ubuntu 为例，如果我们打算启动里面的 bash 并且进行交互式操作的话，可以执行下面的命令。 $ sudo docker run -it --rm ubuntu root@0ae011f7b5be:/# cat /etc/os-release NAME=&quot;Ubuntu&quot; VERSION=&quot;16.04.2 LTS (Xenial Xerus)&quot; ID=ubuntu ID_LIKE=debian PRETTY_NAME=&quot;Ubuntu 16.04.2 LTS&quot; VERSION_ID=&quot;16.04&quot; HOME_URL=&quot;http://www.ubuntu.com/&quot; SUPPORT_URL=&quot;http://help.ubuntu.com/&quot; BUG_REPORT_URL=&quot;http://bugs.launchpad.net/ubuntu/&quot; VERSION_CODENAME=xenial UBUNTU_CODENAME=xenial docker run 就是运行容器的命令 -it：这是两个参数，一个是 -i：交互式操作，一个是 -t 终端。我们这里打算进入 bash 执行一些命令并查看返回结果，因此我们需要交互式终端。 --rm：这个参数是说容器退出后随之将其删除。默认情况下，为了排障需求，退出的容器并不会立即删除，除非手动 docker rm。我们这里只是随便执行个命令，看看结果，不需要排障和保留结果，因此使用 –rm 可以避免浪费空间。 ubuntu：这是指用 ubuntu 镜像为基础来启动容器。 bash：放在镜像名后的是命令，这里我们希望有个交互式 Shell，因此用的是 bash。 进入容器后，我们可以在 Shell 下操作，执行任何所需的命令。这里，我们执行了 cat /etc/os-release，这是 Linux 常用的查看当前系统版本的命令，从返回的结果可以看到容器内是 Ubuntu 16.04.2 LTS 系统。 最后通过 exit 退出了这个容器。","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://jiangxingye.github.io/tags/docker/"}]},{"title":"linux无损调整分区大小","slug":"linux无损调整分区大小","date":"2017-05-17T14:00:42.000Z","updated":"2019-09-02T13:02:59.998Z","comments":true,"path":"2017/05/17/linux无损调整分区大小/","link":"","permalink":"https://jiangxingye.github.io/2017/05/17/linux无损调整分区大小/","excerpt":"","text":"summary 系统环境: Red Hat 4.8.5-11 情况： home：500G root：50G root分区不够用 思路：把home分区的空间划一部分到root分区 # 设置home分区大小为200G，释放300G空间 $ lvreduce -L 200G /dev/centos/home # 将空闲空间扩展到root分区 $ lvextend -l +100%FREE /dev/centos/root # 使用XFS文件系统自带的命令集增加分区空间 $ xfs_growfs /dev/mapper/centos-root 实例situation挂载在根目录的分区 /dev/mapper/centos-root 爆满，占用100% $ df -h Filesystem Size Used Avail Use% Mounted on /dev/mapper/centos-root 50G 50G 19M 100% / devtmpfs 32G 0 32G 0% /dev tmpfs 32G 0 32G 0% /dev/shm tmpfs 32G 2.5G 29G 8% /run tmpfs 32G 0 32G 0% /sys/fs/cgroup /dev/mapper/centos-home 476G 33M 476G 1% /home /dev/sda1 497M 238M 259M 48% /boot tmpfs 6.3G 0 6.3G 0% /run/user/0 analyze挂载在根目录的分区空间太小，只有50G，而服务器 home 目录为非常用目录，挂在了近500G的空间。 思路：从 centos-home 分区划出300G空间到 centos-root 分区。 operation1.查看各分区信息$ lvdisplay --- Logical volume --- LV Path /dev/centos/home LV Name home VG Name centos LV UUID 1fAt1E-bQsa-1HXR-MCE2-5VZ1-xzBz-iI1SLv LV Write Access read/write LV Creation host, time localhost, 2016-10-26 17:23:47 +0800 LV Status available # open 0 LV Size 475.70 GiB Current LE 121778 Segments 1 Allocation inherit Read ahead sectors auto - currently set to 256 Block device 253:2 --- Logical volume --- LV Path /dev/centos/root LV Name root VG Name centos LV UUID lD64zY-yc3Z-SZaB-dAjK-03YM-2gM8-pfj4oo LV Write Access read/write LV Creation host, time localhost, 2016-10-26 17:23:48 +0800 LV Status available # open 1 LV Size 50.00 GiB Current LE 12800 Segments 1 Allocation inherit Read ahead sectors auto - currently set to 256 Block device 253:0 2.减少/home分区空间# 释放 /dev/centos/home 分区 300G 的空间 # 命令设置 /dev/centos/home 分区 200G空间 $ lvreduce -L 200G /dev/centos/home WARNING: Reducing active logical volume to 200.00 GiB. THIS MAY DESTROY YOUR DATA (filesystem etc.) Do you really want to reduce centos/home? [y/n]: y Size of logical volume centos/home changed from 475.70 GiB (121778 extents) to 200.00 GiB (51200 extents). Logical volume centos/home successfully resized. 3.增加/root分区空间$ lvextend -l +100%FREE /dev/centos/root Size of logical volume centos/root changed from 50.06 GiB (12816 extents) to 325.76 GiB (83394 extents). Logical volume centos/root successfully resized. 4.扩展XFS文件空间大小$ xfs_growfs /dev/mapper/centos-root meta-data=/dev/mapper/centos-root isize=256 agcount=4, agsize=3276800 blks = sectsz=512 attr=2, projid32bit=1 = crc=0 finobt=0 spinodes=0 data = bsize=4096 blocks=13107200, imaxpct=25 = sunit=0 swidth=0 blks naming =version 2 bsize=4096 ascii-ci=0 ftype=0 log =internal bsize=4096 blocks=6400, version=2 = sectsz=512 sunit=0 blks, lazy-count=1 realtime =none extsz=4096 blocks=0, rtextents=0 data blocks changed from 13107200 to 85395456 完成","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/tags/运维/"},{"name":"磁盘分区","slug":"磁盘分区","permalink":"https://jiangxingye.github.io/tags/磁盘分区/"}]},{"title":"解决linux下zip文件解压乱码","slug":"解决linux下zip文件解压乱码","date":"2017-04-25T01:10:40.000Z","updated":"2019-09-02T13:03:00.031Z","comments":true,"path":"2017/04/25/解决linux下zip文件解压乱码/","link":"","permalink":"https://jiangxingye.github.io/2017/04/25/解决linux下zip文件解压乱码/","excerpt":"","text":"原因由于zip格式并没有指定编码格式，Windows下生成的zip文件中的编码是GBK/GB2312等，因此，导致这些zip文件在Linux下解压时出现乱码问题，因为Linux下的默认编码是UTF8。 解决方案使用7z解压。 安装p7zip和convmv # fedora $ su -c &#39;yum install p7zip convmv&#39; # ubuntu $ sudo apt-get install p7zip convmv 执行一下命令解压缩 # 使用7z解压缩 $ LANG=C 7za x your-zip-file.zip # 递归转码 $ convmv -f GBK -t utf8 --notest -r .","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"https://jiangxingye.github.io/tags/linux命令/"}]},{"title":"加密算法简介","slug":"encryption-algorithm","date":"2017-04-22T01:30:41.000Z","updated":"2019-09-02T13:02:59.977Z","comments":true,"path":"2017/04/22/encryption-algorithm/","link":"","permalink":"https://jiangxingye.github.io/2017/04/22/encryption-algorithm/","excerpt":"","text":"一、对称密钥算法概述对称加密（Symmetric-key algorithm）是指加解密用同一个密钥的算法，根据具体实现分为流加密和分组加密两种类型： 流加密（Stream cipher）是对称加密常用的一种实现方法，加密和解密双方使用相同伪随机加密数据流，一般都是逐位异或随机密码本的内容。 分组加密加密（Block cipher），也叫块加密，将明文分成多个等长的模块（block），使用确定的算法和对称密钥对每组分别加密解密。现代分组加密建立在迭代的思想上产生密文。迭代产生的密文在每一轮加密中使用不同的子密钥，而子密钥生成自原始密钥。 对称加密普遍比非对称加密速度要快，实现更简单，适合大量内容的加密 DESDES (Data Encryption Standard) 是一种分组加密算法 DES算法的入口参数有三个:Key,Data,Mode，Key是密钥密钥占7个字节56位（64位里另外8位是用来校验的），Data是加密内容，占8个字节64位，Mode是加密还是解密。 DES算法于1976被确定，现在已经被认为不够安全，主要原因是56位的密钥过短。据说这个算法因为包含一些机密设计元素，被怀疑内含美国国家安全局（NSA）的后门。 DES算法有个拓展算法叫3DES，就是对数据块进行三次DES加密，增加爆破成本，但本质上也不够安全。 RC4RC4 (Rivest Cipher 4) 是一种流加密算法 RC4起源于1987年，现在已经被认为不够安全。RC4由伪随机数生成器和异或运算组成。RC4的密钥长度可变，范围是[1,255]。RC4一个字节一个字节地加解密。给定一个密钥，伪随机数生成器接受密钥并产生一个S盒。S盒用来加密数据，而且在加密过程中S盒会变化。 由于异或运算的对合性，RC4加密解密使用同一套算法。这个算法实现起来很简单，只用了最基本的加、异或、循环，话说我大学时某个课程设计的做的加密算法就是简化版的RC4。 之后还出现了RC5、RC6加密算法，但RC5和RC6都是分组加密，和RC4原理并不一样。 RC5RC5 （Rivest Cipher 5） 是一种分组加密算法，它和RC2，RC4，RC6都是同一个叫Ronald Rivest的人设计的。 相比RC4，RC5的密钥成了128位，但RC5仍然只需要基础的加、异或、循环运算，可以在很多硬件上实现。RC5有三个参数：字的大小，循环轮数（round），密钥中的8位字节个数，所以可以说RC5是一种可变加密算法。实际上循环轮数12轮以下的RC5都被认为是不安全的，会被差分分析法（Differential cryptanalysis）攻击，18-20轮才足够安全。 目前来说，RC5还是挺安全的，因为实现简单，消耗资源少，在一些传感器、嵌入式设备上使用很合适。 RC6RC6 （Rivest Cipher 6） 是RC5的加强版，也属于分组加密算法。 RC6算法在RC5算法基础之上针对RC5算法中的漏洞，主要是循环移位的位移量并不取决于要移动次数的所有比特，通过采用引入乘法运算来决定循环移位次数的方法，对RC5算法进行了改进，从而大大提高了RC6算法的安全性。 RC6曾作为AES（高级加密标准）备选算法之一，但最终AES选择了Rijndael算法。 AES最后压轴出场的是最著名的单密钥对称加密算法AES (Rijndael)，AES是Advanced Encryption Standard的缩写，是美国国家标准与技术研究院2001年发布的新加密标准。 AES现在就是指的限定了区块长度和密钥长度的Rijndael算法，同样属于分组加密算法，该算法是两位比利时学者1998年发布的。起初还有很多算法参与了AES甄选，最终Rijndael凭借高安全性和清晰的数学结构而被选用。 AES将Rijndael算法的区块长度固定为128位，密钥长度可选128，192或256比特（Rijndael原版支持128-256，n*32的区块长度和密钥长度）。 AES算法包括4个步骤： AddRoundKey—矩阵中的每一个字节都与该次回合密钥（round key）做XOR运算；每个子密钥由密钥生成方案产生。 SubBytes—通过一个非线性的替换函数，用查找表的方式把每个字节替换成对应的字节。 ShiftRows—将矩阵中的每个横列进行循环式移位。 MixColumns—为了充分混合矩阵中各个直行的操作。这个步骤使用线性转换来混合每内联的四个字节。最后一个加密循环中省略MixColumns步骤，而以另一个AddRoundKey替换。 截止现在（2016），AES在算法层面上是安全的。2005年有人公布过一种缓存时序攻击法，但使用场景非常极端。 二、非对称秘钥算法概述公钥加密的思想于1974年被提出，相比对称加密无需共享密钥，更加安全。但是没法加密大量数据，一般用来加密对称加密的密钥，而用对称加密加密大量数据。非对称加密的原理如下： 消息发送方A在本地构建密钥对，公钥和私钥； 消息发送方A将产生的公钥发送给消息接收方B； B向A发送数据时，通过公钥进行加密，A接收到数据后通过私钥进行解密，完成一次通信； 反之，A向B发送数据时，通过私钥对数据进行加密，B接收到数据后通过公钥进行解密。 RSARSA算法是最著名的非对称加密算法。RSA是1977年提出的，名字来源于Rivest、Shmir和Adleman三位作者。我们平时用到的SSL协议，TLS协议都采用了该算法加密，SSH（Secure Shell）也是基于RSA实现的。 RSA的数学基础是极大整数的因数分解，具体实现过程如下： 随意选择两个大的质数p和q，p不等于q，计算N=pq。 根据欧拉函数，求得r=varphi (N) = varphi(p) * varphi(q)=(p-1)(q-1) 选择一个小于r的整数e，使e与r互质。并求得e关于r的模反元素，命名为d。 (N,e)是公钥，(N,d)是私钥。 加密时，加密的块 n^e ≡ c(MOD N)，得到的c就是密文。解密时，c^d ≡ n(MOD N)。 要破解RSA要解决怎么把一个极大数分解为两个质数p和q，然后通过欧拉函数再得到公钥和私钥。但极大数因数分解目前还没什么好办法，所以只要N足够大，RSA在算法层面上就是安全的。 当N的长度为256时，用普通电脑花几小时即可以分解，当N长度为512时需要花数月时间分解，1024时需要大型分布式系统才能分解，长度到2046则可以确保是完全安全的。目前已有记录里，被分解的极大数最大位数是768位，于2009年被分解。 RSA也常被用来做数字签名，在消息内附加一个私钥加密过的散列值（Message digest），以此来确保消息发送人是可靠的。公钥私钥对生成 # 1.该命令会生成1024位的私钥,此时我们就可以在当前路径下看到rsa_private_key.pem文件了. genrsa -out rsa_private_key.pem 1024 # 2.生成的密钥不是pcs8格式，我们需要转成pkcs8格式 pkcs8 -topk8 -inform PEM -in rsa_private_key.pem -outform PEM -nocrypt # 3.生成 rsa 公钥 rsa -in rsa_private_key.pem -pubout -out rsa_public_key.pem 椭圆曲线算法椭圆曲线算法（Elliptic curve cryptography）也是一种非对称加密算法，于1985年被提出，以下简称ECC。相比RSA，同等破解难度时ECC的秘钥更短。另外，ECC可定义椭圆曲线群的双线性映射，该特性可能将来被用来实现身份基加密体制（Identity-Based Encryption，IBE）。 ECC的数学基础是求椭圆曲线离散对数问题。实现比较复杂我就不写了，因为我也看不懂(⊙﹏⊙)b。 也正因为实现复杂，ECC的加解密速度慢，消耗资源也更多。 ECC也同样可以实现数字签名，叫做ECDSA。 ECC的秘钥长度最小要求是160位，建议是163位。目前已有的破解记录是109位，一万台机器破解了一年半。所以ECC在算法层面是可以保证安全的。 ElGamalElGamal加密算法是一种用于对采用Diff-Hellman方式进行交换的公钥进行加密，常被用于数字签名和密钥加密的算法，ElGamal的数学基础是有限域上的离散对数问题。 选择一个素数p和两个随机数g 、x （g、 x &lt; p ），计算 y ≡ g^x（ mod p ） ，则其公钥为 y, g 和p ，私钥是x ，g和p可由一组用户共享。 ElGamal方法中一个明文对应两个加密结果(g^a和g^b)，因此密文空间的大小是明文空间大小的两倍，也就是说纵观整个通信过程，收发密文的大小是实际明文大小的两倍。 三、哈希算法概述我们经常说MD5加密，但追根究底的话，MD5应该是哈希函数（Hash Function），而哈希函数并不等同于加密（Encrypt），不过我们平常也把哈希叫做加密。哈希函数也叫散列函数，散列函数把消息或数据压缩成摘要，使得数据量变小，将数据的格式固定下来。该函数将数据打乱混合，重新创建一个叫做散列值（hash values，hash codes，hash sums，或hashes）的指纹。散列值通常用来代表一个短的随机字母和数字组成的字符串。 说人话就是哈希（Hash）是将目标文本转换成具有相同长度的、不可逆的杂凑字符串，而加密（Encrypt）是将目标文本转换成具有不同长度的、可逆的密文。 哈希主要用来校验身份，错误检查，完整性检查。 MD5MD5（Message-Digest5 Algorithm）即消息摘要算法，是最著名、应用最为广泛的一种哈希算法，于1992年被公开。MD5之前还有MD4、MD3、MD2等哥哥算法，MD5是最终的改进版。 MD5输入不定长度信息，输出固定长度为128-bits的散列 未完 待补充REFERENCE常见加密算法简介","categories":[{"name":"后端","slug":"后端","permalink":"https://jiangxingye.github.io/categories/后端/"}],"tags":[{"name":"encryption","slug":"encryption","permalink":"https://jiangxingye.github.io/tags/encryption/"}]},{"title":"JSP操作记录","slug":"jsp-use-record","date":"2017-04-21T03:22:12.000Z","updated":"2019-09-02T13:02:59.983Z","comments":true,"path":"2017/04/21/jsp-use-record/","link":"","permalink":"https://jiangxingye.github.io/2017/04/21/jsp-use-record/","excerpt":"","text":"问题EL表达式失效&lt;!-- jsp渲染器不识别el表达式，结果页面展示效果如下 --&gt; {person.id} {person.name} 解决方法：在页面内加入下面代码即可 &lt;%@ page isELIgnored=&quot;false&quot; %&gt; Map遍历&lt;c:forEach items=&quot;${map}&quot; var=&quot;entry&quot;&gt; &lt;c:out value=&quot;${entry.key}&quot; /&gt; &lt;c:out value=&quot;${entry.value}&quot; /&gt; &lt;/c:forEach&gt; 取值&lt;c:out value=&quot;${map[key]}&quot; /&gt;","categories":[{"name":"大前端","slug":"大前端","permalink":"https://jiangxingye.github.io/categories/大前端/"}],"tags":[{"name":"jsp","slug":"jsp","permalink":"https://jiangxingye.github.io/tags/jsp/"},{"name":"jstl","slug":"jstl","permalink":"https://jiangxingye.github.io/tags/jstl/"}]},{"title":"[转]SpringMVC执行流程及源码解析","slug":"SpringMVC-implementation-process","date":"2017-04-15T02:22:05.000Z","updated":"2019-09-02T13:02:59.978Z","comments":true,"path":"2017/04/15/SpringMVC-implementation-process/","link":"","permalink":"https://jiangxingye.github.io/2017/04/15/SpringMVC-implementation-process/","excerpt":"","text":"在SpringMVC中主要是围绕着DispatcherServlet来设计，可以把它当做指挥中心。这里先说明一下SpringMVC文档给出的执行流程，然后是我们稍微具体的执行流程，最后是流程大致的源码跟踪。关于很很很详细的源码解析，这里暂先不做。 官方文档中的流程首先看下SpringMVC文档上给的流程图：这张图片给了我们大概的执行流程： 用户请求首先发送到前端控制器DispatcherServlet，DispatcherServlet根据请求的信息来决定使用哪个页面控制器Controller（也就是我们通常编写的Controller）来处理该请求。找到控制器之后，DispatcherServlet将请求委托给控制器去处理。 接下来页面控制器开始处理用户请求，页面控制器会根据请求信息进行处理，调用业务层等等，处理完成之后，会把结果封装成一个ModelAndView返回给DispatcherServlet。 前端控制器DispatcherServlet接到页面控制器的返回结果后，根据返回的视图名选择相应的试图模板，并根据返回的数据进行渲染。 最后前端控制器DispatcherServlet将结果返回给用户。 更具体的流程上面只是总体流程，接下来我们稍微深入一点，看下更具体的流程，这里没有图，只有步骤解析： 用户请求发送到前端控制器DispatcherServlet。 前端控制器DispatcherServlet接收到请求后，DispatcherServlet会使用HandlerMapping来处理，HandlerMapping会查找到具体进行处理请求的Handler对象。 HandlerMapping找到对应的Handler之后，并不是返回一个Handler原始对象，而是一个Handler执行链，在这个执行链中包括了拦截器和处理请求的Handler。HandlerMapping返回一个执行链给DispatcherServlet。 DispatcherServlet接收到执行链之后，会调用Handler适配器去执行Handler。 Handler适配器执行完成Handler（也就是我们写的Controller）之后会得到一个ModelAndView，并返回给DispatcherServlet。 DispatcherServlet接收到Handler适配器返回的ModelAndView之后，会根据其中的视图名调用视图解析器。 视图解析器根据逻辑视图名解析成一个真正的View视图，并返回给DispatcherServlet。 DispatcherServlet接收到视图之后，会根据上面的ModelAndView中的model来进行视图中数据的填充，也就是所谓的视图渲染。 渲染完成之后，DispatcherServlet就可以将结果返回给用户了。 源码DispatcherServlet是一个Servlet，我们知道在Servlet在处理一个请求的时候会交给service方法进行处理，这里也不例外，DispatcherServlet继承了FrameworkServlet，首先进入FrameworkServlet的service方法： protected void service(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { //请求方法 String method = request.getMethod(); //PATCH方法单独处理 if (method.equalsIgnoreCase(RequestMethod.PATCH.name())) { processRequest(request, response); } else {//其他的请求类型的方法经由父类，也就是HttpServlet处理 super.service(request, response); } } HttpServlet中会根据请求类型的不同分别调用doGet或者doPost等方法，FrameworkServlet中已经重写了这些方法，在这些方法中会调用processRequest进行处理，在processRequest中会调用doService方法，这个doService方法就是在DispatcherServlet中实现的。下面就看下DispatcherServlet中的doService方法的实现。 请求到达DispatcherServletdoService方法： protected void doService(HttpServletRequest request, HttpServletResponse response) throws Exception { //给request中的属性做一份快照 Map&lt;String, Object&gt; attributesSnapshot = null; if (WebUtils.isIncludeRequest(request)) { logger.debug(&quot;Taking snapshot of request attributes before include&quot;); attributesSnapshot = new HashMap&lt;String, Object&gt;(); Enumeration&lt;?&gt; attrNames = request.getAttributeNames(); while (attrNames.hasMoreElements()) { String attrName = (String) attrNames.nextElement(); if (this.cleanupAfterInclude || attrName.startsWith(&quot;org.springframework.web.servlet&quot;)) { attributesSnapshot.put(attrName, request.getAttribute(attrName)); } } } //如果我们没有配置类似本地化或者主题的处理器之类的 //SpringMVC会使用默认的值 //默认配置文件是DispatcherServlet.properties request.setAttribute(WEB_APPLICATION_CONTEXT_ATTRIBUTE, getWebApplicationContext()); request.setAttribute(LOCALE_RESOLVER_ATTRIBUTE, this.localeResolver); request.setAttribute(THEME_RESOLVER_ATTRIBUTE, this.themeResolver); request.setAttribute(THEME_SOURCE_ATTRIBUTE, getThemeSource()); FlashMap inputFlashMap = this.flashMapManager.retrieveAndUpdate(request, response); if (inputFlashMap != null) { request.setAttribute(INPUT_FLASH_MAP_ATTRIBUTE, Collections.unmodifiableMap(inputFlashMap)); } request.setAttribute(OUTPUT_FLASH_MAP_ATTRIBUTE, new FlashMap()); request.setAttribute(FLASH_MAP_MANAGER_ATTRIBUTE, this.flashMapManager); try { //开始处理 doDispatch(request, response); } finally { if (WebAsyncUtils.getAsyncManager(request).isConcurrentHandlingStarted()) { return; } // Restore the original attribute snapshot, in case of an include. if (attributesSnapshot != null) { restoreAttributesAfterInclude(request, attributesSnapshot); } } } DispatcherServlet开始真正的处理，doDispatch方法： protected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception { HttpServletRequest processedRequest = request; HandlerExecutionChain mappedHandler = null; boolean multipartRequestParsed = false; //SpringMVC中异步请求的相关知识，暂先不解释 WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request); try { ModelAndView mv = null; Exception dispatchException = null; try { //先检查是不是Multipart类型的，比如上传等 //如果是Multipart类型的，则转换为MultipartHttpServletRequest类型 processedRequest = checkMultipart(request); multipartRequestParsed = processedRequest != request; //获取当前请求的Handler mappedHandler = getHandler(processedRequest, false); if (mappedHandler == null || mappedHandler.getHandler() == null) { noHandlerFound(processedRequest, response); return; } //获取当前请求的Handler适配器 HandlerAdapter ha = getHandlerAdapter(mappedHandler.getHandler()); // 对于header中last-modified的处理 String method = request.getMethod(); boolean isGet = &quot;GET&quot;.equals(method); if (isGet || &quot;HEAD&quot;.equals(method)) { long lastModified = ha.getLastModified(request, mappedHandler.getHandler()); if (new ServletWebRequest(request, response).checkNotModified(lastModified) &amp;&amp; isGet) { return; } } //拦截器的preHandle方法进行处理 if (!mappedHandler.applyPreHandle(processedRequest, response)) { return; } try { //真正调用Handler的地方 mv = ha.handle(processedRequest, response, mappedHandler.getHandler()); } finally { if (asyncManager.isConcurrentHandlingStarted()) { return; } } //处理成默认视图名，就是添加前缀和后缀等 applyDefaultViewName(request, mv); //拦截器postHandle方法进行处理 mappedHandler.applyPostHandle(processedRequest, response, mv); } catch (Exception ex) { dispatchException = ex; } //处理最后的结果，渲染之类的都在这里 processDispatchResult(processedRequest, response, mappedHandler, mv, dispatchException); } catch (Exception ex) { triggerAfterCompletion(processedRequest, response, mappedHandler, ex); } catch (Error err) { triggerAfterCompletionWithError(processedRequest, response, mappedHandler, err); } finally { if (asyncManager.isConcurrentHandlingStarted()) { // Instead of postHandle and afterCompletion mappedHandler.applyAfterConcurrentHandlingStarted(processedRequest, response); return; } // Clean up any resources used by a multipart request. if (multipartRequestParsed) { cleanupMultipart(processedRequest); } } } 可以看到大概的步骤还是按照我们上面分析的走的。 查找请求对应的Handler对象对应着这句代码 mappedHandler = getHandler(processedRequest, false);，看下具体的getHandler方法： protected HandlerExecutionChain getHandler(HttpServletRequest request, boolean cache) throws Exception { return getHandler(request); } 继续往下看getHandler： protected HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception { //遍历所有的handlerMappings进行处理 //handlerMappings是在启动的时候预先注册好的 for (HandlerMapping hm : this.handlerMappings) { HandlerExecutionChain handler = hm.getHandler(request); if (handler != null) { return handler; } } return null; } 继续往下看getHandler，在AbstractHandlerMapping类中： public final HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception { //根据request获取handler Object handler = getHandlerInternal(request); if (handler == null) { //如果没有找到就使用默认的handler handler = getDefaultHandler(); } if (handler == null) { return null; } //如果Handler是String，表明是一个bean名称 //需要超照对应bean if (handler instanceof String) { String handlerName = (String) handler; handler = getApplicationContext().getBean(handlerName); } //封装Handler执行链 return getHandlerExecutionChain(handler, request); } 根据requrst获取handler首先看下根据requrst获取handler步骤getHandlerInternal方法，在AbstractHandlerMethodMapping中： protected HandlerMethod getHandlerInternal(HttpServletRequest request) throws Exception { //获取request中的url，用来匹配handler String lookupPath = getUrlPathHelper().getLookupPathForRequest(request); //根据路径寻找Handler HandlerMethod handlerMethod = lookupHandlerMethod(lookupPath, request); //根据handlerMethod中的bean来实例化Handler并添加进HandlerMethod return (handlerMethod != null) ? handlerMethod.createWithResolvedBean() : null; } 看下根据路径寻找handler的方法lookupHandlerMethod： protected HandlerMethod lookupHandlerMethod(String lookupPath, HttpServletRequest request) throws Exception { List&lt;Match&gt; matches = new ArrayList&lt;Match&gt;(); //直接匹配 List&lt;T&gt; directPathMatches = this.urlMap.get(lookupPath); //如果有匹配的，就添加进匹配列表中 if (directPathMatches != null) { addMatchingMappings(directPathMatches, matches, request); } //还没有匹配的，就遍历所有的处理方法查找 if (matches.isEmpty()) { // No choice but to go through all mappings addMatchingMappings(this.handlerMethods.keySet(), matches, request); } //找到了匹配的 if (!matches.isEmpty()) { Comparator&lt;Match&gt; comparator = new MatchComparator(getMappingComparator(request)); Collections.sort(matches, comparator); //排序之后，获取第一个 Match bestMatch = matches.get(0); //如果有多个匹配的，会找到第二个最合适的进行比较一下 if (matches.size() &gt; 1) { Match secondBestMatch = matches.get(1); if (comparator.compare(bestMatch, secondBestMatch) == 0) { Method m1 = bestMatch.handlerMethod.getMethod(); Method m2 = secondBestMatch.handlerMethod.getMethod(); throw new IllegalStateException( &quot;Ambiguous handler methods mapped for HTTP path &#39;&quot; + request.getRequestURL() + &quot;&#39;: {&quot; + m1 + &quot;, &quot; + m2 + &quot;}&quot;); } } //设置request参数 handleMatch(bestMatch.mapping, lookupPath, request); //返回匹配的url的处理的方法 return bestMatch.handlerMethod; } else {//最后还没有找到，返回null return handleNoMatch(handlerMethods.keySet(), lookupPath, request); } } 获取默认Handler如果上面没有获取到Handler，就会获取默认的Handler。如果还获取不到就返回null。 处理String类型的Handler如果上面处理完的Handler是String类型的，就会根据这个handlerName获取bean。 封装Handler执行链上面获取完Handler，就开始封装执行链了，就是将我们配置的拦截器加入到执行链中去，getHandlerExecutionChain： protected HandlerExecutionChain getHandlerExecutionChain(Object handler, HttpServletRequest request) { //如果当前Handler不是执行链类型，就使用一个新的执行链实例封装起来 HandlerExecutionChain chain = (handler instanceof HandlerExecutionChain) ? (HandlerExecutionChain) handler : new HandlerExecutionChain(handler); //先获取适配类型的拦截器添加进去拦截器链 chain.addInterceptors(getAdaptedInterceptors()); //当前的url String lookupPath = urlPathHelper.getLookupPathForRequest(request); //遍历拦截器，找到跟当前url对应的，添加进执行链中去 for (MappedInterceptor mappedInterceptor : mappedInterceptors) { if (mappedInterceptor.matches(lookupPath, pathMatcher)) { chain.addInterceptor(mappedInterceptor.getInterceptor()); } } return chain; } 获取对应请求的Handler适配器getHandlerAdapter： protected HandlerAdapter getHandlerAdapter(Object handler) throws ServletException { //遍历所有的HandlerAdapter，找到和当前Handler匹配的就返回 //我们这里会匹配到RequestMappingHandlerAdapter for (HandlerAdapter ha : this.handlerAdapters) { if (ha.supports(handler)) { return ha; } } } 缓存的处理也就是对last-modified的处理 执行拦截器的preHandle方法就是遍历所有的我们定义的interceptor，执行preHandle方法 使用Handler适配器执行当前的Handlerha.handle执行当前Handler，我们这里使用的是RequestMappingHandlerAdapter，首先会进入AbstractHandlerMethodAdapter的handle方法： public final ModelAndView handle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { return handleInternal(request, response, (HandlerMethod) handler); } handleInternal方法，在RequestMappingHandlerAdapter中： protected final ModelAndView handleInternal(HttpServletRequest request, HttpServletResponse response, HandlerMethod handlerMethod) throws Exception { if (getSessionAttributesHandler(handlerMethod).hasSessionAttributes()) { // Always prevent caching in case of session attribute management. checkAndPrepare(request, response, this.cacheSecondsForSessionAttributeHandlers, true); } else { // Uses configured default cacheSeconds setting. checkAndPrepare(request, response, true); } // Execute invokeHandlerMethod in synchronized block if required. if (this.synchronizeOnSession) { HttpSession session = request.getSession(false); if (session != null) { Object mutex = WebUtils.getSessionMutex(session); synchronized (mutex) { return invokeHandleMethod(request, response, handlerMethod); } } } //执行方法，封装ModelAndView return invokeHandleMethod(request, response, handlerMethod); } 组装默认视图名称前缀和后缀名都加上 执行拦截器的postHandle方法遍历intercepter的postHandle方法。 处理最后的结果，渲染之类的processDispatchResult方法： private void processDispatchResult(HttpServletRequest request, HttpServletResponse response, HandlerExecutionChain mappedHandler, ModelAndView mv, Exception exception) throws Exception { boolean errorView = false; if (exception != null) { if (exception instanceof ModelAndViewDefiningException) { mv = ((ModelAndViewDefiningException) exception).getModelAndView(); } else { Object handler = (mappedHandler != null ? mappedHandler.getHandler() : null); mv = processHandlerException(request, response, handler, exception); errorView = (mv != null); } } // Did the handler return a view to render? if (mv != null &amp;&amp; !mv.wasCleared()) { //渲染 render(mv, request, response); if (errorView) { WebUtils.clearErrorRequestAttributes(request); } } else { } if (WebAsyncUtils.getAsyncManager(request).isConcurrentHandlingStarted()) { // Concurrent handling started during a forward return; } if (mappedHandler != null) { mappedHandler.triggerAfterCompletion(request, response, null); } } 重点看下render方法，进行渲染： protected void render(ModelAndView mv, HttpServletRequest request, HttpServletResponse response) throws Exception { //设置本地化 Locale locale = this.localeResolver.resolveLocale(request); response.setLocale(locale); View view; if (mv.isReference()) { //解析视图名，得到视图 view = resolveViewName(mv.getViewName(), mv.getModelInternal(), locale, request); } else { // No need to lookup: the ModelAndView object contains the actual View object. view = mv.getView(); if (view == null) { throw new ServletException(&quot;ModelAndView [&quot; + mv + &quot;] neither contains a view name nor a &quot; + &quot;View object in servlet with name &#39;&quot; + getServletName() + &quot;&#39;&quot;); } } //委托给视图进行渲染 view.render(mv.getModelInternal(), request, response); } view.render就是进行视图的渲染，然后跳转页面等处理。 到这里大概的流程就走完了。其中涉及到的东西还有很多，暂先不做详细处理。 原文：SpringMVC执行流程及源码解析","categories":[{"name":"后端","slug":"后端","permalink":"https://jiangxingye.github.io/categories/后端/"}],"tags":[{"name":"java","slug":"java","permalink":"https://jiangxingye.github.io/tags/java/"},{"name":"spring","slug":"spring","permalink":"https://jiangxingye.github.io/tags/spring/"},{"name":"springmvc","slug":"springmvc","permalink":"https://jiangxingye.github.io/tags/springmvc/"}]},{"title":"PostgreSQL常用SQL操作","slug":"postgres-sql-use","date":"2017-04-14T08:37:24.000Z","updated":"2019-09-02T13:02:59.981Z","comments":true,"path":"2017/04/14/postgres-sql-use/","link":"","permalink":"https://jiangxingye.github.io/2017/04/14/postgres-sql-use/","excerpt":"","text":"说明：文章中实例均在 PostgreSQL 环境操作。 DDL数据定义语言数据库/角色/schema-- 创建一个数据库用户 create role &quot;sp-boss&quot; createdb createrole login password &#39;sp-boss&#39;; -- 使用上面角色登录 postgres 数据库 psql -U sp-boss -d postgres -- 创建自己的数据库 create database &quot;sp-boss&quot; -- 登录自己的数据库 psql -U sp-boss -- 创建一个其他用户 create role &quot;sp-manager&quot; login password &#39;sp-manager&#39;; -- 赋予 create 权限 grant create on database &quot;sp-boss&quot; to &quot;sp-manager&quot;; -- 使用 新用户 登录数据库 psql -U sp-manager -d sp-boss -- 创建自己的 schema create schema &quot;sp-manager&quot;; 表--创建表 create table user_info ( id serial primary key, name varchar(20), age integer, create_time timestamp, type integer, display boolean default true, unique (name, type) ); --删除表 drop table exists user_info; --重命名表 alter table user_info rename to user_infos; 字段（列）--添加一列 alter table user_info add [column] username varchar(50); --删除一列 alter table user_info drop [column] username; --重命名列 alter table user_info rename [column] username to name; --修改结构 alter table user_info alter [column] username set not null; -- 唯一约束-- 添加名为 uk_name 的联合唯一约束，组合列为column1和column2 alter table sys_theme add constraint uk_name unique(column1,column2); -- 删除名为 uk_name 的约束 alter table sys_theme drop constraint uk_name; DML数据库操作语言SELECT查询包含json格式的text类型的数据postgres=# select * from person; id | name | other ----+--------+---------------------------------------------------------- 1 | faker | {&quot;gender&quot;:&quot;male&quot;,&quot;address&quot;:&quot;xiamen&quot;,&quot;college&quot;:&quot;xmut&quot;} 2 | watson | {&quot;gender&quot;:&quot;male&quot;,&quot;address&quot;:&quot;shenzhen&quot;,&quot;college&quot;:&quot;szu&quot;} 3 | lance | {&quot;gender&quot;:&quot;male&quot;,&quot;address&quot;:&quot;shenzhen&quot;,&quot;college&quot;:&quot;xmut&quot;} 4 | jine | {&quot;gender&quot;:&quot;female&quot;,&quot;address&quot;:&quot;xiamen&quot;,&quot;college&quot;:&quot;xmut&quot;} 5 | jobs | {&quot;gender&quot;:&quot;male&quot;,&quot;address&quot;:&quot;beijing&quot;,&quot;college&quot;:&quot;xmu&quot;} 6 | yak | {&quot;gender&quot;:&quot;female&quot;,&quot;address&quot;:&quot;xiamen&quot;,&quot;college&quot;:&quot;xmut&quot;} 7 | alice | {&quot;gender&quot;:&quot;female&quot;,&quot;address&quot;:&quot;shanghai&quot;,&quot;college&quot;:&quot;thu&quot;} 8 | anita | {&quot;gender&quot;:&quot;female&quot;,&quot;address&quot;:&quot;xiongan&quot;,&quot;college&quot;:&quot;hku&quot;} (8 行记录) -- 查询深圳学生的高校分部情况 select other::json-&gt;&gt;&#39;college&#39; college, count(1) from person where other::json-&gt;&gt;&#39;address&#39;=&#39;shenzhen&#39; group by other::json-&gt;&gt;&#39;college&#39;; ___________________________ college | count ---------+------- szu | 1 xmut | 1 (1 行记录) --- 结果可得深圳一共有两个学生， --- 在深圳大学和厦门理工学院各一个。","categories":[{"name":"数据库","slug":"数据库","permalink":"https://jiangxingye.github.io/categories/数据库/"}],"tags":[{"name":"postgres","slug":"postgres","permalink":"https://jiangxingye.github.io/tags/postgres/"},{"name":"sql","slug":"sql","permalink":"https://jiangxingye.github.io/tags/sql/"}]},{"title":"npm使用介绍","slug":"npm","date":"2017-03-16T12:09:48.000Z","updated":"2019-09-02T13:02:59.988Z","comments":true,"path":"2017/03/16/npm/","link":"","permalink":"https://jiangxingye.github.io/2017/03/16/npm/","excerpt":"","text":"Whatnpm（全称Node Package Manager，即node包管理器）是Node.js默认的、以JavaScript编写的软件包管理系统。作者：艾萨克·施吕特（Isaac Z. Schlueter） 安装npm 是随同node.js一起安装的，所以安装node.js即可。 使用# 查看版本 $ npm -v # 升级 $ sudo npm install npm -g # 安装模块 $ npm install &lt;Module Name&gt; #本地安装 # 本地安装：安装到./node_modules(命令运行目录) $ npm install &lt;Module Name&gt; -g #全局安装 # 全局安装：放在 /usr/local 下或者你 node 的安装目录。 # 卸载模块 $ npm uninstall &lt;Module Name&gt; # 更新模块 $ npm update &lt;Module Name&gt; # 查看所有安装的模块 $ npm ls #所有本地模块 $ npm ls -g #所有全局模块 # 搜索模块 $ npm search &lt;Module Name&gt;","categories":[{"name":"大前端","slug":"大前端","permalink":"https://jiangxingye.github.io/categories/大前端/"}],"tags":[{"name":"node","slug":"node","permalink":"https://jiangxingye.github.io/tags/node/"}]},{"title":"不蒜子适配pjax","slug":"busuanzi-pjax","date":"2017-03-09T12:15:51.000Z","updated":"2019-09-02T13:02:59.989Z","comments":true,"path":"2017/03/09/busuanzi-pjax/","link":"","permalink":"https://jiangxingye.github.io/2017/03/09/busuanzi-pjax/","excerpt":"","text":"不蒜子一般配置加入脚本 &lt;script async src=&quot;//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js&quot;&gt;&lt;/script&gt; &lt;!--pv方式 --&gt; &lt;span id=&quot;busuanzi_container_site_pv&quot;&gt; 本站总访问量&lt;span id=&quot;busuanzi_value_site_pv&quot;&gt;&lt;/span&gt;次 &lt;/span&gt; &lt;!--uv方式 --&gt; &lt;span id=&quot;busuanzi_container_site_uv&quot;&gt; 本站访客数&lt;span id=&quot;busuanzi_value_site_uv&quot;&gt;&lt;/span&gt;人次 &lt;/span&gt; &lt;!--pv方式 --&gt; &lt;span id=&quot;busuanzi_container_page_pv&quot;&gt; 本文总阅读量&lt;span id=&quot;busuanzi_value_page_pv&quot;&gt;&lt;/span&gt;次 &lt;/span&gt; 只安装脚本，不安装标签代码，即可实现只记数，不显示。 适配pjax最近开发3-hexo主题，由于主题使用的pjax，异步加载页面时不蒜子会出现加载不到多说js的问题。在pjax：end加载下面js代替标签即可 $.getScript(&quot;//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js&quot;);","categories":[{"name":"大前端","slug":"大前端","permalink":"https://jiangxingye.github.io/categories/大前端/"}],"tags":[{"name":"jQuery","slug":"jQuery","permalink":"https://jiangxingye.github.io/tags/jQuery/"},{"name":"hexo","slug":"hexo","permalink":"https://jiangxingye.github.io/tags/hexo/"}]},{"title":"多说适配pjax","slug":"duoshuo-pjax","date":"2017-03-09T11:50:45.000Z","updated":"2019-09-02T13:02:59.989Z","comments":true,"path":"2017/03/09/duoshuo-pjax/","link":"","permalink":"https://jiangxingye.github.io/2017/03/09/duoshuo-pjax/","excerpt":"","text":"最近开发3-hexo主题，由于主题使用的pjax，异步加载页面时多说会出现加载不到多说js的问题。 多说加载代码如下： //加载多说 function loadComment() { duoshuoQuery = {short_name: $(&quot;.theme_duoshuo_domain&quot;).val()}; var d = document, s = d.createElement(&#39;script&#39;); s.src = &#39;https://static.duoshuo.com/embed.js?t=&#39;+new Date().getTime(); s.async = true; s.charset = &#39;UTF-8&#39;; (d.head || d.body).appendChild(s); } 当局部加载页面时，就会无法加载多说。需要编写一个js方法，参考文档：(http://dev.duoshuo.com/docs/50b344447f32d30066000147) /** * pjax后需要回调函数.加载多说 */ function pajx_loadDuodsuo(){ if(typeof duoshuoQuery ==&quot;undefined&quot;){ loadComment(); } else { var dus=$(&quot;.ds-thread&quot;); if($(dus).length==1){ var el = document.createElement(&#39;div&#39;); el.setAttribute(&#39;data-thread-key&#39;,$(dus).attr(&quot;data-thread-key&quot;));//必选参数 el.setAttribute(&#39;data-url&#39;,$(dus).attr(&quot;data-url&quot;)); DUOSHUO.EmbedThread(el); $(dus).html(el); } } } 在pjax:end中调用此方法即可。","categories":[{"name":"大前端","slug":"大前端","permalink":"https://jiangxingye.github.io/categories/大前端/"}],"tags":[{"name":"jQuery","slug":"jQuery","permalink":"https://jiangxingye.github.io/tags/jQuery/"},{"name":"hexo","slug":"hexo","permalink":"https://jiangxingye.github.io/tags/hexo/"}]},{"title":"[译]理解浏览器关键渲染路径","slug":"understanding-the-critical-rendering-path","date":"2017-03-08T00:58:21.000Z","updated":"2019-09-02T13:02:59.990Z","comments":true,"path":"2017/03/08/understanding-the-critical-rendering-path/","link":"","permalink":"https://jiangxingye.github.io/2017/03/08/understanding-the-critical-rendering-path/","excerpt":"","text":"当一个浏览器接收到从服务器发来的html页面，在渲染并呈现到屏幕上之前，有很多步骤要做。浏览器渲染页面需要做的一系列行为被称作“关键渲染路径（Critical Rendering Path 简称CRP）”。 CRP 的知识对于如何提升网站性能是相当有用的。CRP有6个步骤： 构建DOM树 构建CSSOM树 运行JavaScript 创建渲染树 生成布局 绘制页面 构建DOM树DOM（Document Object Model）树是一个表示整个解析过的HTML页面的对象，从根节点&lt;html&gt;开始，会创建页面中的每个 元素/文本 节点。嵌套在其他元素中的元素作为字节点，每个节点都包含了其所有的元素属性，例如： 一个&lt;a&gt;节点将有 href 属性与其关联。 举个例子 &lt;html&gt; &lt;head&gt; &lt;title&gt;Understanding the Critical Rendering Path&lt;/title&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;style.css&quot;&gt; &lt;/head&gt; &lt;body&gt; &lt;header&gt; &lt;h1&gt;Understanding the Critical Rendering Path&lt;/h1&gt; &lt;/header&gt; &lt;main&gt; &lt;h2&gt;Introduction&lt;/h2&gt; &lt;p&gt;Lorem ipsum dolor sit amet&lt;/p&gt; &lt;/main&gt; &lt;footer&gt; &lt;small&gt;Copyright 2017&lt;/small&gt; &lt;/footer&gt; &lt;/body&gt; &lt;/html&gt; 上面的 HTML 将会被解析成下面的DOM树HTML的优点在于它不必等待整个页面加载完成才呈现页面，可以解析一部分，显示一部分。但是像CSS、JavaScript等其他资源会阻止页面渲染。 构建CSSOM树CSSOM（CSS Object Model） 是一个跟DOM相关的样式对象。它跟DOM的表示方法是相似的，但是不论显式声明还是隐式继承，每个节点都存在关联样式。 In the style.css file from the document mentioned above, we have the folowing styles在上面提到的html页面的style.css中的样式如下 body { font-size: 18px; } header { color: plum; } h1 { font-size: 28px; } main { color: firebrick; } h2 { font-size: 20px; } footer { display: none; } 它会被构建成下面的CSSOM树CSS 被认为是 “渲染阻塞资源”，它意味着如果不首先完全解析资源，渲染树是无法构建的。CSS由于它的层叠继承的性质，不能像HTML一样解析一部分，显示一部分。定义在文档后面的样式会覆盖或改写之前定义的样式，因为在整个样式表都被解析之前，如果我们使用了在样式表中较早定义的样式，那错误的样式将被应用。这意味着CSS必须被全部解析之后，才能开始下一步。 如果CSS文件适用于当前设备的话，仅仅只是会阻塞渲染。&lt;link rel=&quot;stylesheet&quot;&gt;标签可以使用media属性，用来指定特定样式宽度的特定媒体查询。 举个例子，如果我们有一个包含媒体属性orientation:landscape的样式，我们使用纵向模式（portrait mode）查看页面，这个资源将不会阻塞渲染。 CSS 也会导致脚本阻塞。这是因为JavaScript文件必须等待CSSOM被构建后才能运行。 运行JavaScriptJavaScript被认为是解析阻塞资源，这意味着HTML的解析会被JavaScript阻塞。 当解析器解析到 &lt;script&gt; 标签时，无论该资源是内部还是外链的都会停止解析，先去下载资源。这也是为什么，当页面内有引用JavaScript文件时，引用标签要放到可视元素之后了。 为避免JavaScript解析阻塞，它可以通过设定 async 属性来要求其异步加载。 &lt;script async src=&quot;script.js&quot;&gt; 创建渲染树渲染树是DOM和CSSOM的结合体，它代表最终会渲染在页面上的元素的结构对象。这意味着它只关注可见内容，对于被隐藏或者CSS属性 display:none 的属性，不会被包含在结构内。 使用上面例子的DOM和CSSOM，渲染树被创建如下： 生成布局布局决定了浏览器视窗的大小,它提供了上下文依赖的CSS样式，如百分比或窗口的单位。视窗尺寸通常通过 &lt;head&gt; 标签中的 &lt;meta&gt; 中的 viewport 设定来决定。如果不存在该标签，则通常默认为 980px 例如，最常用的 meta veiwport 的值将会被设置为和设备宽度相符： &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,initial-scale=1&quot;&gt; 如果用户访问网页的设备宽度为1000px。然后整体视窗尺寸就会基于这个宽度值了，比如 50% 就是500px, 10vw 就是100px 等等。 绘制页面最后，在绘制页面步骤。页面上的所有可见内容都会被转换为像素并呈现在屏幕上。 具体的绘制时间跟DOM数以及应用的样式有关。有些样式会花费更多的执行时间，比如复杂的渐变背景图片所需要的计算时间远超过简单固定背景色。 整合所有想要看到关键渲染路径的执行流程，可以使用DevTools，在Chrome中，它是根据时间轴展示的。 举个例子, 上面的页面加入&lt;script&gt;标签 &lt;html&gt; &lt;head&gt; &lt;title&gt;Understanding the Critical Rendering Path&lt;/title&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;style.css&quot;&gt; &lt;/head&gt; &lt;body&gt; &lt;header&gt; &lt;h1&gt;Understanding the Critical Rendering Path&lt;/h1&gt; &lt;/header&gt; &lt;main&gt; &lt;h2&gt;Introduction&lt;/h2&gt; &lt;p&gt;Lorem ipsum dolor sit amet&lt;/p&gt; &lt;/main&gt; &lt;footer&gt; &lt;small&gt;Copyright 2017&lt;/small&gt; &lt;/footer&gt; &lt;script src=&quot;main.js&quot;&gt;&lt;/script&gt; &lt;/body&gt; &lt;/html&gt; 可以看关于页面加载时的事件日志，以下是我们获得的： Send Request - 发送到index.html的GET请求 Parse HTML and Send Request - 开始解析HTML并构建DOM，然后发送 GET 请求style.css和main.js Parse Stylesheet - 根据 style.css 创建的CSSOM Evaluate Script - 执行 main.js Layout - 基于HTML的元视窗标签，生成布局 Paint - 绘制网页基于这些信息，我们可以知道如何优化关键渲染路径。 原文： Understanding the Critical Rendering Path","categories":[{"name":"大前端","slug":"大前端","permalink":"https://jiangxingye.github.io/categories/大前端/"}],"tags":[{"name":"translation","slug":"translation","permalink":"https://jiangxingye.github.io/tags/translation/"}]},{"title":"Vim命令速查表","slug":"Vim-command","date":"2017-03-06T03:23:36.000Z","updated":"2019-09-02T13:02:59.994Z","comments":true,"path":"2017/03/06/Vim-command/","link":"","permalink":"https://jiangxingye.github.io/2017/03/06/Vim-command/","excerpt":"","text":"去年上半年开始全面使用linux进行开发和娱乐了，现在已经回不去windows了。 话归正传，在linux上一直使用vim，慢慢熟悉了它的命令，才终于领悟了什么是编辑器之神。 最近抽空整理了这份速查表，收获颇丰，并分享给大家。 进入vim 命令 描述 vim filename 打开或新建文件,并将光标置于第一行首 vim +n filename 打开文件，并将光标置于第n行首 vim + filename 打开文件，并将光标置于最后一行首 vim +/pattern filename 打开文件，并将光标置于第一个与pattern匹配的串处 vim -r filename 在上次正用vim编辑时发生系统崩溃，恢复filename vim filename….filename 打开多个文件，依次编辑 vim配置 命令 描述 all 列出所有选项设置情况 term 设置终端类型 ignorance 在搜索中忽略大小写 list 显示制表位(Ctrl+I)和行尾标志（$) number 显示行号 report 显示由面向行的命令修改过的数目 terse 显示简短的警告信息 warn 在转到别的文件时若没保存当前文件则显示NO write信息 nomagic 允许在搜索模式中，使用前面不带“\\”的特殊字符 nowrapscan 禁止vi在搜索到达文件两端时，又从另一端开始 mesg 允许vi显示其他用户用write写到自己终端上的信息 :set number / set nonumber 显示/不显示行号 :set ruler /set noruler 显示/不显示标尺 :set hlsearch 高亮显示查找到的单词 :set nohlsearch 关闭高亮显示 :syntax on 语法高亮 :set nu 显示行号 :set ignorecase 搜索时忽略大小写 :set smartcase 搜索时匹配大小写 :set ruler 显示光标位置坐标 :set hlsearch 搜索匹配全高亮 :set tabstop=8 设置tab大小,8为最常用最普遍的设置 :set softtabstop=8 4:4个空格,8:正常的制表符,12:一个制表符4个空格,16:两个制表符 :set autoindent 自动缩进 :set cindent C语言格式里面的自动缩进 移动光标 命令 描述 k nk 上 向上移动n行 j nj 下 向下移动n行 h nh 左 向左移动n行 l nl 右 向右移动n行 Space 光标右移一个字符 Backspace 光标左移一个字符 Enter 光标下移一行 w/W 光标右移一个字至字首 b/B 光标左移一个字至字首 e或E 光标右移一个字至字尾 ) 光标移至句尾 ( 光标移至句首 } 光标移至段落开头 { 光标移至段落结尾 n$ 光标移至第n行尾 H 光标移至屏幕顶行 M 光标移至屏幕中间行 L 光标移至屏幕最后行 0 （注意是数字零）光标移至当前行首 ^ 移动光标到行首第一个非空字符上去 $ 光标移至当前行尾 gg 移到第一行 G 移到最后一行 f 移动光标到当前行的字符a上 F 相反 % 移动到与制匹配的括号上去（），{}，[]，&lt;&gt;等 nG 移动到第n行上 G 到最后一行 屏幕滚动 命令 描述 Ctrl+e 向文件首翻一行 Ctrl+y 向文件尾翻一行 Ctrl+u 向文件首翻半屏 Ctrl+d 向文件尾翻半屏 Ctrl+f 向文件尾翻一屏 Ctrl+b 向文件首翻一屏 nz 将第n行滚至屏幕顶部，不指定n时将当前行滚至屏幕顶部 插入文本类 命令 描述 i 在光标前 I 在当前行首 a 光标后 A 在当前行尾 o 在当前行之下新开一行 O 在当前行之上新开一行 r 替换当前字符 R 替换当前字符及其后的字符，直至按ESC键 s 从当前光标位置处开始，以输入的文本替代指定数目的字符 S 删除指定数目的行，并以所输入文本代替之 ncw/nCW 修改指定数目的字 nCC 修改指定数目的行 删除命令 命令 描述 x/X 删除一个字符，x删除光标后的，而X删除光标前的 dw 删除一个单词(删除光标位置到下一个单词开始的位置) dnw 删除n个单词 dne 也可，只是删除到单词尾 do 删至行首 d$ 删至行尾 dd 删除一行 ndd 删除当前行及其后n-1行 dnl 向右删除n个字母 dnh 向左删除n个字母 dnj 向下删除n行,当前行+其上n行 dnk 向上删除n行,当期行+其下n行 cnw[word] 将n个word改变为word C$ 改变到行尾 cc 改变整行 shift+j 删除行尾的换行符，下一行接上来了 复制粘贴 命令 描述 p 粘贴用x或d删除的文本 ynw 复制n个单词 yy 复制一行 ynl 复制n个字符 y$ 复制当前光标至行尾处 nyy 拷贝n行 撤销 命令 描述 u 撤销前一次的操作 shif+u(U) 撤销对该行的所有操作 搜索及替换 命令 描述 /pattern 从光标开始处向文件尾搜索pattern ?pattern 从光标开始处向文件首搜索pattern n 在同一方向重复上一次搜索命令 N 在反方向上重复上一次搜索命令 cw newword 替换为newword n 继续查找 . 执行替换 :s/p1/p2/g 将当前行中所有p1均用p2替代,g表示执行 用c表示需要确认 :n1,n2 s/p1/p2/g 将第n1至n2行中所有p1均用p2替代 :g/p1/s//p2/g 将文件中所有p1均用p2替换 :1,$ s/string1/string2/g 在全文中将string1替换为string2 书签 命令 描述 m[a-z] 在文中做标记，标记号可为a-z的26个字母 `a 移动到标记a处 visual模式 命令 描述 v 进入visual 模式 V 进入行的visual 模式 ctrl+v 进如块操作模式用o和O改变选择的边的大小 在所有行插入相同的内容如include&lt; 将光标移到开始插入的位置，按CTRL+V进入VISUAL模式，选择好模块后按I（shift+i)，后插入要插入的文本，按[ESC]完成 行方式命令 命令 描述 :n1,n2 co n3 将n1行到n2行之间的内容拷贝到第n3行下 :n1,n2 m n3 将n1行到n2行之间的内容移至到第n3行下 :n1,n2 d 将n1行到n2行之间的内容删除 :n1,n2 w!command 将文件中n1行至n2行的内容作为command的输入并执行之若不指定n1，n2，则表示将整个文件内容作为command的输入 宏 命令 描述 q[a-z] 开始记录但前开始的操作为宏，名称可为【a-z】，然后用q终止录制宏 reg 显示当前定义的所有的宏，用@[a-z]来在当前光标处执行宏[a-z] 窗口操作 命令 描述 :split 分割一个窗口 :split file.c 为另一个文件file.c分隔窗口 :nsplit file.c 为另一个文件file.c分隔窗口，并指定其行数 ctrl＋w 在窗口中切换 :close 关闭当前窗口 文件及其他 命令 描述 :q 退出vi :q! 不保存文件并退出vi :e filename 打开文件filename进行编辑 :e! 放弃修改文件内容，重新载入该文件编辑 :w 保存当前文件 :wq 存盘退出 :ZZ 保存当前文档并退出VIM :!command 执行shell命令command :r!command 将命令command的输出结果放到当前行 :n1,n2 write temp.c :read file.c 将文件file.c的内容插入到当前光标所在的下面","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"vim","slug":"vim","permalink":"https://jiangxingye.github.io/tags/vim/"}]},{"title":"如何在linux中搭建ftp服务","slug":"linux-ftp","date":"2017-03-06T00:47:48.000Z","updated":"2019-09-02T13:03:00.000Z","comments":true,"path":"2017/03/06/linux-ftp/","link":"","permalink":"https://jiangxingye.github.io/2017/03/06/linux-ftp/","excerpt":"","text":"什么是 FTPFTP 是文件传输协议File Transfer Protocol的缩写。顾名思义，FTP用于计算机之间通过网络进行文件传输。你可以通过FTP在计算机账户间进行文件传输，也可以在账户和桌面计算机之间传输文件，或者访问在线软件归档。但是，需要注意的是多数的FTP站点的使用率非常高，可能需要多次重连才能连接上。 FTP地址和HTTP地址（即网页地址）非常相似，只是FTP地址使用 ftp://前缀而不是http:// FTP 服务器是什么通常，拥有FTP地址的计算机是专用于接收FTP连接请求的。一台专用于接收FTP连接请求的计算机即为FTP服务器或者FTP站点。 现在，我们来开始一个特别的冒险，我们将会搭建一个FTP服务用于和家人、朋友进行文件共享。在本教程，我们将以vsftpd作为ftp服务。 VSFTPD是一个自称为最安全的FTP服务端软件。事实上VSFTPD的前两个字母表示“非常安全的very secure”。该软件的构建绕开了FTP协议的漏洞。 尽管如此，你应该知道还有更安全的方法进行文件管理和传输，如：SFTP（使用OpenSSH）。FTP协议对于共享非敏感数据是非常有用和可靠的。 安装 VSFTP#使用 rpm 安装 $ dnf -y install vsftpd #使用 deb 安装 $ sudo apt-get install vsftpd #在 Arch 中安装 $ sudo pacman -S vsftpd 配置 FTP 服务多数的VSFTPD配置项都在/etc/vsftpd.conf配置文件中。这个文件本身已经有非常良好的文档说明了，因此，在本节中，我只强调一些你可能进行修改的重要选项。使用man页面查看所有可用的选项和基本的 文档说明： $ man vsftpd.conf 根据文件系统层级标准，FTP共享文件默认位于/srv/ftp目录中。允许上传：为了允许ftp用户可以修改文件系统的内容，如上传文件等，“write_enable”标志必须设置为 YES write_enable=YES 允许本地（系统）用户登录：为了允许文件/etc/passwd中记录的用户可以登录ftp服务，“local_enable”标记必须设置为YES。 local_enable=YES 匿名用户登录下面配置内容控制匿名用户是否允许登录： # 允许匿名用户登录 anonymous_enable=YES # 匿名登录不需要密码（可选） no_anon_password=YES # 匿名登录的最大传输速率，Bytes/second（可选） anon_max_rate=30000 # 匿名登录的目录（可选） anon_root=/example/directory/ 根目录限制（Chroot Jail）（ LCTT 译注：chroot jail是类unix系统中的一种安全机制，用于修改进程运行的根目录环境，限制该线程不能感知到其根目录树以外的其他目录结构和文件的存在。详情参看chroot jail） 有时我们需要设置根目录（chroot）环境来禁止用户离开他们的家（home）目录。在配置文件中增加/修改下面配置开启根目录限制（Chroot Jail）: chroot_list_enable=YES chroot_list_file=/etc/vsftpd.chroot_list “chroot_list_file”变量指定根目录限制所包含的文件/目录（ LCTT 译注：即用户只能访问这些文件/目录） 最后你必须重启ftp服务，在命令行中输入以下命令： $ sudo systemctl restart vsftpd 到此为止，你的ftp服务已经搭建完成并且启动了。","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"ftp","slug":"ftp","permalink":"https://jiangxingye.github.io/tags/ftp/"}]},{"title":"每天一个linux命令（57）: sftp","slug":"linux-command（57）-sftp","date":"2017-03-05T08:29:38.000Z","updated":"2019-09-02T13:03:00.029Z","comments":true,"path":"2017/03/05/linux-command（57）-sftp/","link":"","permalink":"https://jiangxingye.github.io/2017/03/05/linux-command（57）-sftp/","excerpt":"","text":"sFTP（安全文件传输程序）是一种安全的交互式文件传输程序，其工作方式与 FTP（文件传输协议）类似。 然而，sFTP 比 FTP 更安全；它通过加密 SSH 传输处理所有操作。 它可以配置使用几个有用的 SSH 功能，如公钥认证和压缩。 它连接并登录到指定的远程机器，然后切换到交互式命令模式，在该模式下用户可以执行各种命令。 在本文中，我们将向你展示如何使用 sFTP 上传/下载整个目录（包括其子目录和子文件）。 How to use默认情况下，SFTP 协议采用和 SSH 传输协议一样的方式建立到远程服务器的安全连接。虽然，用户验证使用类似于 SSH 默认设置的密码方式，但是，建议创建和使用 SSH 无密码登录，以简化和更安全地连接到远程主机。 要连接到远程 sftp 服务器，如下建立一个安全 SSH 连接并创建 SFTP 会话： $ sftp root@server 登录到远程主机后，你可以如下运行交互式的 sFTP 命令： sftp&gt; ls #列出服务器文件列表 sftp&gt; lls #列出本地文件列表 sftp&gt; pwd #当前服务器上路径 sftp&gt; lpwd #当前本地路径 sftp&gt; cd img #切换服务器路径 sftp&gt; lcd img #切换本地路径 sftp&gt; mkdir img #在服务器上创建一个目录 sftp&gt; lmkdir img #在本地创建一个目录 上传文件sftp&gt; put readme.md #上传单个文件 sftp&gt; mput *.xls #上传多个文件 下载文件sftp&gt; get readme.md #下载单个文件 sftp&gt; mget *.xls #下载多个文件 上传文件夹使用put -r .但是远程服务器要提前创建一个相同名称的目录; -r 递归复制子目录和子文件 sftp&gt; mkdir img sftp&gt; put -r img 要保留修改时间、访问时间以及被传输的文件的模式，可使用 -p 。 sftp&gt; put -pr img 下载文件夹sftp&gt; get -r img 退出sftp&gt; bye 或 sftp&gt; exit 或 ctrl + d","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"https://jiangxingye.github.io/tags/linux命令/"}]},{"title":"AngularJs快速入门","slug":"AngularJs","date":"2017-03-04T00:40:58.000Z","updated":"2019-09-02T13:02:59.982Z","comments":true,"path":"2017/03/04/AngularJs/","link":"","permalink":"https://jiangxingye.github.io/2017/03/04/AngularJs/","excerpt":"","text":"简介 AngularJS是一个JavaScript框架，为了克服HTML在构建应用上的不足而设计的。 AngularJS通过使用我们称为标识符(directives)的结构，让浏览器能够识别新的语法。 AngularJS 使得开发现代的单一页面应用程序（SPAs：Single Page Applications）变得更加容易。 表达式AngularJS 使用 表达式 把数据绑定到 HTML。 表达式AngularJS 表达式写在双大括号内：{{ expression }} 。AngularJS 表达式把数据绑定到 HTML，这与 ng-bind 指令有异曲同工之妙。AngularJS 将在表达式书写的位置”输出”数据。AngularJS 表达式 很像 JavaScript 表达式：它们可以包含文字、运算符和变量。实例： {{ 5 + 5 }} 或 {{ firstName + \" \" + lastName }} &lt;div ng-app=&quot;&quot;&gt; &lt;p&gt;我的第一个表达式: {{ 5 + 5 }}&lt;/p&gt; &lt;/div&gt; 效果 数字&lt;div ng-app=&quot;&quot; ng-init=&quot;quantity=1;cost=5&quot;&gt; &lt;p&gt;总价： {{ quantity * cost }}&lt;/p&gt; &lt;/div&gt;","categories":[{"name":"大前端","slug":"大前端","permalink":"https://jiangxingye.github.io/categories/大前端/"}],"tags":[{"name":"AngularJs","slug":"AngularJs","permalink":"https://jiangxingye.github.io/tags/AngularJs/"}]},{"title":"[译]Java内存泄露介绍","slug":"the-introduction-of-memory-leak-what-why-and-how","date":"2017-02-21T07:05:39.000Z","updated":"2019-09-02T13:02:59.976Z","comments":true,"path":"2017/02/21/the-introduction-of-memory-leak-what-why-and-how/","link":"","permalink":"https://jiangxingye.github.io/2017/02/21/the-introduction-of-memory-leak-what-why-and-how/","excerpt":"","text":"内存管理是Java最大的优势之一；你可以很简单的创建一个对象，内存的分配和释放则交给Java垃圾收集器处理；然而实际情况并非如此简单，因为在Java应用程序中会频繁的发生内存泄露。 这个教程将会说明内存泄露是什么？它为什么会发生？我们如何防止它？ 内存泄露是什么内存泄露的定义：对象不再被应用程序使用，但是由于它们还在被引用，垃圾收集器不能清除掉它们。 为了理解这个定义，我们需要理解对象在内存中的状态；下面的图表说明什么是未被使用和未被引用。 图表中，有被引用的对象和未被引用的对象；未被引用的对象将会被当做垃圾回收，而被引用的对象将不会被当做垃圾回收；未被引用的对象由于没有被其他对象引用，它当然也是不被使用的对象，然而，不被使用的对象不全是不被引用的，它们中的一些是被引用的！这就是内存泄露的来源。 内存泄露为什么会发生让我们来看一下下面这个例子，它说明了内存泄露为什么会发生。在下面这个列子中，对象A引用了对象B，A的生命周期（t1~t4）是比B（t2~t3）的长；当B不再被应用程序使用时，A仍然在引用它；在这种情况下，垃圾收集器不能从内存中移除B；如果A引用了很多类似B这样的对象，它们不能被回收，又消耗着内存空间的资源，这样很有可能造成内存不足的问题。 还有一种可能的事情，B又引用了一些对象，这些被B引用的对象也不能被回收，那所有这些不被使用的对象将消耗大量宝贵的内存空间。 如何防止内存泄露下面有一些防止内存泄露的快速实践技巧 注意集合类，如：HashMap、ArrayList等等，因为它们是在常见的地方发生内存泄露；当它们被static声明时，它们和应用程序的生命周期是一样长的。 注意事件监听和回调，当一个监听事件被注册，而这个类再也没有被使用时可能会发生内存泄露。 “如果一个类管理自己的内存，程序员应该被提醒内存泄漏了”，通常，一个对象的指向其他对象的成员变量需要被置为null。 References：[1] Program Creek :The Introduction of Java Memory Leaks","categories":[{"name":"后端","slug":"后端","permalink":"https://jiangxingye.github.io/categories/后端/"}],"tags":[{"name":"java","slug":"java","permalink":"https://jiangxingye.github.io/tags/java/"},{"name":"translation","slug":"translation","permalink":"https://jiangxingye.github.io/tags/translation/"}]},{"title":"每天一个linux命令（56）: tailf","slug":"linux-command（56）-tailf","date":"2017-02-20T07:11:06.000Z","updated":"2019-09-02T13:03:00.028Z","comments":true,"path":"2017/02/20/linux-command（56）-tailf/","link":"","permalink":"https://jiangxingye.github.io/2017/02/20/linux-command（56）-tailf/","excerpt":"tailf 一个实时监听文件或日志的强大的命令","text":"tailf 一个实时监听文件或日志的强大的命令 命令格式$ tailf [option] file 命令描述 tailf 将会打印出一个文件的最后10行,等待并持续输出此文件的增长，它和tail -f相似，不同之处是当文件没有增长时，是不访问此文件的；但这会有一个副作用：不会更新文件的访问时间。当没有发生日志活动时，文件系统的冲洗（flush）不会定期发生。 tailf 对于打印日志不频繁，而又在使用笔记本电脑时是非常有用的，这样用户就能降低磁盘转速从而增加笔记本续航。 命令参数 参数 描述 -n,–lines=N,-N 输出最后N行,而不是默认的最后10行 命令实例例一：展示一个文件的最后5行并监听文件的新行（新增加的内容） $ tailf -n 5 myfile.txt $ tailf -5 myfile.txt $ tailf --lines=5 myfile.txt 注：这是一个实时监听文件或日志的强大的命令 例二：实时新增日志内容，并通过管道过滤出自己想要的内容 # 实时监听ip地址为24.10.160.10的访问日志 $ tailf access.log | grep 24.10.160.10","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"https://jiangxingye.github.io/tags/linux命令/"}]},{"title":"pjax用法","slug":"pjax","date":"2017-02-08T12:18:54.000Z","updated":"2019-09-02T13:02:59.989Z","comments":true,"path":"2017/02/08/pjax/","link":"","permalink":"https://jiangxingye.github.io/2017/02/08/pjax/","excerpt":"最近在开发一款hexo主题3-hexo，其中使用了pjax大大提高了用户体验和加载速度，在此简单介绍一下pjax的用法github链接","text":"最近在开发一款hexo主题3-hexo，其中使用了pjax大大提高了用户体验和加载速度，在此简单介绍一下pjax的用法github链接 pjax是什么 pjax是一款jQuery插件，使用了ajax和pushState的技术，在保留真正永久链接，网页标题和可用的返回功能的情况下，带来一种快速的浏览体验。 –官方介绍 用人话说，就是当跳转过去的网页和当前网页的一部分是一样的，这时可以通过pjax就会从响应页面中取出 不同的那部分 （需指定），替换掉原来的内容。 如果在服务端判断处理，直接返回 不同的那部分内容，这样就可以减少带宽占用，提升加载速度。 这样做的优势： 由于从服务器取回的数据量变少，加载速度将会提升。 并且采用异步刷新页面中的不一样的地方，用户体验也是满满的。 保留了浏览器回退的功能（解决了ajax的尴尬） 好了，开始操作。 Demo第一步：引入jQuery和jQuery.pjax &lt;script src=&quot;//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js&quot;&gt;&lt;/script&gt; &lt;script src=&quot;//cdnjs.cloudflare.com/ajax/libs/jquery.pjax/1.9.6/jquery.pjax.min.js&quot;&gt;&lt;/script&gt; 第二步：将指定的a的链接，转为pjax风格 /*将#menu中的a的链接的页面，只取回class=pjax元素中的内容，替换掉当前页面class=pjax元素中的内容*/ $(document).pjax(&#39;.#menu a&#39;, &#39;.pjax&#39;, {fragment:&#39;.pjax&#39;, timeout:8000}); 第三步：如果需要在请求的过程中做一些自定义的事件，可以使用下面的方法 $(document).on({ &#39;pjax:click&#39;: function() { //点击链接时，需要触发的事件写到这里 }, &#39;pjax:start&#39;: function() { //当开始获取请求时，需要触发的事件写在这里 }, &#39;pjax:end&#39;: function() { //当请求完成后，需要触发的事件写在这里 } }); 结束。 详细文档翻译于官方 参数$(document).pjax(selector, [container], options) selector 触发点击事件的选择器，String类型 container 一个选择器，为唯一的pjax容器 options 一个可以包含下面这些选项的对象 pjax options key default description timeout 650 ajax超时时间，单位毫秒，超时后将请求整个页面进行刷新 push true 使用 pushState 添加一个浏览器历史导航条目 replace false 替换URL，而不添加浏览器历史条目 maxCacheLength 20 历史内容 cache 的最大size version string ： 当前pjax版本 scrollTo 0 垂直位置滚动，为了避免改变滚动条位置 type “GET” 可以查看jQuery.ajax() dataType “html” 可以查看jQuery.ajax() container css选择器，此元素内容将被替换 url link.href string: ajax 请求的URL target link eventually the relatedTarget value for pjax events fragment 从ajax响应的页面中抽取的‘片段’ Events除了pjax:click和pjax:clicked外的所有pjax事件从pjax容器中触发，是不需要点击链接的。所有事件的生命周期在通过pjax请求链接的过程中 event cancel arguments notes pjax:click ✔︎ options 在一个链接被激活（点击）时触发此事件，可以在此取消阻止pjax pjax:beforeSend ✔︎ xhr, options 可以设置 XHR 头 pjax:start xhr, options pjax:send xhr, options pjax:clicked options 当链接被点击，并且已经开始pjax请求后触发 pjax:beforeReplace contents, options 从服务器已经加载到HTML内容，在替换HTML内容之前触发 pjax:success data, status, xhr, options 从服务器已经加载到HTML内容，在替换HTML内容之后触发 pjax:timeout ✔︎ xhr, options 页面将会在options.timeout之后直接发起请求刷新页面，除非取消pjax pjax:error ✔︎ xhr, textStatus, error, options ajax 错误，将会请求刷新页面，除非取消pjax pjax:complete xhr, textStatus, options 不管结果是什么，在ajax后，都触发 pjax:end xhr, options 生命周期在浏览器返回或前进时触发 event cancel arguments notes pjax:popstate 事件方向(前进，后退)属性: “back”/“forward” pjax:start null, options 替换内容前 pjax:beforeReplace contents, options 从cache中读取内容后，替换html前 pjax:end null, options 替换内容后","categories":[{"name":"大前端","slug":"大前端","permalink":"https://jiangxingye.github.io/categories/大前端/"}],"tags":[{"name":"jQuery","slug":"jQuery","permalink":"https://jiangxingye.github.io/tags/jQuery/"}]},{"title":"每天一个linux命令","slug":"linux-command","date":"2017-01-23T03:41:48.000Z","updated":"2019-09-02T13:03:00.001Z","comments":true,"path":"2017/01/23/linux-command/","link":"","permalink":"https://jiangxingye.github.io/2017/01/23/linux-command/","excerpt":"开始详细的系统的学习linux命令，坚持每天一个命令。","text":"开始详细的系统的学习linux命令，坚持每天一个命令。此系列最初参考peida的“ 每天一个linux命令”，之后根据自己的见闻逐渐添加整理。 文件目录操作命令 每天一个linux命令（1）: ls 每天一个linux命令（2）: cd 每天一个linux命令（3）: pwd 每天一个linux命令（4）: mkdir 每天一个linux命令（5）: rm 每天一个linux命令（6）: rmdir 每天一个linux命令（7）: mv 每天一个linux命令（8）: cp 每天一个linux命令（9）: touch 每天一个linux命令（10）: cat 每天一个linux命令（11）: nl 每天一个linux命令（12）: more 每天一个linux命令（13）: less 每天一个linux命令（14）: head 每天一个linux命令（15）: tail 每天一个linux命令（56）: tailf 文件查找命令 每天一个linux命令（16）: which 每天一个linux命令（17）: whereis 每天一个linux命令（18）: locate 每天一个linux命令（19）: find命令概览 每天一个linux命令（20）: find命令之exec 每天一个linux命令（21）: find命令之xargs 每天一个linux命令（22）: find命令的参数详解 文件打包上传和下载 每天一个linux命令（23）: 用SecureCRT来上传和下载文件 每天一个linux命令（24）: tar 每天一个linux命令（25）: gzip linux文件权限设置 每天一个linux命令（26）: chmod 每天一个linux命令（27）: chgrp 每天一个linux命令（28）: chown 磁盘存储相关 每天一个linux命令（30）: df 每天一个linux命令（31）: du 性能监控和优化命令 每天一个linux命令（32）: top 每天一个linux命令（33）: free 每天一个linux命令（34）: vmstat 每天一个linux命令（35）: iostat 每天一个linux命令（36）: lsof 网络命令 每天一个linux命令（37）: ifconfig 每天一个linux命令（38）: route 每天一个linux命令（39）: ping 每天一个linux命令（40）: traceroute 每天一个linux命令（41）: netstat 每天一个linux命令（42）: ss 每天一个linux命令（43）: telnet 每天一个linux命令（44）: rcp 每天一个linux命令（45）: scp 其他命令 每天一个linux命令（46）: ln 每天一个linux命令（47）: diff 每天一个linux命令（48）: date 每天一个linux命令（49）: cal 每天一个linux命令（50）: grep 每天一个linux命令（51）: wc 每天一个linux命令（52）: ps 每天一个linux命令（53）: watch 每天一个linux命令（54）: at 每天一个linux命令（55）: crontab 每天一个linux命令（56）: tailf 每天一个linux命令（57）: sftp","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"https://jiangxingye.github.io/tags/linux命令/"}]},{"title":"每天一个linux命令（55）: crontab","slug":"linux-command（55）-crontab","date":"2017-01-23T02:44:50.000Z","updated":"2019-09-02T13:03:00.028Z","comments":true,"path":"2017/01/23/linux-command（55）-crontab/","link":"","permalink":"https://jiangxingye.github.io/2017/01/23/linux-command（55）-crontab/","excerpt":"前一天学习了 at 命令是针对仅运行一次的任务，循环运行的例行性计划任务，linux系统则是由 cron (crond) 这个系统服务来控制的。Linux 系统上面原本就有非常多的计划性工作，因此这个系统服务是默认启动的。另外, 由于使用者自己也可以设置计划任务，所以， Linux 系统也提供了使用者控制计划任务的命令 :crontab 命令。","text":"前一天学习了 at 命令是针对仅运行一次的任务，循环运行的例行性计划任务，linux系统则是由 cron (crond) 这个系统服务来控制的。Linux 系统上面原本就有非常多的计划性工作，因此这个系统服务是默认启动的。另外, 由于使用者自己也可以设置计划任务，所以， Linux 系统也提供了使用者控制计划任务的命令 :crontab 命令。 crond简介 crond是linux下用来周期性的执行某种任务或等待处理某些事件的一个守护进程，与windows下的计划任务类似，当安装完成操作系统后，默认会安装此服务工具，并且会自动启动crond进程，crond进程每分钟会定期检查是否有要执行的任务，如果有要执行的任务，则自动执行该任务。 Linux下的任务调度分为两类，系统任务调度和用户任务调度。 系统任务调度：系统周期性所要执行的工作，比如写缓存数据到硬盘、日志清理等。在/etc目录下有一个crontab文件，这个就是系统任务调度的配置文件。 /etc/crontab文件包括下面几行： # /etc/crontab: system-wide crontab # Unlike any other crontab you don&#39;t have to run the `crontab&#39; # command to install the new version when you edit this file # and files in /etc/cron.d. These files also have username fields, # that none of the other crontabs do. SHELL=/bin/sh PATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin # m h dom mon dow user command 17 * * * * root cd / &amp;&amp; run-parts --report /etc/cron.hourly 25 6 * * * root test -x /usr/sbin/anacron || ( cd / &amp;&amp; run-parts --report /etc/cron.daily ) 47 6 * * 7 root test -x /usr/sbin/anacron || ( cd / &amp;&amp; run-parts --report /etc/cron.weekly ) 52 6 1 * * root test -x /usr/sbin/anacron || ( cd / &amp;&amp; run-parts --report /etc/cron.monthly ) 前四行是用来配置crond任务运行的环境变量，第一行SHELL变量指定了系统要使用哪个shell，这里是bash，第二行PATH变量指定了系统执行命令的路径，第三行MAILTO变量指定了crond的任务执行信息将通过电子邮件发送给root用户，如果MAILTO变量的值为空，则表示不发送任务执行信息给用户，第四行的HOME变量指定了在执行命令或者脚本时使用的主目录。第六至九行表示的含义将在下个小节详细讲述。这里不在多说。 用户任务调度：用户定期要执行的工作，比如用户数据备份、定时邮件提醒等。用户可以使用 crontab 工具来定制自己的计划任务。所有用户定义的crontab 文件都被保存在 /var/spool/cron目录中。其文件名与用户名一致。 使用者权限文件文件：/etc/cron.deny说明：该文件中所列用户不允许使用crontab命令 文件：/etc/cron.allow说明：该文件中所列用户允许使用crontab命令 文件：/var/spool/cron/说明：所有用户crontab文件存放的目录,以用户名命名 crontab文件的含义 用户所建立的crontab文件中，每一行都代表一项任务，每行的每个字段代表一项设置，它的格式共分为六个字段，前五段是时间设定段，第六段是要执行的命令段，格式如下：minute hour day month week command其中： minute： 表示分钟，可以是从0到59之间的任何整数。 hour：表示小时，可以是从0到23之间的任何整数。 day：表示日期，可以是从1到31之间的任何整数。 month：表示月份，可以是从1到12之间的任何整数。 week：表示星期几，可以是从0到7之间的任何整数，这里的0或7代表星期日。 command：要执行的命令，可以是系统命令，也可以是自己编写的脚本文件。 在以上各个字段中，还可以使用以下特殊字符：星号（*）：代表所有可能的值，例如month字段如果是星号，则表示在满足其它字段的制约条件后每月都执行该命令操作。逗号（,）：可以用逗号隔开的值指定一个列表范围，例如，“1,2,5,7,8,9”中杠（-）：可以用整数之间的中杠表示一个整数范围，例如“2-6”表示“2,3,4,5,6”正斜线（/）：可以用正斜线指定时间的间隔频率，例如“0-23/2”表示每两小时执行一次。同时正斜线可以和星号一起使用，例如*/10，如果用在minute字段，表示每十分钟执行一次。 crond服务安装crontab： $ yum install crontabs 服务操作说明： $ /sbin/service crond start //启动服务 $ /sbin/service crond stop //关闭服务 $ /sbin/service crond restart //重启服务 $ /sbin/service crond reload //重新载入配置 查看crontab服务状态： $ service crond status 手动启动crontab服务： $ service crond start 查看crontab服务是否已设置为开机启动，执行命令： $ ntsysv 加入开机自动启动： $ chkconfig –level 35 crond on contab 命令详解命令格式$ crontab [-u user] file $ crontab [-u user] [ -e | -l | -r ] 命令功能 通过crontab 命令，我们可以在固定的间隔时间执行指定的系统指令或 shell script脚本。时间间隔的单位可以是分钟、小时、日、月、周及以上的任意组合。这个命令非常设合周期性的日志分析或数据备份等工作。 命令参数 参数 描述 -u user 用来设定某个用户的crontab服务，例如，“-u ixdba”表示设定ixdba用户的crontab服务，此参数一般有root用户来运行 file file是命令文件的名字,表示将file做为crontab的任务列表文件并载入crontab。如果在命令行中没有指定这个文件，crontab命令将接受标准输入（键盘）上键入的命令，并将它们载入crontab。 -e 编辑某个用户的crontab文件内容。如果不指定用户，则表示编辑当前用户的crontab文件 -l 显示某个用户的crontab文件内容，如果不指定用户，则表示显示当前用户的crontab文件内容 -r 从/var/spool/cron目录中删除某个用户的crontab文件，如果不指定用户，则默认删除当前用户的crontab文件 -i 在删除用户的crontab文件时给确认提示 常用方法例一：创建一个新的crontab文件在考虑向cron进程提交一个crontab文件之前，首先要做的一件事情就是设置环境变量EDITOR。cron进程根据它来确定使用哪个编辑器编辑crontab文件。9 9 %的UNIX和LINUX用户都使用vi，如果你也是这样，那么你就编辑$ HOME目录下的. profile文件，在其中加入这样一行：EDITOR=vi; export EDITOR然后保存并退出。不妨创建一个名为 cron的文件，其中是用户名，例如， davecron。在该文件中加入如下的内容。 # (put your own initials here)echo the date to the console every # 15minutes between 6pm and 6am 0,15,30,45 18-06 * * * /bin/echo &#39;date&#39; &gt; /dev/console 保存并退出。确信前面5个域用空格分隔。 在上面的例子中，系统将每隔1 5分钟向控制台输出一次当前时间。如果系统崩溃或挂起，从最后所显示的时间就可以一眼看出系统是什么时间停止工作的。在有些系统中，用tty1来表示控制台，可以根据实际情况对上面的例子进行相应的修改。为了提交你刚刚创建的crontab文件，可以把这个新创建的文件作为cron命令的参数： $ crontab davecron现在该文件已经提交给cron进程，它将每隔1 5分钟运行一次。同时，新创建文件的一个副本已经被放在/var/spool/cron目录中，文件名就是用户名(即dave)。例二：列出crontab文件 $ crontab -l 说明：你将会看到和上面类似的内容。可以使用这种方法在$ H O M E目录中对crontab文件做一备份： $ crontab -l &gt; $HOME/mycron这样，一旦不小心误删了crontab文件，可以用上一节所讲述的方法迅速恢复。 例三：编辑crontab文件 $ crontab -e 说明：可以像使用v i编辑其他任何文件那样修改crontab文件并退出。如果修改了某些条目或添加了新的条目，那么在保存该文件时， c r o n会对其进行必要的完整性检查。如果其中的某个域出现了超出允许范围的值，它会提示你。我们在编辑crontab文件时，没准会加入新的条目。例如，加入下面的一条： # DT:delete core files,at 3.30am on 1,7,14,21,26,26 days of each month 30 3 1,7,14,21,26 * * /bin/find -name &quot;core&#39; -exec rm {} \\; 现在保存并退出。最好在crontab文件的每一个条目之上加入一条注释，这样就可以知道它的功能、运行时间，更为重要的是，知道这是哪位用户的作业。现在让我们使用前面讲过的crontab -l命令列出它的全部信息： $ crontab -l # (crondave installed on Tue May 4 13:07:43 1999) # DT:ech the date to the console every 30 minites 0,15,30,45 18-06 * * * /bin/echo `date` &gt; /dev/tty1 # DT:delete core files,at 3.30am on 1,7,14,21,26,26 days of each month 30 3 1,7,14,21,26 * * /bin/find -name &quot;core&#39; -exec rm {} \\; 例四：删除crontab文件 $ crontab -r 例五：恢复丢失的crontab文件如果不小心误删了crontab文件，假设你在自己的$ H O M E目录下还有一个备份，那么可以将其拷贝到/var/spool/cron/，其中是用户名。如果由于权限问题无法完成拷贝，可以用： $ crontab 其中，是你在$ H O M E目录中副本的文件名。我建议你在自己的$ H O M E目录中保存一个该文件的副本。我就有过类似的经历，有数次误删了crontab文件（因为r键紧挨在e键的右边）。这就是为什么有些系统文档建议不要直接编辑crontab文件，而是编辑该文件的一个副本，然后重新提交新的文件。有些crontab的变体有些怪异，所以在使用crontab命令时要格外小心。如果遗漏了任何选项，crontab可能会打开一个空文件，或者看起来像是个空文件。这时敲delete键退出，不要按，否则你将丢失crontab文件。 使用实例例一：每1分钟执行一次command * * * * * command 例二：每小时的第3和第15分钟执行 3,15 * * * * command 例三：在上午8点到11点的第3和第15分钟执行 3,15 8-11 * * * command 例四：每隔两天的上午8点到11点的第3和第15分钟执行 3,15 8-11 */2 * * command 例五：每个星期一的上午8点到11点的第3和第15分钟执行 3,15 8-11 * * 1 command 例六：每晚的21:30重启smb 30 21 * * * /etc/init.d/smb restart 例七：每月1、10、22日的4 : 45重启smb 45 4 1,10,22 * * /etc/init.d/smb restart 例八：每周六、周日的1 : 10重启smb 10 1 * * 6,0 /etc/init.d/smb restart 例九：每天18 : 00至23 : 00之间每隔30分钟重启smb 0,30 18-23 * * * /etc/init.d/smb restart 例十：每星期六的晚上11 : 00 pm重启smb 0 23 * * 6 /etc/init.d/smb restart 例十一：每一小时重启smb * */1 * * * /etc/init.d/smb restart 例十二：晚上11点到早上7点之间，每隔一小时重启smb * 23-7/1 * * * /etc/init.d/smb restart 例十三：每月的4号与每周一到周三的11点重启smb 0 11 4 * mon-wed /etc/init.d/smb restart 例十四：一月一号的4点重启smb 0 4 1 jan * /etc/init.d/smb restart 例十五：每小时执行/etc/cron.hourly目录内的脚本 01 * * * * root run-parts /etc/cron.hourly 说明：run-parts这个参数了，如果去掉这个参数的话，后面就可以写要运行的某个脚本名，而不是目录名了 注意事项注意环境变量问题 有时我们创建了一个crontab，但是这个任务却无法自动执行，而手动执行这个任务却没有问题，这种情况一般是由于在crontab文件中没有配置环境变量引起的。 在crontab文件中定义多个调度任务时，需要特别注意的一个问题就是环境变量的设置，因为我们手动执行某个任务时，是在当前shell环境下进行的，程序当然能找到环境变量，而系统自动执行任务调度时，是不会加载任何环境变量的，因此，就需要在crontab文件中指定任务运行所需的所有环境变量，这样，系统执行任务调度时就没有问题了。 不要假定cron知道所需要的特殊环境，它其实并不知道。所以你要保证在shelll脚本中提供所有必要的路径和环境变量，除了一些自动设置的全局变量。所以注意如下3点： 1）脚本中涉及文件路径时写全局路径； 2）脚本执行要用到java或其他环境变量时，通过source命令引入环境变量，如： $ cat start_cbp.sh #!/bin/sh source /etc/profile export RUN_CONF=/home/d139/conf/platform/cbp/cbp_jboss.conf /usr/local/jboss-4.0.5/bin/run.sh -c mev &amp; 3）当手动执行脚本OK，但是crontab死活不执行时。这时必须大胆怀疑是环境变量惹的祸，并可以尝试在crontab中直接引入环境变量解决问题。如： 0 * * * * . /etc/profile;/bin/sh /var/www/java/audit_no_count/bin/restart_audit.sh 注意清理系统用户的邮件日志 每条任务调度执行完毕，系统都会将任务输出信息通过电子邮件的形式发送给当前系统用户，这样日积月累，日志信息会非常大，可能会影响系统的正常运行，因此，将每条任务进行重定向处理非常重要。 例如，可以在crontab文件中设置如下形式，忽略日志输出： 0 */3 * * * /usr/local/apache2/apachectl restart &gt;/dev/null 2&gt;&amp;1 “/dev/null 2&gt;&amp;1”表示先将标准输出重定向到/dev/null，然后将标准错误重定向到标准输出，由于标准输出已经重定向到了/dev/null，因此标准错误也会重定向到/dev/null，这样日志输出问题就解决了。 系统级任务调度与用户级任务调度 系统级任务调度主要完成系统的一些维护操作，用户级任务调度主要完成用户自定义的一些任务，可以将用户级任务调度放到系统级任务调度来完成（不建议这么做），但是反过来却不行，root用户的任务调度操作可以通过“crontab –uroot –e”来设置，也可以将调度任务直接写入/etc/crontab文件，需要注意的是，如果要定义一个定时重启系统的任务，就必须将任务放到/etc/crontab文件，即使在root用户下创建一个定时重启系统的任务也是无效的。 其他注意事项 新创建的cron job，不会马上执行，至少要过2分钟才执行。如果重启cron则马上执行。 当crontab突然失效时，可以尝试/etc/init.d/crond restart解决问题。或者查看日志看某个job有没有执行/报错tail -f /var/log/cron。 千万别乱运行crontab -r。它从Crontab目录（/var/spool/cron）中删除用户的Crontab文件。删除了该用户的所有crontab都没了。 在crontab中%是有特殊含义的，表示换行的意思。如果要用的话必须进行转义\\%，如经常用的date ‘+%Y%m%d’在crontab里是不会执行的，应该换成date ‘+\\%Y\\%m\\%d’。","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"https://jiangxingye.github.io/tags/linux命令/"}]},{"title":"每天一个linux命令（54）: at","slug":"linux-command（54）-at","date":"2017-01-22T02:23:44.000Z","updated":"2019-09-02T13:03:00.027Z","comments":true,"path":"2017/01/22/linux-command（54）-at/","link":"","permalink":"https://jiangxingye.github.io/2017/01/22/linux-command（54）-at/","excerpt":"在windows系统中，windows提供了计划任务这一功能，在控制面板 -&gt; 性能与维护 -&gt; 任务计划， 它的功能就是安排自动运行的任务。 通过’添加任务计划’的一步步引导，则可建立一个定时执行的任务。","text":"在windows系统中，windows提供了计划任务这一功能，在控制面板 -&gt; 性能与维护 -&gt; 任务计划， 它的功能就是安排自动运行的任务。 通过’添加任务计划’的一步步引导，则可建立一个定时执行的任务。 在linux系统中你可能已经发现了为什么系统常常会自动的进行一些任务？这些任务到底是谁在支配他们工作的？在linux系统如果你想要让自己设计的备份程序可以自动在某个时间点开始在系统底下运行，而不需要手动来启动它，又该如何处置呢？ 这些例行的工作可能又分为一次性定时工作与循环定时工作，在系统内又是哪些服务在负责？ 还有，如果你想要每年在老婆的生日前一天就发出一封信件提醒自己不要忘记，linux系统下该怎么做呢？ 今天我们主要学习一下一次性定时计划任务的at命令的用法！ 命令格式$ at [参数] [时间] 命令功能 在一个指定的时间执行一个指定任务，只能执行一次，且需要开启atd进程（ps -ef | grep atd查看， 开启用/etc/init.d/atd start or restart； 开机即启动则需要运行 chkconfig –level 2345 atd on）。 命令参数 参数 描述 -m 当指定的任务被完成之后，将给用户发送邮件，即使没有标准输出 -I atq的别名 -d atrm的别名 -v 显示任务将被执行的时间 -c 打印任务的内容到标准输出 -V 显示版本信息 -q&lt;列队&gt; 使用指定的列队 -f&lt;文件&gt; 从指定文件读入任务而不是从标准输入读入 -t&lt;时间参数&gt; 以时间参数的形式提交要运行的任务at允许使用一套相当复杂的指定时间的方法。他能够接受在当天的hh:mm（小时:分钟）式的时间指定。假如该时间已过去，那么就放在第二天执行。当然也能够使用midnight（深夜），noon（中午），teatime（饮茶时间，一般是下午4点）等比较模糊的 词语来指定时间。用户还能够采用12小时计时制，即在时间后面加上AM（上午）或PM（下午）来说明是上午还是下午。 也能够指定命令执行的具体日期，指定格式为month day（月 日）或mm/dd/yy（月/日/年）或dd.mm.yy（日.月.年）。指定的日期必须跟在指定时间的后面。 上面介绍的都是绝对计时法，其实还能够使用相对计时法，这对于安排不久就要执行的命令是很有好处的。指定格式为：now + count time-units ，now就是当前时间，time-units是时间单位，这里能够是minutes（分钟）、hours（小时）、days（天）、weeks（星期）。count是时间的数量，究竟是几天，还是几小时，等等。 更有一种计时方法就是直接使用today（今天）、tomorrow（明天）来指定完成命令的时间。 TIME 时间格式，这里可以定义出什么时候要进行 at 这项任务的时间 TIME的格式：HH:MMex&gt; 04:00在今日的 HH:MM 时刻进行，若该时刻已超过，则明天的 HH:MM 进行此任务。 HH:MM YYYY-MM-DDex&gt; 04:00 2009-03-17强制规定在某年某月的某一天的特殊时刻进行该项任务 HH:MM[am|pm] [Month] [Date]ex&gt; 04pm March 17也是一样，强制在某年某月某日的某时刻进行该项任务 HH:MM[am|pm] + number [minutes|hours|days|weeks]ex&gt; now + 5 minutesex&gt; 04pm + 3 days就是说，在某个时间点再加几个时间后才进行该项任务。 使用实例例一：三天后的下午 5 点锺执行 /bin/ls $ at 5pm+3 days at&gt; /bin/ls at&gt; &lt;EOT&gt; # 按一下Ctrl+d就会出现&lt;EOT&gt;结束符 job 2 at Thu Feb 2 17:00:00 2017 例二：明天17点钟，输出时间到指定文件内 $ at 17:20 tomorrow at&gt; date &gt;/root/2013.log at&gt; &lt;EOT&gt; 例三：计划任务设定后，在没有执行之前我们可以用atq命令来查看系统没有执行工作任务 $ atq 2 Thu Feb 2 17:00:00 2017 a faker 例四：删除已经设置的任务 # 2 为atq查出来的最前面的任务id $ atrm 2 例五：显示已经设置的任务内容 $ at -c 2 #!/bin/sh # atrun uid=1000 gid=1000 # mail faker 0 umask 22 此处省略n个字符 /bin/ls atd 的启动与 at 运行的方式atd 的启动 要使用一次性计划任务时，我们的 Linux 系统上面必须要有负责这个计划任务的服务，那就是 atd 服务。 不过并非所有的 Linux distributions 都默认会把他打开的，所以，某些时刻我们需要手动将atd 服务激活才行。 激活的方法很简单，就是这样：命令： $ /etc/init.d/atd start $ /etc/init.d/atd restart 配置一下启动时就启动这个服务，免得每次重新启动都得再来一次 $ chkconfig atd on at 的运行方式 既然是计划任务，那么应该会有任务执行的方式，并且将这些任务排进行程表中。那么产生计划任务的方式是怎么进行的? 事实上，我们使用 at 这个命令来产生所要运行的计划任务，并将这个计划任务以文字档的方式写入 /var/spool/at/ 目录内，该工作便能等待 atd 这个服务的取用与运行了。就这么简单。 不过，并不是所有的人都可以进行 at 计划任务。为什么? 因为系统安全的原因。很多主机被所谓的攻击破解后，最常发现的就是他们的系统当中多了很多的黑客程序， 这些程序非常可能运用一些计划任务来运行或搜集你的系统运行信息,并定时的发送给黑客。 所以，除非是你认可的帐号，否则先不要让他们使用 at 命令。那怎么达到使用 at 的可控呢? 我们可以利用 /etc/at.allow 与 /etc/at.deny 这两个文件来进行 at 的使用限制。加上这两个文件后， at 的工作情况是这样的： 先找寻 /etc/at.allow 这个文件，写在这个文件中的使用者才能使用 at ，没有在这个文件中的使用者则不能使用 at (即使没有写在 at.deny 当中); 如果 /etc/at.allow 不存在，就寻找 /etc/at.deny 这个文件，若写在这个 at.deny 的使用者则不能使用 at ，而没有在这个 at.deny 文件中的使用者，就可以使用 at 命令了。 如果两个文件都不存在，那么只有 root 可以使用 at 这个命令。 透过这个说明，我们知道 /etc/at.allow 是管理较为严格的方式，而 /etc/at.deny 则较为松散 (因为帐号没有在该文件中，就能够运行 at 了)。在一般的 distributions 当中，由于假设系统上的所有用户都是可信任的， 因此系统通常会保留一个空的 /etc/at.deny 文件，意思是允许所有人使用 at 命令的意思 (您可以自行检查一下该文件)。 不过，万一你不希望有某些使用者使用 at 的话，将那个使用者的帐号写入 /etc/at.deny 即可！ 一个帐号写一行。","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"https://jiangxingye.github.io/tags/linux命令/"}]},{"title":"每天一个linux命令（53）: watch","slug":"linux-command（53）-watch","date":"2017-01-21T02:12:30.000Z","updated":"2019-09-02T13:03:00.027Z","comments":true,"path":"2017/01/21/linux-command（53）-watch/","link":"","permalink":"https://jiangxingye.github.io/2017/01/21/linux-command（53）-watch/","excerpt":"watch是一个非常实用的命令，基本所有的Linux发行版都带有这个小工具，如同名字一样，watch可以帮你监测一个命令的运行结果，省得你一遍遍的手动运行。在Linux下，watch是周期性的执行下个程序，并全屏显示执行结果。你可以拿他来监测你想要的一切命令的结果变化，比如 tail 一个 log 文件，ls 监测某个文件的大小变化，看你的想象力了！","text":"watch是一个非常实用的命令，基本所有的Linux发行版都带有这个小工具，如同名字一样，watch可以帮你监测一个命令的运行结果，省得你一遍遍的手动运行。在Linux下，watch是周期性的执行下个程序，并全屏显示执行结果。你可以拿他来监测你想要的一切命令的结果变化，比如 tail 一个 log 文件，ls 监测某个文件的大小变化，看你的想象力了！ 命令格式$ watch[参数][命令] 命令功能 可以将命令的输出结果输出到标准输出设备，多用于周期性执行命令/定时执行命令 命令参数 参数 描述 -n或–interval watch缺省每2秒运行一下程序，可以用-n或-interval来指定间隔的时间 -d或–differences watch 会高亮显示变化的区域 -d=cumulative 会把变动过的地方(不管最近的那次有没有变动)都高亮显示出来 -t 或-no-title 会关闭watch命令在顶部的时间间隔,命令，当前时间的输出 -h, –help 查看帮助文档 使用实例例一：每隔一秒高亮显示网络链接数的变化情况 $ watch -n 1 -d netstat -ant 说明：其它操作：切换终端： Ctrl+x退出watch：Ctrl+g (deepin系统没效果，只能使用Ctrl+c退出了) 例二：每隔一秒高亮显示http链接数的变化情况 # 每隔一秒高亮显示http链接数的变化情况。 后面接的命令若带有管道符，需要加&#39;&#39;将命令区域归整。 $ watch -n 1 -d &#39;pstree|grep http&#39; 例三：实时查看模拟攻击客户机建立起来的连接数 $ watch &#39;netstat -an | grep:21 | \\ grep&lt;模拟攻击客户机的IP&gt;| wc -l&#39; 例四：监测当前目录中 scf’ 的文件的变化 $ watch -d &#39;ls -l|grep scf&#39; 例五：10秒一次输出系统的平均负载 $ watch -n 10 &#39;cat /proc/loadavg&#39;","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"https://jiangxingye.github.io/tags/linux命令/"}]},{"title":"每天一个linux命令（52）: ps","slug":"linux-command（52）-ps","date":"2017-01-20T01:46:16.000Z","updated":"2019-09-02T13:03:00.026Z","comments":true,"path":"2017/01/20/linux-command（52）-ps/","link":"","permalink":"https://jiangxingye.github.io/2017/01/20/linux-command（52）-ps/","excerpt":"Linux中的ps命令是Process Status的缩写。ps命令用来列出系统中当前运行的那些进程。ps命令列出的是当前那些进程的快照，就是执行ps命令的那个时刻的那些进程，如果想要动态的显示进程信息，就可以使用top命令。","text":"Linux中的ps命令是Process Status的缩写。ps命令用来列出系统中当前运行的那些进程。ps命令列出的是当前那些进程的快照，就是执行ps命令的那个时刻的那些进程，如果想要动态的显示进程信息，就可以使用top命令。 要对进程进行监测和控制，首先必须要了解当前进程的情况，也就是需要查看当前进程，而 ps 命令就是最基本同时也是非常强大的进程查看命令。使用该命令可以确定有哪些进程正在运行和运行的状态、进程是否结束、进程有没有僵死、哪些进程占用了过多的资源等等。总之大部分信息都是可以通过执行该命令得到的。 ps 为我们提供了进程的一次性的查看，它所提供的查看结果并不动态连续的；如果想对进程时间监控，应该用 top 工具。 kill 命令用于杀死进程。linux上进程有5种状态: 运行(正在运行或在运行队列中等待) 中断(休眠中, 受阻, 在等待某个条件的形成或接受到信号) 不可中断(收到信号不唤醒和不可运行, 进程必须等待直到有中断发生) 僵死(进程已终止, 但进程描述符存在, 直到父进程调用wait4()系统调用后释放) 停止(进程收到SIGSTOP, SIGSTP, SIGTIN, SIGTOU信号后停止运行运行) ps工具标识进程的5种状态码:D 不可中断 uninterruptible sleep (usually IO)R 运行 runnable (on run queue)S 中断 sleepingT 停止 traced or stoppedZ 僵死 a defunct (”zombie”) process 命令格式$ ps [参数] 命令功能用来现实当前进程的状态 命令参数 参数 描述 a 显示所有进程 -a 显示同一终端下的所有程序 -A 显示所有进程 c 显示进程的真实名称 -N 反向选择 -e 等于“-A” e 显示环境变量 f 显示程序间的关系 -H 显示树状结构 r 显示当前终端的进程 T 显示当前终端的所有程序 u 指定用户的所有进程 -au 显示较详细的资讯 -aux 显示所有包含其他使用者的行程 -C&lt;命令&gt; 列出指定命令的状况 –lines&lt;行数&gt; 每页显示的行数 –width&lt;字符数&gt; 每页显示的字符数 –help 显示帮助信息 –version 显示版本显示 使用实例例一：显示所有进程信息 $ ps -A 例二：显示指定用户的进程信息 $ ps -u faker 例三：显示所有进程信息，连同命令行 $ ps -ef 例四：ps 与grep 常用组合用法，查找特定进程 $ ps -ef|grep ssh 例五：将目前属于您自己这次登入的 PID 与相关信息列示出来 $ ps -l 说明：各相关信息的意义： F 代表这个程序的旗标 (flag)， 4 代表使用者为 super user S 代表这个程序的状态 (STAT)，关于各 STAT 的意义将在内文介绍 UID 程序被该 UID 所拥有 PID 就是这个程序的 ID ！ PPID 则是其上级父程序的ID C CPU 使用的资源百分比 PRI 这个是 Priority (优先执行序) 的缩写，详细后面介绍 NI 这个是 Nice 值，在下一小节我们会持续介绍 ADDR 这个是 kernel function，指出该程序在内存的那个部分。如果是个 running的程序，一般就是 “-“ SZ 使用掉的内存大小 WCHAN 目前这个程序是否正在运作当中，若为 - 表示正在运作 TTY 登入者的终端机位置 TIME 使用掉的 CPU 时间。 CMD 所下达的指令为何 在预设的情况下， ps 仅会列出与目前所在的 bash shell 有关的 PID 而已，所以， 当我使用 ps -l 的时候，只有三个 PID。 例六：列出目前所有的正在内存当中的程序 $ ps aux 说明： USER：该 process 属于那个使用者账号的 PID ：该 process 的号码 %CPU：该 process 使用掉的 CPU 资源百分比 %MEM：该 process 所占用的物理内存百分比 VSZ ：该 process 使用掉的虚拟内存量 (Kbytes) RSS ：该 process 占用的固定的内存量 (Kbytes) TTY ：该 process 是在那个终端机上面运作，若与终端机无关，则显示 ?，另外， tty1-tty6 是本机上面的登入者程序，若为 pts/0 等等的，则表示为由网络连接进主机的程序。 STAT：该程序目前的状态，主要的状态有 R ：该程序目前正在运作，或者是可被运作 S ：该程序目前正在睡眠当中 (可说是 idle 状态)，但可被某些讯号 (signal) 唤醒。 T ：该程序目前正在侦测或者是停止了 Z ：该程序应该已经终止，但是其父程序却无法正常的终止他，造成 zombie (疆尸) 程序的状态 START：该 process 被触发启动的时间 TIME ：该 process 实际使用 CPU 运作的时间 COMMAND：该程序的实际指令 例七：列出类似程序树的程序显示 $ ps -axjf 例八：找出与 cron 与 syslog 这两个服务有关的 PID 号码 $ ps aux | egrep &#39;(cron|syslog)&#39; 其他 # 可以用 | 管道和 more 连接起来分页查看 $ ps -aux |more # 把所有进程显示出来，并输出到ps001.txt文件 $ ps -aux &gt; ps001.txt # 输出指定的字段 $ ps -o pid,ppid,pgrp,session,tpgid,comm","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"https://jiangxingye.github.io/tags/linux命令/"}]},{"title":"每天一个linux命令（51）: wc","slug":"linux-command（51）-wc","date":"2017-01-19T01:33:59.000Z","updated":"2019-09-02T13:03:00.026Z","comments":true,"path":"2017/01/19/linux-command（51）-wc/","link":"","permalink":"https://jiangxingye.github.io/2017/01/19/linux-command（51）-wc/","excerpt":"Linux系统中的wc(Word Count)命令的功能为统计指定文件中的字节数、字数、行数，并将统计结果显示输出。","text":"Linux系统中的wc(Word Count)命令的功能为统计指定文件中的字节数、字数、行数，并将统计结果显示输出。 命令格式$ wc [选项]文件... 命令功能 统计指定文件中的字节数、字数、行数，并将统计结果显示输出。该命令统计指定文件中的字节数、字数、行数。如果没有给出文件名，则从标准输入读取。wc同时也给出所指定文件的总统计数。 命令参数 参数 描述 -c 统计字节数 -l 统计行数 -m 统计字符数。这个标志不能与 -c 标志一起使用 -w 统计字数。一个字被定义为由空白、跳格或换行字符分隔的字符串 -L 打印最长行的长度 -help 显示帮助信息 –version 显示版本信息 使用实例例一：查看文件的字节数、字数、行数 $ wc 1.txt 5 19 105 1.txt 行数 单词数 字节数 文件名 例二：用wc命令怎么做到只打印统计数字不打印文件名 $ wc -l 1.txt 5 1.txt # 5行 $ cat 1.txt | wc -l 5 # 值输出数字 例三：用来统计当前目录下的文件和文件夹总数 # 数量中包含当前目录 $ ls -l | wc -l 10 # 7个文件 + 2个文件夹 + 1个当前目录","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"https://jiangxingye.github.io/tags/linux命令/"}]},{"title":"每天一个linux命令（50）: grep","slug":"linux-command（50）-grep","date":"2017-01-18T02:12:46.000Z","updated":"2019-09-02T13:03:00.025Z","comments":true,"path":"2017/01/18/linux-command（50）-grep/","link":"","permalink":"https://jiangxingye.github.io/2017/01/18/linux-command（50）-grep/","excerpt":"Linux系统中grep命令是一种强大的文本搜索工具，它能使用正则表达式搜索文本，并把匹 配的行打印出来。grep全称是Global Regular Expression Print，表示全局正则表达式版本，它的使用权限是所有用户。","text":"Linux系统中grep命令是一种强大的文本搜索工具，它能使用正则表达式搜索文本，并把匹 配的行打印出来。grep全称是Global Regular Expression Print，表示全局正则表达式版本，它的使用权限是所有用户。 grep的工作方式是这样的，它在一个或多个文件中搜索字符串模板。如果模板包括空格，则必须被引用，模板后的所有字符串被看作文件名。搜索的结果被送到标准输出，不影响原文件内容。 grep可用于shell脚本，因为grep通过返回一个状态值来说明搜索的状态，如果模板搜索成功，则返回0，如果搜索不成功，则返回1，如果搜索的文件不存在，则返回2。我们利用这些返回值就可进行一些自动化的文本处理工作。 命令格式$ grep [option] pattern file 命令功能 用于过滤/搜索的特定字符。可使用正则表达式能多种命令配合使用，使用上十分灵活。 命令参数 参数 描述 -a –text 不要忽略二进制的数据 -A&lt;显示行数&gt; –after-context=&lt;显示行数&gt; 除了显示符合范本样式的那一列之外，并显示该行之后的内容 -b –byte-offset 在显示符合样式的那一行之前，标示出该行第一个字符的编号 -B&lt;显示行数&gt; –before-context=&lt;显示行数&gt; 除了显示符合样式的那一行之外，并显示该行之前的内容 -c –count 计算符合样式的列数 -C&lt;显示行数&gt; –context=&lt;显示行数&gt;或-&lt;显示行数&gt; 显示上下文n行 -d &lt;动作&gt; –directories=&lt;动作&gt; 当指定要查找的是目录而非文件时，必须使用这项参数，否则grep指令将回报信息并停止动作 -e&lt;范本样式&gt; –regexp=&lt;范本样式&gt; 指定字符串做为查找文件内容的样式 -E –extended-regexp 将样式为延伸的普通表示法来使用 -f&lt;规则文件&gt; –file=&lt;规则文件&gt; 指定规则文件，其内容含有一个或多个规则样式，让grep查找符合规则条件的文件内容，格式为每行一个规则样式 -F –fixed-regexp 将样式视为固定字符串的列表 -G –basic-regexp 样式视为普通的表示法来使用 -h –no-filename 在显示符合样式的那一行之前，不标示该行所属的文件名称 -H –with-filename 在显示符合样式的那一行之前，表示该行所属的文件名称 -i –ignore-case 忽略字符的大小写 -l –file-with-matches 只列出匹配的文件名 -L –files-without-match 列出不匹配的文件名 -n –line-number 显示行号 -q –quiet或–silent 不显示任何信息 -r –recursive 递归查询， 此参数的效果和指定“-d recurse”参数相同 -s –no-messages 不显示错误信息 -v –revert-match 显示不包含匹配文本的所有行 -V –version 显示版本信息 -w –word-regexp 只显示全字符合的列 -x –line-regexp 只显示全列符合的列 -y 此参数的效果和指定“-i”参数相同 规则表达式grep的规则表达式 ^ #锚定行的开始 如：&#39;^grep&#39;匹配所有以grep开头的行。 $ #锚定行的结束 如：&#39;grep$&#39;匹配所有以grep结尾的行。 . #匹配一个非换行符的字符 如：&#39;gr.p&#39;匹配gr后接一个任意字符，然后是p。 * #匹配零个或多个先前字符 如：&#39;*grep&#39;匹配所有一个或多个空格后紧跟grep的行。 .* #一起用代表任意字符。 [] #匹配一个指定范围内的字符，如&#39;[Gg]rep&#39;匹配Grep和grep。 [^] #匹配一个不在指定范围内的字符，如：&#39;[^A-FH-Z]rep&#39;匹配不包含A-R和T-Z的一个字母开头，紧跟rep的行。 \\(..\\) #标记匹配字符，如&#39;\\(love\\)&#39;，love被标记为1。 \\&lt; #锚定单词的开始，如:&#39;\\&lt;grep&#39;匹配包含以grep开头的单词的行。 \\&gt; #锚定单词的结束，如&#39;grep\\&gt;&#39;匹配包含以grep结尾的单词的行。 x\\{m\\} #重复字符x，m次，如：&#39;o\\{5\\}&#39;匹配包含5个o的行。 x\\{m,\\} #重复字符x,至少m次，如：&#39;o\\{5,\\}&#39;匹配至少有5个o的行。 x\\{m,n\\} #重复字符x，至少m次，不多于n次，如：&#39;o\\{5,10\\}&#39;匹配5–10个o的行。 \\w #匹配文字和数字字符，也就是[A-Za-z0-9]，如：&#39;G\\w*p&#39;匹配以G后跟零个或多个文字或数字字符，然后是p。 \\W #\\w的反置形式，匹配一个或多个非单词字符，如点号句号等。 \\b #单词锁定符，如: &#39;\\bgrep\\b&#39;只匹配grep。POSIX字符 为了在不同国家的字符编码中保持一至，POSIX(The Portable Operating System Interface)增加了特殊的字符类，如[:alnum:]是[A-Za-z0-9]的另一个写法。要把它们放到[]号内才能成为正则表达式，如[A- Za-z0-9]或[[:alnum:]]。在linux下的grep除fgrep外，都支持POSIX的字符类。 [:alnum:] #文字数字字符 [:alpha:] #文字字符 [:digit:] #数字字符 [:graph:] #非空字符（非空格、控制字符） [:lower:] #小写字符 [:cntrl:] #控制字符 [:print:] #非空字符（包括空格） [:punct:] #标点符号 [:space:] #所有空白字符（新行，空格，制表符） [:upper:] #大写字符 [:xdigit:] #十六进制数字（0-9，a-f，A-F） 使用实例例一：查找指定进程 $ ps -ef|grep hexo faker 13401 19030 0 09:51 pts/2 00:00:15 hexo faker 15465 15449 0 10:34 pts/3 00:00:00 grep hexo 说明：第一条记录是查找出的进程；第二条结果是grep进程本身，并非真正要找的进程。 例二：查找指定进程数 $ ps -ef|grep hexo -c $ ps -ef|grep -c hexo 2 例三：从2.txt中读取关键词在1.txt中进行搜索 # -n显示行号 $ cat 1.txt | grep -nf 2.txt 1:If you please draw me a sheep! 2:What! 例四：从文件中查找关键词 $ grep &#39;jump&#39; 1.txt I jumped to my feet,completely thunderstruck. 例五：从多个文件中查找关键词 $ grep &#39;jump&#39; 1.txt 2.txt 1.txt:I jumped to my feet,completely thunderstruck. 2.txt:I jump 说明：多文件时，输出查询到的信息内容行时，会把文件的命名在行最前面输出并且加上”:”作为标示符 例六：grep不显示本身进程 $ ps aux|grep \\[s]sh $ ps aux | grep ssh | grep -v &quot;grep&quot; 例七：找出以u开头的行内容 $ cat 1.txt |grep ^u If you please draw me a sheep! I jumped to my feet,completely thunderstruck. 例八：输出非u开头的行内容 $ cat 1.txt | grep ^[^I] What! Draw me a sheep! 例九：输出以!结尾的行内容 $ cat 1.txt |grep \\!$ If you please draw me a sheep! What! Draw me a sheep! 例十：显示包含sh或者at字符的内容行 $ cat 1.txt |grep -E &quot;sh|at&quot; If you please draw me a sheep! What! Draw me a sheep! 例十一：显示当前目录下面以.txt 结尾的文件中的所有包含每个字符串至少有7个连续小写字符的字符串的行 $ grep &#39;[a-z]\\{7\\}&#39; *.txt 1.txt:I jumped to my feet,completely thunderstruck. 3.txt:kdfkksjdf112123 4.txt:kisdfsf","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"https://jiangxingye.github.io/tags/linux命令/"}]},{"title":"每天一个linux命令（49）: cal","slug":"linux-command（49）-cal","date":"2017-01-17T01:38:32.000Z","updated":"2019-09-02T13:03:00.024Z","comments":true,"path":"2017/01/17/linux-command（49）-cal/","link":"","permalink":"https://jiangxingye.github.io/2017/01/17/linux-command（49）-cal/","excerpt":"cal命令可以用来显示公历（阳历）日历。公历是现在国际通用的历法，又称格列历，通称阳历。“阳历”又名“太阳历”，系以地球绕行太阳一周为一年，为西方各国所通用，故又名“西历”。","text":"cal命令可以用来显示公历（阳历）日历。公历是现在国际通用的历法，又称格列历，通称阳历。“阳历”又名“太阳历”，系以地球绕行太阳一周为一年，为西方各国所通用，故又名“西历”。 命令格式$ cal [参数][月份][年份] 命令功能用于查看日历等时间信息，如只有一个参数，则表示年份(1-9999)，如有两个参数，则表示月份和年份 命令参数 参数 描述 -1 显示一个月的月历 -3 显示系统前一个月，当前月，下一个月的月历 -s 显示星期天为一个星期的第一天，默认的格式 -m 显示星期一为一个星期的第一天 -j 显示在当年中的第几天（一年日期按天算，从1月1号算起，默认显示当前月在一年中的天数） -y 显示当前年份的日历 使用实例例一：显示当前月份日历 $ cal 例二：显示指定月份的日历 $ cal 6 2016 例三：显示2016年的日历 $ cal -y 2016 $ cal 2016 例四：显示自1月1日的天数 $ cal -j 例五：星期一显示在第一列 $ cal -m","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"https://jiangxingye.github.io/tags/linux命令/"}]},{"title":"每天一个linux命令（48）: date","slug":"linux-command（48）-date","date":"2017-01-16T06:39:27.000Z","updated":"2019-09-02T13:03:00.024Z","comments":true,"path":"2017/01/16/linux-command（48）-date/","link":"","permalink":"https://jiangxingye.github.io/2017/01/16/linux-command（48）-date/","excerpt":"在linux环境中，不管是编程还是其他维护，时间是必不可少的，也经常会用到时间的运算，熟练运用date命令来表示自己想要表示的时间，肯定可以给自己的工作带来诸多方便。","text":"在linux环境中，不管是编程还是其他维护，时间是必不可少的，也经常会用到时间的运算，熟练运用date命令来表示自己想要表示的时间，肯定可以给自己的工作带来诸多方便。 命令格式$ date [参数]... [+格式] 命令功能 date 可以用来显示或设定系统的日期与时间。 命令参数命令参数 参数 描述 %H 小时(以00-23来表示) %I 小时(以01-12来表示) %K 小时(以0-23来表示) %l 小时(以0-12来表示) %M 分钟(以00-59来表示) %P AM或PM %r 时间(含时分秒，小时以12小时AM/PM来表示) %s 总秒数。起算时间为1970-01-01 00:00:00 UTC %S 秒(以本地的惯用法来表示) %T 时间(含时分秒，小时以24小时制来表示) %X 时间(以本地的惯用法来表示) %Z 市区 %a 星期的缩写 %A 星期的完整名称 %b 月份英文名的缩写 %B 月份的完整英文名称 %c 日期与时间。只输入date指令也会显示同样的结果 %d 日期(以01-31来表示) %D 日期(含年月日) %j 该年中的第几天 %m 月份(以01-12来表示) %U 该年中的周数 %w 该周的天数，0代表周日，1代表周一，异词类推 %x 日期(以本地的惯用法来表示) %y 年份(以00-99来表示) %Y 年份(以四位数来表示) %n 在显示时，插入新的一行 %t 在显示时，插入tab MM 月份(必要) DD 日期(必要) hh 小时(必要) mm 分钟(必要) ss 秒(选择性) 选择参数 参数 描述 -d&lt;字符串&gt; 显示字符串所指的日期与时间。字符串前后必须加上双引号 -s&lt;字符串&gt; 根据字符串来设置日期与时间。字符串前后必须加上双引号 -u 显示GMT –help 在线帮助 –version 显示版本信息 使用说明1.在显示方面，使用者可以设定欲显示的格式，格式设定为一个加号后接数个标记，其中可用的标记列表如下: % : 打印出 %%n : 下一行%t : 跳格%H : 小时(00..23)%I : 小时(01..12)%k : 小时(0..23)%l : 小时(1..12)%M : 分钟(00..59)%p : 显示本地 AM 或 PM%r : 直接显示时间 (12 小时制，格式为 hh:mm:ss [AP]M)%s : 从 1970 年 1 月 1 日 00:00:00 UTC 到目前为止的秒数%S : 秒(00..61)%T : 直接显示时间 (24 小时制)%X : 相当于 %H:%M:%S%Z : 显示时区 %a : 星期几 (Sun..Sat)%A : 星期几 (Sunday..Saturday)%b : 月份 (Jan..Dec)%B : 月份 (January..December)%c : 直接显示日期与时间%d : 日 (01..31)%D : 直接显示日期 (mm/dd/yy)%h : 同 %b%j : 一年中的第几天 (001..366)%m : 月份 (01..12)%U : 一年中的第几周 (00..53) (以 Sunday 为一周的第一天的情形)%w : 一周中的第几天 (0..6)%W : 一年中的第几周 (00..53) (以 Monday 为一周的第一天的情形)%x : 直接显示日期 (mm/dd/yy)%y : 年份的最后两位数字 (00.99)%Y : 完整年份 (0000..9999)2.在设定时间方面date -s //设置当前时间，只有root权限才能设置，其他只能查看。date -s 20080523 //设置成20080523，这样会把具体时间设置成空00:00:00date -s 01:01:01 //设置具体时间，不会对日期做更改date -s “01:01:01 2008-05-23″ //这样可以设置全部时间date -s “01:01:01 20080523″ //这样可以设置全部时间date -s “2008-05-23 01:01:01″ //这样可以设置全部时间date -s “20080523 01:01:01″ //这样可以设置全部时间3.加减date +%Y%m%d //显示前天年月日date +%Y%m%d –date=”+1 day” //显示前一天的日期date +%Y%m%d –date=”-1 day” //显示后一天的日期date +%Y%m%d –date=”-1 month” //显示上一月的日期date +%Y%m%d –date=”+1 month” //显示下一月的日期date +%Y%m%d –date=”-1 year” //显示前一年的日期date +%Y%m%d –date=”+1 year” //显示下一年的日期 使用实例例一：显示当前时间 $ date 2017年 01月 28日 星期六 14:51:10 CST $ date &#39;+%c&#39; 2017年01月28日 星期六 14时51分35秒 $ date &#39;+%D&#39; 01/28/17 $ date &#39;+%x&#39; 2017年01月28日 $ date &#39;+%T&#39; 14:52:02 $ date &#39;+%X&#39; 14时52分06秒 例二：显示日期和设定时间 $ date --date 08:42:00 例三：date -d参数使用 $ date -d &quot;nov 22&quot; 2012年 11月 22日 星期四 00:00:00 CST $ date -d &#39;2 weeks&#39; 2012年 12月 22日 星期六 08:50:21 CST $ date -d &#39;next monday&#39; 2012年 12月 10日 星期一 00:00:00 CST $ date -d next-day +%Y%m%d 20121209 $ date -d tomorrow +%Y%m%d 20121209 $ date -d last-day +%Y%m%d 20121207 $ date -d yesterday +%Y%m%d 20121207 $ date -d last-month +%Y%m 201211 $ date -d next-month +%Y%m 201301 $ date -d &#39;30 days ago&#39; 2012年 11月 08日 星期四 08:51:37 CST $ date -d &#39;-100 days&#39; 2012年 08月 30日 星期四 08:52:03 CST $ date -d &#39;dec 14 -2 weeks&#39; 2012年 11月 30日 星期五 00:00:00 CST $ date -d &#39;50 days&#39; 2013年 01月 27日 星期日 08:52:27 CST 说明： date 命令的另一个扩展是 -d 选项，该选项非常有用。使用这个功能强大的选项，通过将日期作为引号括起来的参数提供，您可以快速地查明一个特定的日期。-d 选项还可以告诉您，相对于当前日期若干天的究竟是哪一天，从现在开始的若干天或若干星期以后，或者以前（过去）。通过将这个相对偏移使用引号括起来，作为 -d 选项的参数，就可以完成这项任务。 具体说明如下： date -d “nov 22” 今年的 11 月 22 日是星期三 date -d ‘2 weeks’ 2周后的日期 date -d ‘next monday’ (下周一的日期) date -d next-day +%Y%m%d（明天的日期）或者：date -d tomorrow +%Y%m%d date -d last-day +%Y%m%d(昨天的日期) 或者：date -d yesterday +%Y%m%d date -d last-month +%Y%m(上个月是几月) date -d next-month +%Y%m(下个月是几月) 使用 ago 指令，您可以得到过去的日期： date -d ‘30 days ago’ （30天前的日期） 使用负数以得到相反的日期： date -d ‘dec 14 -2 weeks’ （相对:dec 14这个日期的两周前的日期） date -d ‘-100 days’ (100天以前的日期) date -d ‘50 days’(50天后的日期) 例四：显示月份和日数 $ date &#39;+%B %d&#39; 一月 28 例五：显示时间后跳行，再显示目前日期 $ date &#39;+%T%n%D&#39; 14:58:23 01/28/17","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"https://jiangxingye.github.io/tags/linux命令/"}]},{"title":"每天一个linux命令（47）: diff","slug":"linux-command（47）-diff","date":"2017-01-15T06:08:08.000Z","updated":"2019-09-02T13:03:00.024Z","comments":true,"path":"2017/01/15/linux-command（47）-diff/","link":"","permalink":"https://jiangxingye.github.io/2017/01/15/linux-command（47）-diff/","excerpt":"diff 命令是 linux上非常重要的工具，用于比较文件的内容，特别是比较两个版本不同的文件以找到改动的地方。diff在命令行中打印每一个行的改动。最新版本的diff还支持二进制文件。diff程序的输出被称为补丁 (patch)，因为Linux系统中还有一个patch程序，可以根据diff的输出将a.c的文件内容更新为b.c。diff是svn、cvs、git等版本控制工具不可或缺的一部分。","text":"diff 命令是 linux上非常重要的工具，用于比较文件的内容，特别是比较两个版本不同的文件以找到改动的地方。diff在命令行中打印每一个行的改动。最新版本的diff还支持二进制文件。diff程序的输出被称为补丁 (patch)，因为Linux系统中还有一个patch程序，可以根据diff的输出将a.c的文件内容更新为b.c。diff是svn、cvs、git等版本控制工具不可或缺的一部分。 命令格式$ diff [参数] [文件1或目录1] [文件2或目录2] 命令功能 diff命令能比较单个文件或者目录内容。如果指定比较的是文件，则只有当输入为文本文件时才有效。以逐行的方式，比较文本文件的异同处。如果指定比较的是目录的的时候，diff 命令会比较两个目录下名字相同的文本文件。列出不同的二进制文件、公共子目录和只在一个目录出现的文件。 命令参数 参数 描述 - 指定要显示多少行的文本。此参数必须与-c或-u参数一并使用 -a或–text diff预设只会逐行比较文本文件 -b或–ignore-space-change 不检查空格字符的不同 -B或–ignore-blank-lines 不检查空白行 -c 显示全部内文，并标出不同之处 -C或–context 与执行”-c”指令相同 -d或–minimal 使用不同的演算法，以较小的单位来做比较 -D或ifdef 此参数的输出格式可用于前置处理器巨集 -e或–ed 此参数的输出格式可用于ed的script文件 -f或-forward-ed 输出的格式类似ed的script文件，但按照原来文件的顺序来显示不同处 -H或–speed-large-files 比较大文件时，可加快速度 -l或–ignore-matching-lines 若两个文件在某几行有所不同，而这几行同时都包含了选项中指定的字符或字符串，则不显示这两个文件的差异 -i或–ignore-case 不检查大小写的不同 -l或–paginate 将结果交由pr程序来分页 -n或–rcs 将比较结果以RCS的格式来显示 -N或–new-file 在比较目录时，若文件A仅出现在某个目录中，预设会显示：Only in目录：文件A若使用-N参数，则diff会将文件A与一个空白的文件比较 -p 若比较的文件为C语言的程序码文件时，显示差异所在的函数名称 -P或–unidirectional-new-file 与-N类似，但只有当第二个目录包含了一个第一个目录所没有的文件时，才会将这个文件与空白的文件做比较 -q或–brief 仅显示有无差异，不显示详细的信息 -r或–recursive 比较子目录中的文件 -s或–report-identical-files 若没有发现任何差异，仍然显示信息 -S或–starting-file 在比较目录时，从指定的文件开始比较 -t或–expand-tabs 在输出时，将tab字符展开 -T或–initial-tab 在每行前面加上tab字符以便对齐 -u,-U或–unified= 以合并的方式来显示文件内容的不同 -v或–version 显示版本信息 -w或–ignore-all-space 忽略全部的空格字符 -W或–width 在使用-y参数时，指定栏宽 -x或–exclude 不比较选项中所指定的文件或目录 -X或–exclude-from 您可以将文件或目录类型存成文本文件，然后在=中指定此文本文件 -y或–side-by-side 以并列的方式显示文件的异同之处 –left-column 在使用-y参数时，若两个文件某一行内容相同，则仅在左侧的栏位显示该行内容 –suppress-common-lines 在使用-y参数时，仅显示不同之处 –help 显示帮助 使用实例例一：比较两个文件 $ diff 1.txt 2.txt 1c1 &lt; ii --- &gt; iii 说明： 上面的“1c1”表示第一个文件和第二个文件的第1行内容有所不同； diff 的normal 显示格式有三种提示: a - add c - change d - delete 例二：并排格式输出 $ diff 1.txt 2.txt -y -W 50 ii | iii iii iii iiii iiii iiiii iiiii 说明： “|”表示前后2个文件内容有不同 “&lt;”表示后面文件比前面文件少了1行内容 “&gt;”表示后面文件比前面文件多了1行内容 例三：上下文输出格式 $ diff 1.txt 2.txt -c *** 1.txt 2017-01-28 14:24:13.744538252 +0800 --- 2.txt 2017-01-28 14:24:59.096124066 +0800 *************** *** 1,4 **** ! ii iii iiii iiiii --- 1,4 ---- ! iii iii iiii iiiii 说明： 这种方式在开头两行作了比较文件的说明，这里有三中特殊字符： “＋” 比较的文件的后者比前着多一行 “－” 比较的文件的后者比前着少一行 “！” 比较的文件两者有差别的行 例四：统一格式输出 $ diff 1.txt 2.txt -u --- 1.txt 2017-01-28 14:24:13.744538252 +0800 +++ 2.txt 2017-01-28 14:24:59.096124066 +0800 @@ -1,4 +1,4 @@ -ii +iii iii iiii iiiii 例五：比较文件夹不同 $ diff test3 test6 例六：比较两个文件不同，并生产补丁 $ diff -ruN 1.txt 2.txt &gt;patch.log 例七：打补丁 $ 1.txt patch","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"https://jiangxingye.github.io/tags/linux命令/"}]},{"title":"每天一个linux命令（46）: ln","slug":"linux-command（46）-ln","date":"2017-01-14T03:00:33.000Z","updated":"2019-09-02T13:03:00.023Z","comments":true,"path":"2017/01/14/linux-command（46）-ln/","link":"","permalink":"https://jiangxingye.github.io/2017/01/14/linux-command（46）-ln/","excerpt":"ln是linux中又一个非常重要命令，它的功能是为某一个文件在另外一个位置建立一个同步的链接.当我们需要在不同的目录，用到相同的文件时，我们不需要在每一个需要的目录下都放一个必须相同的文件，我们只要在某个固定的目录，放上该文件，然后在 其它的目录下用ln命令链接（link）它就可以，不必重复的占用磁盘空间。","text":"ln是linux中又一个非常重要命令，它的功能是为某一个文件在另外一个位置建立一个同步的链接.当我们需要在不同的目录，用到相同的文件时，我们不需要在每一个需要的目录下都放一个必须相同的文件，我们只要在某个固定的目录，放上该文件，然后在 其它的目录下用ln命令链接（link）它就可以，不必重复的占用磁盘空间。 命令格式$ ln [参数][源文件或目录][目标文件或目录] 命令功能 Linux文件系统中，有所谓的链接(link)，我们可以将其视为档案的别名，而链接又可分为两种 : 硬链接(hard link)与软链接(symbolic link)，硬链接的意思是一个档案可以有多个名称，而软链接的方式则是产生一个特殊的档案，该档案的内容是指向另一个档案的位置。硬链接是存在同一个文件系统中，而软链接却可以跨越不同的文件系统。软连接 1.软链接，以路径的形式存在。类似于Windows操作系统中的快捷方式 2.软链接可以 跨文件系统 ，硬链接不可以 3.软链接可以对一个不存在的文件名进行链接 4.软链接可以对目录进行链接硬链接 1.硬链接，以文件副本的形式存在。但不占用实际空间。 2.不允许给目录创建硬链接 3.硬链接只有在同一个文件系统中才能创建两点注意 第一，ln命令会保持每一处链接文件的同步性，也就是说，不论你改动了哪一处，其它的文件都会发生相同的变化； 第二，ln的链接又分软链接和硬链接两种，软链接就是ln –s 源文件 目标文件，它只会在你选定的位置上生成一个文件的镜像，不会占用磁盘空间，硬链接 ln 源文件 目标文件，没有参数-s， 它会在你选定的位置上生成一个和源文件大小相同的文件，无论是软链接还是硬链接，文件都保持同步变化。 ln指令用在链接文件或目录，如同时指定两个以上的文件或目录，且最后的目的地是一个已经存在的目录，则会把前面指定的所有文件或目录复制到该目录中。若同时指定多个文件或目录，且最后的目的地并非是一个已存在的目录，则会出现错误信息。 命令参数必要参数 参数 描述 -b 删除，覆盖以前建立的链接 -d 允许超级用户制作目录的硬链接 -f 强制执行 -i 交互模式，文件存在则提示用户是否覆盖 -n 把符号链接视为一般目录 -s 软链接(符号链接) -v 显示详细的处理过程 选择参数 参数 描述 -S “-S&lt;字尾备份字符串&gt; ”或 “–suffix=&lt;字尾备份字符串&gt;” -V “-V&lt;备份方式&gt;”或“–version-control=&lt;备份方式&gt;” –help 显示帮助信息 –version 显示版本信息 使用实例例一：给文件创建软链接 # 为2.txt文件创建软链接2，如果2.txt丢失，2将失效 $ ln -s 2.txt 2 例二：给文件创建硬链接 # 为1.txt创建硬链接1，1.txt与1的各项属性相同,删除1.txt，1仍能使用 $ ln 1.txt 1 例三：接上面两实例，链接完毕后，删除和重建链接原文件 $ ll -rw-r--r-- 2 faker faker 10 1月 22 11:28 1 -rw-r--r-- 2 faker faker 10 1月 22 11:28 1.txt lrwxrwxrwx 1 faker faker 5 1月 28 11:15 2 -&gt; 2.txt -rwxrwxrwx 1 faker faker 14 1月 18 10:06 2.txt $ rm 1.txt 2.txt -rw-r--r-- 1 faker faker 10 1月 22 11:28 1 lrwxrwxrwx 1 faker faker 5 1月 28 11:15 2 -&gt; 2.txt $ cat 1 sdfiskdlf $ cat 2 cat: 2: 没有那个文件或目录 说明： 1.源文件被删除后，并没有影响硬链接文件；软链接文件在centos系统下不断的闪烁，提示源文件已经不存在 2.重建源文件后，软链接不在闪烁提示，说明已经链接成功，找到了链接文件系统；重建后，硬链接文件并没有受到源文件影响，硬链接文件的内容还是保留了删除前源文件的内容，说明硬链接已经失效 例三：将文件链接为另一个目录中的相同名字 # 在ig文件夹中创建一个1.txt的链接 $ ln 1.txt ig/ $ ll ig -rw-r--r-- 2 faker faker 10 1月 28 13:40 1.txt 例五：给目录创建软连接 $ ln -s ig gi 说明： 1.目录只能创建软链接 2.目录创建链接必须用绝对路径，相对路径创建会不成功，会提示：符号连接的层数过多 这样的错误（测试并不会出现这样的问题） 3.在链接目标目录中修改文件都会在源文件目录中同步变化","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"https://jiangxingye.github.io/tags/linux命令/"}]},{"title":"每天一个linux命令（45）: scp","slug":"linux-command（45）-scp","date":"2017-01-13T02:53:48.000Z","updated":"2019-09-02T13:03:00.023Z","comments":true,"path":"2017/01/13/linux-command（45）-scp/","link":"","permalink":"https://jiangxingye.github.io/2017/01/13/linux-command（45）-scp/","excerpt":"scp是secure copy的简写，用于在Linux下进行远程拷贝文件的命令，和它类似的命令有cp，不过cp只是在本机进行拷贝不能跨服务器，而且scp传输是加密的。可能会稍微影响一下速度。当你服务器硬盘变为只读 read only system时，用scp可以帮你把文件移出来。另外，scp还非常不占资源，不会提高多少系统负荷，在这一点上，rsync就远远不及它了。虽然 rsync比scp会快一点，但当小文件众多的情况下，rsync会导致硬盘I/O非常高，而scp基本不影响系统正常使用。","text":"scp是secure copy的简写，用于在Linux下进行远程拷贝文件的命令，和它类似的命令有cp，不过cp只是在本机进行拷贝不能跨服务器，而且scp传输是加密的。可能会稍微影响一下速度。当你服务器硬盘变为只读 read only system时，用scp可以帮你把文件移出来。另外，scp还非常不占资源，不会提高多少系统负荷，在这一点上，rsync就远远不及它了。虽然 rsync比scp会快一点，但当小文件众多的情况下，rsync会导致硬盘I/O非常高，而scp基本不影响系统正常使用。 命令格式$ scp [参数] [原路径] [目标路径] 命令功能 scp是 secure copy的缩写, scp是linux系统下基于ssh登陆进行安全的远程文件拷贝命令。linux的scp命令可以在linux服务器之间复制文件和目录。 命令参数 参数 描述 -1 强制scp命令使用协议ssh1 -2 强制scp命令使用协议ssh2 -4 强制scp命令只使用IPv4寻址 -6 强制scp命令只使用IPv6寻址 -B 使用批处理模式（传输过程中不询问传输口令或短语） -C 允许压缩。（将-C标志传递给ssh，从而打开压缩功能） -p 保留原文件的修改时间，访问时间和访问权限 -q 不显示传输进度条 -r 递归复制整个目录 -v 详细方式显示输出。scp和ssh(1)会显示出整个过程的调试信息。这些信息用于调试连接，验证和配置问题 -c cipher 以cipher将数据传输进行加密，这个选项将直接传递给ssh -F ssh_config 指定一个替代的ssh配置文件，此参数直接传递给ssh -i identity_file 从指定文件中读取传输时使用的密钥文件，此参数直接传递给ssh -l limit 限定用户所能使用的带宽，以Kbit/s为单位 -o ssh_option 如果习惯于使用ssh_config(5)中的参数传递方式 -P port 注意是大写的P, port是指定数据传输用到的端口号 -S program 指定加密传输时所使用的程序。此程序必须能够理解ssh(1)的选项 使用实例从本地服务器复制到远程服务器： # 指定了用户名，命令执行后需输入密码 $ scp -r img/* root@server:/var/project/img/ # 没有指定用户名，命令执行后需要输入用户名密码 $ scp -r img/* server:/var/project/img/ 从远程服务器复制到本地当前目录： $ scp -r server:/var/project/img/* .","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"https://jiangxingye.github.io/tags/linux命令/"}]},{"title":"每天一个linux命令（44）: rcp","slug":"linux-command（44）-rcp","date":"2017-01-12T02:36:06.000Z","updated":"2019-09-02T13:03:00.022Z","comments":true,"path":"2017/01/12/linux-command（44）-rcp/","link":"","permalink":"https://jiangxingye.github.io/2017/01/12/linux-command（44）-rcp/","excerpt":"rcp代表“remote file copy”（远程文件拷贝）。该命令用于在计算机之间拷贝文件。rcp命令有两种格式。第一种格式用于文件到文件的拷贝；第二种格式用于把文件或目录拷贝到另一个目录中。","text":"rcp代表“remote file copy”（远程文件拷贝）。该命令用于在计算机之间拷贝文件。rcp命令有两种格式。第一种格式用于文件到文件的拷贝；第二种格式用于把文件或目录拷贝到另一个目录中。 命令格式$ rcp [参数] [源文件] [目标文件] 命令功能 rcp命令用在远端复制文件或目录，如同时指定两个以上的文件或目录，且最后的目的地是一个已经存在的目录，则它会把前面指定的所有文件或目录复制到该目录中。 命令参数 命令 描述 -r 递归地把源目录中的所有内容拷贝到目的目录中。要使用这个选项，目的必须是一个目录 -p 试图保留源文件的修改时间和模式，忽略umask -k 请求rcp获得在指定区域内的远程主机的Kerberos 许可，而不是获得由krb_relmofhost⑶确定的远程主机区域内的远程主机的Kerberos许可。 -x 为传送的所有数据打开DES加密。这会影响响应时间和CPU利用率，但是可以提高安全性。如果在文件名中指定的路径不是完整的路径名，那么这个路径被解释为相对远程机上同名用户的主目录。如果没有给出远程用户名，就使用当前用户名。如果远程机上的路径包含特殊shell字符，需要用反斜线（\\）、双引号（”）或单引号（’）括起来，使所有的shell元字符都能被远程地解释。需要说明的是，rcp不提示输入口令，它通过rsh命令来执行拷贝。 directory 每个文件或目录参数既可以是远程文件名也可以是本地文件名。远程文件名具有如下形式：rname@rhost：path，其中rname是远程用户名，rhost是远程计算机名，path是这个文件的路径。 使用实例使用rcp，需要具备的条件 如果系统中有 /etc/hosts 文件，系统管理员应确保该文件包含要与之进行通信的远程主机的项。 /etc/hosts 文件中有一行文字，其中包含每个远程系统的以下信息： internet_address official_name alias 例如： 9.186.10.*** webserver1.com.58.webserver.rhosts 文件 .rhosts 文件位于远程系统的主目录下，其中包含本地系统的名称和本地登录名。 例如，远程系统的 .rhosts 文件中的项可能是： webserver1 root 其中，webserver1 是本地系统的名称，root 是本地登录名。这样，webserver1 上的 root 即可在包含.rhosts 文件的远程系统中来回复制文件。配置过程:只对root用户生效 在双方root用户根目录下建立.rhosts文件,并将双方的hostname加进去.在此之前应在双方的 /etc/hosts文件中加入对方的IP和hostname 把rsh服务启动起来,redhat默认是不启动的。方法：用执行ntsysv命令,在rsh选项前用空格键选中,确定退出。然后执行：service xinetd restart即可。 3.到/etc/pam.d/目录下,把rsh文件中的auth required /lib/security/pam_securetty.so一行用“#”注释掉即可。（只有注释掉这一行，才能用root用户登录） 例一：将本地img文件夹内的所有内容 复制到服务器相应的img目录下 # -r 递归子目录 $ rcp -r img/* webserver1:/var/project/img/ 例二：将服务器的img文件夹内的所有内容 复制到本地目录下 # -r 递归子目录 $ rcp -r webserver1:/var/project/img/* img/ 例三：将目录复制到远程系统：要将本地目录及其文件和子目录复制到远程系统 # 将本地的img目录复制到服务器的project目录下 $ rcp -r img/ webserver1:/var/project/","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"https://jiangxingye.github.io/tags/linux命令/"}]},{"title":"每天一个linux命令（43）: telnet","slug":"linux-command（43）-telnet","date":"2017-01-12T01:24:01.000Z","updated":"2019-09-02T13:03:00.022Z","comments":true,"path":"2017/01/12/linux-command（43）-telnet/","link":"","permalink":"https://jiangxingye.github.io/2017/01/12/linux-command（43）-telnet/","excerpt":"telnet命令通常用来远程登录。telnet程序是基于TELNET协议的远程登录客户端程序。Telnet协议是TCP/IP协议族中的一员，是Internet远程登陆服务的标准协议和主要方式。它为用户提供了在本地计算机上完成远程主机工作的 能力。在终端使用者的电脑上使用telnet程序，用它连接到服务器。终端使用者可以在telnet程序中输入命令，这些命令会在服务器上运行，就像直接在服务器的控制台上输入一样。可以在本地就能控制服务器。要开始一个 telnet会话，必须输入用户名和密码来登录服务器。Telnet是常用的远程控制Web服务器的方法。","text":"telnet命令通常用来远程登录。telnet程序是基于TELNET协议的远程登录客户端程序。Telnet协议是TCP/IP协议族中的一员，是Internet远程登陆服务的标准协议和主要方式。它为用户提供了在本地计算机上完成远程主机工作的 能力。在终端使用者的电脑上使用telnet程序，用它连接到服务器。终端使用者可以在telnet程序中输入命令，这些命令会在服务器上运行，就像直接在服务器的控制台上输入一样。可以在本地就能控制服务器。要开始一个 telnet会话，必须输入用户名和密码来登录服务器。Telnet是常用的远程控制Web服务器的方法。 但是，telnet因为采用明文传送报文，安全性不好，很多Linux服务器都不开放telnet服务，而改用更安全的ssh方式了。但仍然有很多别的系统可能采用了telnet方式来提供远程登录，因此弄清楚telnet客户端的使用方式仍是很有必要的。 telnet命令还可做别的用途，比如确定远程服务的状态，比如确定远程服务器的某个端口是否能访问。 命令格式$ telnet [参数][主机] 命令功能 执行telnet指令开启终端机阶段作业，并登入远端主机。 命令参数 命令 描述 -8 允许使用8位字符资料，包括输入与输出 -a 尝试自动登入远端系统 -b&lt;主机别名&gt; 使用别名指定远端主机名称 -c 不读取用户专属目录里的.telnetrc文件 -d 启动排错模式 -e&lt;脱离字符&gt; 设置脱离字符 -E 滤除脱离字符 -f 此参数的效果和指定”-F”参数相同 -F 使用Kerberos V5认证时，加上此参数可把本地主机的认证数据上传到远端主机 -k&lt;域名&gt; 使用Kerberos认证时，加上此参数让远端主机采用指定的领域名，而非该主机的域名 -K 不自动登入远端主机 -l&lt;用户名称&gt; 指定要登入远端主机的用户名称 -L 允许输出8位字符资料 -n&lt;记录文件&gt; 指定文件记录相关信息 -r 使用类似rlogin指令的用户界面 -S&lt;服务类型&gt; 设置telnet连线所需的IP TOS信息 -x 假设主机有支持数据加密的功能，就使用它 -X&lt;认证形态&gt; 关闭指定的认证形态 使用实例例一：远程服务器无法访问 $ telnet 192.168.120.206 Trying 192.168.120.209... telnet: connect to address 192.168.120.209: No route to host telnet: Unable to connect to remote host: No route to host 说明：处理这种情况方法： （1）确认ip地址是否正确？ （2）确认ip地址对应的主机是否已经开机？ （3）如果主机已经启动，确认路由设置是否设置正确？（使用route命令查看） （4）如果主机已经启动，确认主机上是否开启了telnet服务？（使用netstat命令查看，TCP的23端口是否有LISTEN状态的行） （5）如果主机已经启动telnet服务，确认防火墙是否放开了23端口的访问？（使用iptables-save查看） 例二：域名无法解析 $ telnet www.baidu.com www.baidu.com/telnet: Temporary failure in name resolution 说明：处理这种情况方法： （1）确认域名是否正确 （2）确认本机的域名解析有关的设置是否正确（/etc/resolv.conf中nameserver的设置是否正确，如果没有，可以使用nameserver 8.8.8.8） （3）确认防火墙是否放开了UDP53端口的访问（DNS使用UDP协议，端口53，使用iptables-save查看） 例三：连接被拒绝 $ telnet 192.168.120.206 Trying 192.168.120.206... telnet: connect to address 192.168.120.206: Connection refused telnet: Unable to connect to remote host: Connection refused 说明：处理这种情况： （1）确认ip地址或者主机名是否正确？ （2）确认端口是否正确，是否默认的23端口 例四：正常telnet $ telnet 192.168.120.204 Trying 192.168.120.204... Connected to 192.168.120.204 (192.168.120.204). Escape character is &#39;^]&#39;. localhost (Linux release 2.6.18-274.18.1.el5 #1 SMP Thu Feb 9 12:45:44 EST 2012) (1) login: root Password: Login incorrect 说明： 一般情况下不允许root从远程登录，可以先用普通账号登录，然后再用su -切到root用户。 例五：测试服务器8888端口是否可用 $ telnet 192.168.0.88 8888","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"https://jiangxingye.github.io/tags/linux命令/"}]},{"title":"每天一个linux命令（42）: ss","slug":"linux-command（42）-ss","date":"2017-01-11T02:34:47.000Z","updated":"2019-09-02T13:03:00.021Z","comments":true,"path":"2017/01/11/linux-command（42）-ss/","link":"","permalink":"https://jiangxingye.github.io/2017/01/11/linux-command（42）-ss/","excerpt":"ss是Socket Statistics的缩写。顾名思义，ss命令可以用来获取socket统计信息，它可以显示和netstat类似的内容。但ss的优势在于它能够显示更多更详细的有关TCP和连接状态的信息，而且比netstat更快速更高效。","text":"ss是Socket Statistics的缩写。顾名思义，ss命令可以用来获取socket统计信息，它可以显示和netstat类似的内容。但ss的优势在于它能够显示更多更详细的有关TCP和连接状态的信息，而且比netstat更快速更高效。 当服务器的socket连接数量变得非常大时，无论是使用netstat命令还是直接cat /proc/net/tcp，执行速度都会很慢。可能你不会有切身的感受，但请相信我，当服务器维持的连接达到上万个的时候，使用netstat等于浪费 生命，而用ss才是节省时间。 天下武功唯快不破。ss快的秘诀在于，它利用到了TCP协议栈中tcp_diag。tcp_diag是一个用于分析统计的模块，可以获得Linux 内核中第一手的信息，这就确保了ss的快捷高效。当然，如果你的系统中没有tcp_diag，ss也可以正常运行，只是效率会变得稍慢。（但仍然比 netstat要快。） 命令格式$ ss [参数] $ ss[参数] [过滤] 命令功能 ss(Socket Statistics的缩写)命令可以用来获取 socket统计信息，此命令输出的结果类似于 netstat输出的内容，但它能显示更多更详细的 TCP连接状态的信息，且比 netstat 更快速高效。它使用了 TCP协议栈中 tcp_diag（是一个用于分析统计的模块），能直接从获得第一手内核信息，这就使得 ss命令快捷高效。在没有 tcp_diag，ss也可以正常运行。 命令参数 命令 描述 -h, –help 帮助信息 -V, –version 程序版本信息 -n, –numeric 不解析服务名称 -r, –resolve 解析主机名 -a, –all 显示所有套接字（sockets） -l, –listening 显示监听状态的套接字（sockets） -o, –options 显示计时器信息 -e, –extended 显示详细的套接字（sockets）信息 -m, –memory 显示套接字（socket）的内存使用情况 -p, –processes 显示使用套接字（socket）的进程 -i, –info 显示 TCP内部信息 -s, –summary 显示套接字（socket）使用概况 -4, –ipv4 仅显示IPv4的套接字（sockets） -6, –ipv6 仅显示IPv6的套接字（sockets） -0, –packet 显示 PACKET 套接字（socket） -t, –tcp 仅显示 TCP套接字（sockets） -u, –udp 仅显示 UCP套接字（sockets） -d, –dccp 仅显示 DCCP套接字（sockets） -w, –raw 仅显示 RAW套接字（sockets） -x, –unix 仅显示 Unix套接字（sockets） -f, –family=FAMILY 显示 FAMILY类型的套接字（sockets），FAMILY可选，支持 unix, inet, inet6, link, netlink -A, –query=QUERY, –socket=QUERYQUERY := {all inet tcp udp raw unix packet netlink}[,QUERY] -D, –diag=FILE 将原始TCP套接字（sockets）信息转储到文件 -F, –filter=FILE 从文件中都去过滤器信息 FILTER := [ state TCP-STATE ] [ EXPRESSION ] 使用实例例一：显示TCP连接 $ ss -t -a 例二：显示 Sockets 摘要 $ ss -s Total: 1385 (kernel 0) TCP: 199 (estab 64, closed 76, orphaned 0, synrecv 0, timewait 1/0), ports 0 Transport Total IP IPv6 * 0 - - RAW 2 1 1 UDP 29 21 8 TCP 123 47 76 INET 154 69 85 FRAG 0 0 0 说明： 列出当前的established, closed, orphaned and waiting TCP sockets 例三：列出所有打开的网络连接端口 $ ss -l 例四：查看进程使用的socket $ ss -pl 例五：找出打开套接字/端口应用程序 $ ss -lp | grep 3306 例六：显示所有UDP Sockets $ ss -u -a 例七：显示所有状态为established的SMTP连接 $ ss -o state established &#39;( dport = :smtp or sport = :smtp )&#39; 例八：显示所有状态为Established的HTTP连接 $ ss -o state established &#39;( dport = :http or sport = :http )&#39; 例九：列举出处于 FIN-WAIT-1状态的源端口为 80或者 443，目标网络为 193.233.7/24所有 tcp套接字命令 $ ss -o state fin-wait-1 &#39;( sport = :http or sport = :https )&#39; dst 193.233.7/24 例十：用TCP 状态过滤Sockets $ ss -4 state FILTER-NAME-HERE $ ss -6 state FILTER-NAME-HERE 说明：FILTER-NAME-HERE 可以代表以下任何一个： established syn-sent syn-recv fin-wait-1 fin-wait-2 time-wait closed close-wait last-ack listen closing all : 所有以上状态 connected : 除了listen and closed的所有状态 synchronized :所有已连接的状态除了syn-sent bucket : 显示状态为maintained as minisockets,如：time-wait和syn-recv. big : 和bucket相反. 例十一：匹配远程地址和端口号 $ ss dst ADDRESS_PATTERN $ ss dst 192.168.1.5 $ ss dst 192.168.119.113:http $ ss dst 192.168.119.113:smtp $ ss dst 192.168.119.113:443 例十二：匹配本地地址和端口号 $ ss src ADDRESS_PATTERN $ ss src 192.168.119.103 $ ss src 192.168.119.103:http $ ss src 192.168.119.103:80 $ ss src 192.168.119.103:smtp $ ss src 192.168.119.103:25 例十三：将本地或者远程端口和一个数比较 $ ss dport OP PORT $ ss sport OP PORT 说明： ss dport OP PORT 远程端口和一个数比较；ss sport OP PORT 本地端口和一个数比较。 OP 可以代表以下任意一个: &lt;= or le : 小于或等于端口号 &gt;= or ge : 大于或等于端口号 == or eq : 等于端口号 != or ne : 不等于端口号 &lt; or gt : 小于端口号 &gt; or lt : 大于端口号 例十四：ss 和 netstat 效率对比 $ time netstat -at $ time ss 说明： 用time 命令分别获取通过netstat和ss命令获取程序和概要占用资源所使用的时间。在服务器连接数比较多的时候，netstat的效率完全没法和ss比。","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"https://jiangxingye.github.io/tags/linux命令/"}]},{"title":"每天一个linux命令（41）: netstat","slug":"linux-command（41）-netstat","date":"2017-01-10T01:54:16.000Z","updated":"2019-09-02T13:03:00.020Z","comments":true,"path":"2017/01/10/linux-command（41）-netstat/","link":"","permalink":"https://jiangxingye.github.io/2017/01/10/linux-command（41）-netstat/","excerpt":"netstat命令用于显示与IP、TCP、UDP和ICMP协议相关的统计数据，一般用于检验本机各端口的网络连接情况。netstat是在内核中访问网络及相关信息的程序，它能提供TCP连接，TCP和UDP监听，进程内存管理的相关报告。","text":"netstat命令用于显示与IP、TCP、UDP和ICMP协议相关的统计数据，一般用于检验本机各端口的网络连接情况。netstat是在内核中访问网络及相关信息的程序，它能提供TCP连接，TCP和UDP监听，进程内存管理的相关报告。 如果你的计算机有时候接收到的数据报导致出错数据或故障，你不必感到奇怪，TCP/IP可以容许这些类型的错误，并能够自动重发数据报。但如果累计的出错情况数目占到所接收的IP数据报相当大的百分比，或者它的数目正迅速增加，那么你就应该使用netstat查一查为什么会出现这些情况了。 命令格式$ netstat [-acCeFghilMnNoprstuvVwx][-A&lt;网络类型&gt;][--ip] 命令功能 netstat用于显示与IP、TCP、UDP和ICMP协议相关的统计数据，一般用于检验本机各端口的网络连接情况。 命令参数 命令 描述 -a或–all 显示所有连线中的Socket -A&lt;网络类型&gt;或–&lt;网络类型&gt; 列出该网络类型连线中的相关地址 -c或–continuous 持续列出网络状态 -C或–cache 显示路由器配置的快取信息 -e或–extend 显示网络其他相关信息 -F或–fib 显示FIB -g或–groups 显示多重广播功能群组组员名单 -h或–help 在线帮助 -i或–interfaces 显示网络界面信息表单 -l或–listening 显示监控中的服务器的Socket -M或–masquerade 显示伪装的网络连线 -n或–numeric 直接使用IP地址，而不通过域名服务器 -N或–netlink或–symbolic 显示网络硬件外围设备的符号连接名称 -o或–timers 显示计时器 -p或–programs 显示正在使用Socket的程序识别码和程序名称 -r或–route 显示Routing Table -s或–statistice 显示网络工作信息统计表 -t或–tcp 显示TCP传输协议的连线状况 -u或–udp 显示UDP传输协议的连线状况 -v或–verbose 显示指令执行过程 -V或–version 显示版本信息 -w或–raw 显示RAW传输协议的连线状况 -x或–unix 此参数的效果和指定”-A unix”参数相同 –ip或–inet 此参数的效果和指定”-A inet”参数相同 使用实例例一：无参数使用 $ netstat Active Internet connections (w/o servers) Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 268 192.168.120.204:ssh 10.2.0.68:62420 ESTABLISHED udp 0 0 192.168.120.204:4371 10.58.119.119:domain ESTABLISHED Active UNIX domain sockets (w/o servers) Proto RefCnt Flags Type State I-Node Path unix 2 [ ] DGRAM 1491 @/org/kernel/udev/udevd unix 4 [ ] DGRAM 7337 /dev/log unix 2 [ ] DGRAM 708823 unix 2 [ ] DGRAM 7539 unix 3 [ ] STREAM CONNECTED 7287 unix 3 [ ] STREAM CONNECTED 7286 说明： 从整体上看，netstat的输出结果可以分为两个部分： 一个是Active Internet connections，称为有源TCP连接，其中”Recv-Q”和”Send-Q”指的是接收队列和发送队列。这些数字一般都应该是0。如果不是则表示软件包正在队列中堆积。这种情况只能在非常少的情况见到。 另一个是Active UNIX domain sockets，称为有源Unix域套接口(和网络套接字一样，但是只能用于本机通信，性能可以提高一倍)。 Proto显示连接使用的协议,RefCnt表示连接到本套接口上的进程号,Types显示套接口的类型,State显示套接口当前的状态,Path表示连接到套接口的其它进程使用的路径名。套接口类型： -t ：TCP -u ：UDP -raw ：RAW类型 –unix ：UNIX域类型 –ax25 ：AX25类型 –ipx ：ipx类型 –netrom ：netrom类型状态说明： LISTEN：侦听来自远方的TCP端口的连接请求 SYN-SENT：再发送连接请求后等待匹配的连接请求（如果有大量这样的状态包，检查是否中招了） SYN-RECEIVED：再收到和发送一个连接请求后等待对方对连接请求的确认（如有大量此状态，估计被flood攻击了） ESTABLISHED：代表一个打开的连接 FIN-WAIT-1：等待远程TCP连接中断请求，或先前的连接中断请求的确认 FIN-WAIT-2：从远程TCP等待连接中断请求 CLOSE-WAIT：等待从本地用户发来的连接中断请求 CLOSING：等待远程TCP对连接中断的确认 LAST-ACK：等待原来的发向远程TCP的连接中断请求的确认（不是什么好东西，此项出现，检查是否被攻击） TIME-WAIT：等待足够的时间以确保远程TCP接收到连接中断请求的确认 CLOSED：没有任何连接状态 例二：列出所有端口 $ netstat -a Active Internet connections (servers and established) Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 localhost:smux *:* LISTEN tcp 0 0 *:svn *:* LISTEN tcp 0 0 *:ssh *:* LISTEN tcp 0 284 192.168.120.204:ssh 10.2.0.68:62420 ESTABLISHED udp 0 0 localhost:syslog *:* udp 0 0 *:snmp *:* Active UNIX domain sockets (servers and established) Proto RefCnt Flags Type State I-Node Path unix 2 [ ACC ] STREAM LISTENING 708833 /tmp/ssh-yKnDB15725/agent.15725 unix 2 [ ACC ] STREAM LISTENING 7296 /var/run/audispd_events unix 2 [ ] DGRAM 1491 @/org/kernel/udev/udevd unix 4 [ ] DGRAM 7337 /dev/log unix 2 [ ] DGRAM 708823 unix 2 [ ] DGRAM 7539 unix 3 [ ] STREAM CONNECTED 7287 unix 3 [ ] STREAM CONNECTED 7286 说明： 显示一个所有的有效连接信息列表，包括已建立的连接（ESTABLISHED），也包括监听连接请（LISTENING）的那些连接 例三：显示当前UDP连接状况 $ netstat -nu 例四：显示UDP端口号的使用情况 $ netstat -apu 例五：显示UDP端口号的使用情况 $ netstat -i 例六：显示组播组的关系 $ netstat -g 例七：显示网络统计信息 $ netstat -s 说明： 按照各个协议分别显示其统计数据。如果我们的应用程序（如Web浏览器）运行速度比较慢，或者不能显示Web页之类的数据，那么我们就可以用本选项来查看一下所显示的信息。我们需要仔细查看统计数据的各行，找到出错的关键字，进而确定问题所在。 例八：显示监听的套接口 $ netstat -l 例九：显示所有已建立的有效连接 $ netstat -n 例十：显示关于以太网的统计数据 $ netstat -e 说明： 用于显示关于以太网的统计数据。它列出的项目包括传送的数据报的总字节数、错误数、删除数、数据报的数量和广播的数量。这些统计数据既有发送的数据报数量，也有接收的数据报数量。这个选项可以用来统计一些基本的网络流量） 例十一：显示关于路由表的信息 $ netstat -r 例十二：列出所有 tcp 端口 $ netstat -at 例十三：统计机器中网络连接各个状态个数 $ netstat -a | awk &#39;/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}&#39; 例十四：把状态全都取出来后使用uniq -c统计后再进行排序 $ netstat -nat |awk &#39;{print $6}&#39;|sort|uniq -c 例十五：查看连接某服务端口最多的的IP地址 $ netstat -nat | grep &quot;192.168.120.20:16067&quot; |awk &#39;{print $5}&#39;|awk -F: &#39;{print $4}&#39;|sort|uniq -c|sort -nr|head -20 例十六：找出程序运行的端口 $ netstat -ap | grep ssh 例十七：在 netstat 输出中显示 PID 和进程名称 $ netstat -pt 说明： netstat -p 可以与其它开关一起使用，就可以添加 “PID/进程名称” 到 netstat 输出中，这样 debugging 的时候可以很方便的发现特定端口运行的程序 例十八：查看所有端口使用情况 $ netstat -tln 例十九：找出运行在指定端口的进程 $ netstat -anpt | grep &#39;:4000&#39; (Not all processes could be identified, non-owned process info will not be shown, you would have to be root to see it all.) tcp 0 0 0.0.0.0:4000 0.0.0.0:* LISTEN 5362/hexo tcp 0 0 127.0.0.1:4000 127.0.0.1:45884 ESTABLISHED 5362/hexo tcp 0 0 127.0.0.1:4000 127.0.0.1:45886 ESTABLISHED 5362/hexo 说明： 运行在端口4000的进程id为5362，再通过ps命令就可以找到具体的应用程序了","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"https://jiangxingye.github.io/tags/linux命令/"}]},{"title":"每天一个linux命令（40）: traceroute","slug":"linux-command（40）-traceroute","date":"2017-01-09T02:56:53.000Z","updated":"2019-09-02T13:03:00.020Z","comments":true,"path":"2017/01/09/linux-command（40）-traceroute/","link":"","permalink":"https://jiangxingye.github.io/2017/01/09/linux-command（40）-traceroute/","excerpt":"通过traceroute我们可以知道信息从你的计算机到互联网另一端的主机是走的什么路径。当然每次数据包由某一同样的出发点（source）到达某一同样的目的地(destination)走的路径可能会不一样，但基本上来说大部分时候所走的路由是相同的。linux系统中，我们称之为traceroute,在MS Windows中为tracert。 traceroute通过发送小的数据包到目的设备直到其返回，来测量其需要多长时间。一条路径上的每个设备traceroute要测3次。输出结果中包括每次测试的时间(ms)和设备的名称（如有的话）及其IP地址。","text":"通过traceroute我们可以知道信息从你的计算机到互联网另一端的主机是走的什么路径。当然每次数据包由某一同样的出发点（source）到达某一同样的目的地(destination)走的路径可能会不一样，但基本上来说大部分时候所走的路由是相同的。linux系统中，我们称之为traceroute,在MS Windows中为tracert。 traceroute通过发送小的数据包到目的设备直到其返回，来测量其需要多长时间。一条路径上的每个设备traceroute要测3次。输出结果中包括每次测试的时间(ms)和设备的名称（如有的话）及其IP地址。 在大多数情况下，我们会在linux主机系统下，直接执行命令行： traceroute hostname 而在Windows系统下是执行tracert的命令： tracert hostname 命令格式$ traceroute [参数] [主机] 命令功能 traceroute指令让你追踪网络数据包的路由途径，预设数据包大小是40Bytes，用户可另行设置。 具体参数格式：traceroute [-dFlnrvx][-f&lt;存活数值&gt;][-g&lt;网关&gt;…][-i&lt;网络界面&gt;][-m&lt;存活数值&gt;][-p&lt;通信端口&gt;][-s&lt;来源地址&gt;][-t&lt;服务类型&gt;][-w&lt;超时秒数&gt;][主机名称或IP地址][数据包大小] 命令参数 命令 描述 -d 使用Socket层级的排错功能 -f 设置第一个检测数据包的存活数值TTL的大小 -F 设置勿离断位 -g 设置来源路由网关，最多可设置8个 -i 使用指定的网络界面送出数据包 -I 使用ICMP回应取代UDP资料信息 -m 设置检测数据包的最大存活数值TTL的大小 -n 直接使用IP地址而非主机名称 -p 设置UDP传输协议的通信端口 -r 忽略普通的Routing Table，直接将数据包送到远端主机上 -s 设置本地主机送出数据包的IP地址 -t 设置检测数据包的TOS数值 -v 详细显示指令的执行过程 -w 设置等待远端主机回报的时间 -x 开启或关闭数据包的正确性检验 使用实例例一：traceroute 用法简单、最常用的用法 $ traceroute yelog.github.com traceroute to yelog.github.com (151.101.192.133), 30 hops max, 60 byte packets 1 vrouter (192.168.0.1) 0.443 ms 0.565 ms 0.684 ms 2 112.208.32.1.pldt.net (112.208.32.1) 14.518 ms 22.454 ms 23.080 ms 3 119.93.255.197 (119.93.255.197) 24.492 ms 25.380 ms 26.328 ms 4 210.213.131.66.static.pldt.net (210.213.131.66) 29.942 ms 210.213.131.70.static.pldt.net (210.213.131.70) 28.209 ms 28.992 ms 5 122.2.175.30.static.pldt.net (122.2.175.30) 32.429 ms 32.765 ms 210.213.128.29.static.pldt.net (210.213.128.29) 35.165 ms 6 210.213.130.162.static.pldt.net (210.213.130.162) 32.147 ms 31.403 ms 32.107 ms 7 las-b3-link.telia.net (62.115.13.128) 198.546 ms 190.829 ms 191.039 ms 8 las-b21-link.telia.net (213.155.131.82) 194.301 ms las-b21-link.telia.net (62.115.116.179) 191.927 ms las-b21-link.telia.net (213.155.131.84) 194.433 ms 9 * * * 10 * * * 说明： 记录按序列号从1开始，每个纪录就是一跳 ，每跳表示一个网关，我们看到每行有三个时间，单位是 ms，其实就是-q的默认参数。探测数据包向每个网关发送三个数据包后，网关响应后返回的时间；如果您用 traceroute -q 4 www.58.com ，表示向每个网关发送4个数据包。 有时我们traceroute 一台主机时，会看到有一些行是以星号表示的。出现这样的情况，可能是防火墙封掉了ICMP的返回信息，所以我们得不到什么相关的数据包返回数据。 有时我们在某一网关处延时比较长，有可能是某台网关比较阻塞，也可能是物理设备本身的原因。当然如果某台DNS出现问题时，不能解析主机名、域名时，也会 有延时长的现象；您可以加-n 参数来避免DNS解析，以IP格式输出数据。 如果在局域网中的不同网段之间，我们可以通过traceroute 来排查问题所在，是主机的问题还是网关的问题。如果我们通过远程来访问某台服务器遇到问题时，我们用到traceroute 追踪数据包所经过的网关，提交IDC服务商，也有助于解决问题；但目前看来在国内解决这样的问题是比较困难的，就是我们发现问题所在，IDC服务商也不可能帮助我们解决。 例二：跳数设置 $ traceroute -m 10 www.baidu.com 例三：显示IP地址，不查主机名 $ traceroute -n www.baidu.com 例四：探测包使用的基本UDP端口设置6888 $ traceroute -p 6888 www.baidu.com 例五：把探测包的个数设置为值4 $ traceroute -q 4 www.baidu.com 例六：绕过正常的路由表，直接发送到网络相连的主机 $ traceroute -r www.baidu.com 例七：把对外发探测包的等待响应时间设置为3秒 $ traceroute -w 3 www.baidu.com Traceroute的工作原理 Traceroute最简单的基本用法是：traceroute hostname Traceroute程序的设计是利用ICMP及IP header的TTL（Time To Live）栏位（field）。首先，traceroute送出一个TTL是1的IP datagram（其实，每次送出的为3个40字节的包，包括源地址，目的地址和包发出的时间标签）到目的地，当路径上的第一个路由器（router）收到这个datagram时，它将TTL减1。此时，TTL变为0了，所以该路由器会将此datagram丢掉，并送回一个「ICMP time exceeded」消息（包括发IP包的源地址，IP包的所有内容及路由器的IP地址），traceroute 收到这个消息后，便知道这个路由器存在于这个路径上，接着traceroute 再送出另一个TTL是2 的datagram，发现第2 个路由器…… traceroute 每次将送出的datagram的TTL 加1来发现另一个路由器，这个重复的动作一直持续到某个datagram 抵达目的地。当datagram到达目的地后，该主机并不会送回ICMP time exceeded消息，因为它已是目的地了，那么traceroute如何得知目的地到达了呢？ Traceroute在送出UDP datagrams到目的地时，它所选择送达的port number 是一个一般应用程序都不会用的号码（30000 以上），所以当此UDP datagram 到达目的地后该主机会送回一个「ICMP port unreachable」的消息，而当traceroute 收到这个消息时，便知道目的地已经到达了。所以traceroute 在Server端也是没有所谓的Daemon 程式。 Traceroute提取发 ICMP TTL到期消息设备的IP地址并作域名解析。每次 ，Traceroute都打印出一系列数据,包括所经过的路由设备的域名及 IP地址,三个包每次来回所花时间。 windows之tracert 格式： $ tracert [-d] [-h maximum_hops] [-j host-list] [-w timeout] target_name 参数说明 tracert [-d] [-h maximum_hops] [-j computer-list] [-w timeout] target_name 该诊断实用程序通过向目的地发送具有不同生存时间 (TL) 的 Internet 控制信息协议 (CMP) 回应报文，以确定至目的地的路由。路径上的每个路由器都要在转发该 ICMP 回应报文之前将其 TTL 值至少减 1，因此 TTL 是有效的跳转计数。当报文的 TTL 值减少到 0 时，路由器向源系统发回 ICMP 超时信息。通过发送 TTL 为 1 的第一个回应报文并且在随后的发送中每次将 TTL 值加 1，直到目标响应或达到最大 TTL 值，Tracert 可以确定路由。通过检查中间路由器发发回的 ICMP 超时 (ime Exceeded) 信息，可以确定路由器。注意，有些路由器“安静”地丢弃生存时间 (TLS) 过期的报文并且对 tracert 无效。参数：-d 指定不对计算机名解析地址。-h maximum_hops 指定查找目标的跳转的最大数目。-jcomputer-list 指定在 computer-list 中松散源路由。-w timeout 等待由 timeout 对每个应答指定的毫秒数。target_name 目标计算机的名称。","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"https://jiangxingye.github.io/tags/linux命令/"}]},{"title":"每天一个linux命令（39）: ping","slug":"linux-command（39）-ping","date":"2017-01-08T02:24:50.000Z","updated":"2019-09-02T13:03:00.018Z","comments":true,"path":"2017/01/08/linux-command（39）-ping/","link":"","permalink":"https://jiangxingye.github.io/2017/01/08/linux-command（39）-ping/","excerpt":"Linux系统的ping命令是常用的网络命令，它通常用来测试与目标主机的连通性，我们经常会说“ping一下某机器，看是不是开着”、不能打开网页时会说“你先ping网关地址192.168.1.1试试”。它通过发送ICMP ECHO_REQUEST数据包到网络主机（send ICMP ECHO_REQUEST to network hosts），并显示响应情况，这样我们就可以根据它输出的信息来确定目标主机是否可访问（但这不是绝对的）。有些服务器为了防止通过ping探测到，通过防火墙设置了禁止ping或者在内核参数中禁止ping，这样就不能通过ping确定该主机是否还处于开启状态。","text":"Linux系统的ping命令是常用的网络命令，它通常用来测试与目标主机的连通性，我们经常会说“ping一下某机器，看是不是开着”、不能打开网页时会说“你先ping网关地址192.168.1.1试试”。它通过发送ICMP ECHO_REQUEST数据包到网络主机（send ICMP ECHO_REQUEST to network hosts），并显示响应情况，这样我们就可以根据它输出的信息来确定目标主机是否可访问（但这不是绝对的）。有些服务器为了防止通过ping探测到，通过防火墙设置了禁止ping或者在内核参数中禁止ping，这样就不能通过ping确定该主机是否还处于开启状态。 linux下的ping和windows下的ping稍有区别,linux下ping不会自动终止,需要按ctrl+c终止或者用参数-c指定要求完成的回应次数。 命令格式$ ping [参数] [主机名或IP地址] 命令功能 ping命令用于：确定网络和各外部主机的状态；跟踪和隔离硬件和软件问题；测试、评估和管理网络。如果主机正在运行并连在网上，它就对回送信号进行响应。每个回送信号请求包含一个网际协议（IP）和 ICMP 头，后面紧跟一个 tim 结构，以及来填写这个信息包的足够的字节。缺省情况是连续发送回送信号请求直到接收到中断信号（Ctrl-C）。 ping 命令每秒发送一个数据报并且为每个接收到的响应打印一行输出。ping 命令计算信号往返时间和(信息)包丢失情况的统计信息，并且在完成之后显示一个简要总结。ping 命令在程序超时或当接收到 SIGINT 信号时结束。Host 参数或者是一个有效的主机名或者是因特网地址。 命令参数 命令 描述 -d 使用Socket的SO_DEBUG功能 -f 极限检测。大量且快速地送网络封包给一台机器，看它的回应 -n 只输出数值 -q 不显示任何传送封包的信息，只显示最后的结果 -r 忽略普通的Routing Table，直接将数据包送到远端主机上。通常是查看本机的网络接口是否有问题 -R 记录路由过程 -v 详细显示指令的执行过程 -c 数目 在发送指定数目的包后停止 -i 秒数 设定间隔几秒送一个网络封包给一台机器，预设值是一秒送一次 -I 网络界面 使用指定的网络界面送出数据包 -l 前置载入 设置在送出要求信息之前，先行发出的数据包 -p 范本样式 设置填满数据包的范本样式 -s 字节数 指定发送的数据字节数，预设值是56，加上8字节的ICMP头，一共是64ICMP数据字节 -t 存活数值 设置存活数值TTL的大小 使用实例例一：ping通的情况 $ ping 192.168.0.1 PING 192.168.0.1 (192.168.0.1) 56(84) bytes of data. 64 bytes from 192.168.0.1: icmp_seq=1 ttl=64 time=0.238 ms 64 bytes from 192.168.0.1: icmp_seq=2 ttl=64 time=0.202 ms 64 bytes from 192.168.0.1: icmp_seq=3 ttl=64 time=0.232 ms 64 bytes from 192.168.0.1: icmp_seq=4 ttl=64 time=0.210 ms --- 192.168.0.1 ping statistics --- 6 packets transmitted, 6 received, 0% packet loss, time 4997ms 例二：ping不通的情况 $ ping 192.168.0.222 PING 192.168.0.222 (192.168.0.222) 56(84) bytes of data. From 192.168.0.101 icmp_seq=1 Destination Host Unreachable From 192.168.0.101 icmp_seq=2 Destination Host Unreachable From 192.168.0.101 icmp_seq=3 Destination Host Unreachable --- 192.168.0.222 ping statistics --- 7 packets transmitted, 0 received, +6 errors, 100% packet loss, time 6032ms pipe 3 例二：ping指定次数 $ ping -c 192.168.0.1 例三：时间间隔和次数限制的ping $ ping -c 10 -i 0.5 192.168.120.206 例四：通过域名ping公网上的站点 $ ping -c 5 yelog.github.com 例五：多参数使用 # -i 3 发送周期为 3秒 -s 设置发送包的大小为1024 -t 设置TTL值为 255 $ ping -i 3 -s 1024 -t yelog.github.com PING github.map.fastly.net (151.101.192.133) 1024(1052) bytes of data. 1032 bytes from 151.101.192.133 (151.101.192.133): icmp_seq=1 ttl=56 time=191 ms 1032 bytes from 151.101.192.133 (151.101.192.133): icmp_seq=2 ttl=56 time=190 ms 1032 bytes from 151.101.192.133 (151.101.192.133): icmp_seq=3 ttl=56 time=189 ms 1032 bytes from 151.101.192.133 (151.101.192.133): icmp_seq=4 ttl=56 time=190 ms","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"https://jiangxingye.github.io/tags/linux命令/"}]},{"title":"每天一个linux命令（38）: route","slug":"linux-command（38）-route","date":"2017-01-07T02:16:34.000Z","updated":"2019-09-02T13:03:00.017Z","comments":true,"path":"2017/01/07/linux-command（38）-route/","link":"","permalink":"https://jiangxingye.github.io/2017/01/07/linux-command（38）-route/","excerpt":"Linux系统的route命令用于显示和操作IP路由表（show / manipulate the IP routing table）。要实现两个不同的子网之间的通信，需要一台连接两个网络的路由器，或者同时位于两个网络的网关来实现。在Linux系统中，设置路由通常是为了解决以下问题：该Linux系统在一个局域网中，局域网中有一个网关，能够让机器访问Internet，那么就需要将这台机器的IP地址设置为Linux机器的默认路由。要注意的是，直接在命令行下执行route命令来添加路由，不会永久保存，当网卡重启或者机器重启之后，该路由就失效了；可以在/etc/rc.local中添加route命令来保证该路由设置永久有效。","text":"Linux系统的route命令用于显示和操作IP路由表（show / manipulate the IP routing table）。要实现两个不同的子网之间的通信，需要一台连接两个网络的路由器，或者同时位于两个网络的网关来实现。在Linux系统中，设置路由通常是为了解决以下问题：该Linux系统在一个局域网中，局域网中有一个网关，能够让机器访问Internet，那么就需要将这台机器的IP地址设置为Linux机器的默认路由。要注意的是，直接在命令行下执行route命令来添加路由，不会永久保存，当网卡重启或者机器重启之后，该路由就失效了；可以在/etc/rc.local中添加route命令来保证该路由设置永久有效。 命令格式route [-f] [-p] [Command [Destination] [mask Netmask] [Gateway] [metric Metric]] [if Interface]] 命令功能 Route命令是用于操作基于内核ip路由表，它的主要作用是创建一个静态路由让指定一个主机或者一个网络通过一个网络接口，如eth0。当使用”add”或者”del”参数时，路由表被修改，如果没有参数，则显示路由表当前的内容。 命令参数 命令 描述 -c 显示更多信息 -n 不解析名字 -v 显示详细的处理信息 -F 显示发送信息 -C 显示路由缓存 -f 清除所有网关入口的路由表 -p 与 add 命令 -p 与 add 命令一起使用时使路由具有永久性。 add 添加一条新路由 del 删除一条路由 -net 目标地址是一个网络 -host 目标地址是一个主机 netmask 当添加一个网络路由时，需要使用网络掩码 gw 路由数据包通过网关。注意，你指定的网关必须能够达到 metric 设置路由跳数 Command 指定您想运行的命令 (Add/Change/Delete/Print) Destination 指定该路由的网络目标 mask Netmask 指定与网络目标相关的网络掩码（也被称作子网掩码） Gateway 指定网络目标定义的地址集和子网掩码可以到达的前进或下一跃点 IP 地址 metric Metric 为路由指定一个整数成本值标（从 1 至 9999），当在路由表(与转发的数据包目标地址最匹配)的多个路由中进行选择时可以使用 if Interface 为可以访问目标的接口指定接口索引。若要获得一个接口列表和它们相应的接口索引，使用 route print 命令的显示功能。可以使用十进制或十六进制值进行接口索引 使用实例例一：显示当前路由 $ route $ route -n [root@localhost ~]# route Kernel IP routing table Destination Gateway Genmask Flags Metric Ref Use Iface 192.168.120.0 * 255.255.255.0 U 0 0 0 eth0 e192.168.0.0 192.168.120.1 255.255.0.0 UG 0 0 0 eth0 10.0.0.0 192.168.120.1 255.0.0.0 UG 0 0 0 eth0 default 192.168.120.240 0.0.0.0 UG 0 0 0 eth0 [root@localhost ~]# route -n Kernel IP routing table Destination Gateway Genmask Flags Metric Ref Use Iface 192.168.120.0 0.0.0.0 255.255.255.0 U 0 0 0 eth0 192.168.0.0 192.168.120.1 255.255.0.0 UG 0 0 0 eth0 10.0.0.0 192.168.120.1 255.0.0.0 UG 0 0 0 eth0 0.0.0.0 192.168.120.240 0.0.0.0 UG 0 0 0 eth0 说明： 第一行表示主机所在网络的地址为192.168.120.0，若数据传送目标是在本局域网内通信，则可直接通过eth0转发数据包; 第四行表示数据传送目的是访问Internet，则由接口eth0，将数据包发送到网关192.168.120.240 其中Flags为路由标志，标记当前网络节点的状态。 Flags标志说明： U Up表示此路由当前为启动状态 H Host，表示此网关为一主机 G Gateway，表示此网关为一路由器 R Reinstate Route，使用动态路由重新初始化的路由 D Dynamically,此路由是动态性地写入 M Modified，此路由是由路由守护程序或导向器动态修改 ! 表示此路由当前为关闭状态备注： route -n (-n 表示不解析名字,列出速度会比route 快) 例二：添加网关/设置网关 # 增加一条 到达244.0.0.0的路由 $ route add -net 224.0.0.0 netmask 240.0.0.0 dev eth0 例三：屏蔽一条路由 # 增加一条屏蔽的路由，目的地址为 224.x.x.x 将被拒绝 $ route add -net 224.0.0.0 netmask 240.0.0.0 reject 例四：删除路由记录 $ route del -net 224.0.0.0 netmask 240.0.0.0 $ route del -net 224.0.0.0 netmask 240.0.0.0 reject 例五：删除和添加设置默认网关 $ route del default gw 192.168.120.240 $ route add default gw 192.168.120.240","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"https://jiangxingye.github.io/tags/linux命令/"}]},{"title":"每天一个linux命令（37）: ifconfig","slug":"linux-command（37）-ifconfig","date":"2017-01-06T01:57:01.000Z","updated":"2019-09-02T13:03:00.017Z","comments":true,"path":"2017/01/06/linux-command（37）-ifconfig/","link":"","permalink":"https://jiangxingye.github.io/2017/01/06/linux-command（37）-ifconfig/","excerpt":"许多windows非常熟悉ipconfig命令行工具，它被用来获取网络接口配置信息并对此进行修改。Linux系统拥有一个类似的工具，也就是ifconfig(interfaces config)。通常需要以root身份登录或使用sudo以便在Linux机器上使用ifconfig工具。依赖于ifconfig命令中使用一些选项属性，ifconfig工具不仅可以被用来简单地获取网络接口配置信息，还可以修改这些配置。","text":"许多windows非常熟悉ipconfig命令行工具，它被用来获取网络接口配置信息并对此进行修改。Linux系统拥有一个类似的工具，也就是ifconfig(interfaces config)。通常需要以root身份登录或使用sudo以便在Linux机器上使用ifconfig工具。依赖于ifconfig命令中使用一些选项属性，ifconfig工具不仅可以被用来简单地获取网络接口配置信息，还可以修改这些配置。 命令格式$ ifconfig [网络设备] [参数] 命令功能 ifconfig 命令用来查看和配置网络设备。当网络环境发生改变时可通过此命令对网络进行相应的配置。 注意： 用ifconfig命令配置的网卡信息，在网卡重启后机器重启后，配置就不存在。要想将上述的配置信息永远的存的电脑里，那就要修改网卡的配置文件了。 命令参数 命令 描述 up 启动指定网络设备/网卡 down 关闭指定网络设备/网卡。该参数可以有效地阻止通过指定接口的IP信息流，如果想永久地关闭一个接口，我们还需要从核心路由表中将该接口的路由信息全部删除 arp 设置指定网卡是否支持ARP协议 -promisc 设置是否支持网卡的promiscuous模式，如果选择此参数，网卡将接收网络中发给它所有的数据包 -allmulti 设置是否支持多播模式，如果选择此参数，网卡将接收网络中所有的多播数据包 -a 显示全部接口信息 -s 显示摘要信息（类似于 netstat -i） add 给指定网卡配置IPv6地址 del 删除指定网卡的IPv6地址 &lt;硬件地址&gt; 配置网卡最大的传输单元 mtu&lt;字节数&gt; 设置网卡的最大传输单元 (bytes) netmask&lt;子网掩码&gt; 设置网卡的子网掩码。掩码可以是有前缀0x的32位十六进制数，也可以是用点分开的4个十进制数。如果不打算将网络分成子网，可以不管这一选项；如果要使用子网，那么请记住，网络中每一个系统必须有相同子网掩码 tunel 建立隧道 dstaddr 设定一个远端地址，建立点对点通信 -broadcast&lt;地址&gt; 为指定网卡设置广播协议 -pointtopoint&lt;地址&gt; 为网卡设置点对点通讯协议 multicast 为网卡设置组播标志 address 为网卡设置IPv4地址 txqueuelen&lt;长度&gt; 为网卡设置传输列队的长度 使用实例例一：显示网络设备信息（激活状态的） $ ifconfig 说明： eth0 表示第一块网卡， 其中 HWaddr 表示网卡的物理地址，可以看到目前这个网卡的物理地址(MAC地址）是 00:50:56:BF:26:20 inet addr 用来表示网卡的IP地址，此网卡的 IP地址是 192.168.120.204，广播地址， Bcast:192.168.120.255，掩码地址Mask:255.255.255.0 lo 是表示主机的回坏地址，这个一般是用来测试一个网络程序，但又不想让局域网或外网的用户能够查看，只能在此台主机上运行和查看所用的网络接口。比如把 HTTPD服务器的指定到回坏地址，在浏览器输入 127.0.0.1 就能看到你所架WEB网站了。但只是您能看得到，局域网的其它主机或用户无从知道。 第一行：连接类型：Ethernet（以太网）HWaddr（硬件mac地址） 第二行：网卡的IP地址、子网、掩码 第三行：UP（代表网卡开启状态）RUNNING（代表网卡的网线被接上）MULTICAST（支持组播）MTU:1500（最大传输单元）：1500字节 第四、五行：接收、发送数据包情况统计 第七行：接收、发送数据字节数统计信息。 例二：启动关闭指定网卡 # 启动eth0网卡 $ ifconfig eth0 up # 关闭eth0网卡 $ ifconfig eth0 down 注意： ssh登陆linux服务器操作要小心，关闭了就不能开启了，除非你有多网卡。 例三：为网卡配置和删除IPv6地址 # 配置IPv6的地址 $ ifconfig eth0 add 33ffe:3240:800:1005::2/64 # 删除IPv6的地址 $ ifconfig eth0 del 33ffe:3240:800:1005::2/64 例四：用ifconfig修改MAC地址 $ ifconfig eth0 hw ether 00:AA:BB:CC:DD:EE 例五：配置IP地址 # 配置ip $ ifconfig eth0 192.168.120.56 # 配置ip和掩码地址 $ ifconfig eth0 192.168.120.56 netmask 255.255.255.0 # 配置ip、掩码地址和广播地址 $ ifconfig eth0 192.168.120.56 netmask 255.255.255.0 broadcast 192.168.120.255 例六：启用和关闭ARP协议 # 启用eth0的ARP协议 $ ifconfig eth0 arp # 关闭eth0的ARP协议 $ ifconfig eth0 -arp 例七：设置最大传输单元 # 设置能通过的最大数据包大小为 1500 bytes $ ifconfig eth0 mtu 1500","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"https://jiangxingye.github.io/tags/linux命令/"}]},{"title":"每天一个linux命令（36）: lsof","slug":"linux-command（36）-lsof","date":"2017-01-05T02:28:13.000Z","updated":"2019-09-02T13:03:00.016Z","comments":true,"path":"2017/01/05/linux-command（36）-lsof/","link":"","permalink":"https://jiangxingye.github.io/2017/01/05/linux-command（36）-lsof/","excerpt":"lsof（list open files）是一个列出当前系统打开文件的工具。在linux环境下，任何事物都以文件的形式存在，通过文件不仅仅可以访问常规数据，还可以访问网络连接和硬件。所以如传输控制协议 (TCP) 和用户数据报协议 (UDP) 套接字等，系统在后台都为该应用程序分配了一个文件描述符，无论这个文件的本质如何，该文件描述符为应用程序与基础操作系统之间的交互提供了通用接口。因为应用程序打开文件的描述符列表提供了大量关于这个应用程序本身的信息，因此通过lsof工具能够查看这个列表对系统监测以及排错将是很有帮助的。","text":"lsof（list open files）是一个列出当前系统打开文件的工具。在linux环境下，任何事物都以文件的形式存在，通过文件不仅仅可以访问常规数据，还可以访问网络连接和硬件。所以如传输控制协议 (TCP) 和用户数据报协议 (UDP) 套接字等，系统在后台都为该应用程序分配了一个文件描述符，无论这个文件的本质如何，该文件描述符为应用程序与基础操作系统之间的交互提供了通用接口。因为应用程序打开文件的描述符列表提供了大量关于这个应用程序本身的信息，因此通过lsof工具能够查看这个列表对系统监测以及排错将是很有帮助的。 命令格式$ lsof [参数][文件] 命令功能 用于查看你进程开打的文件，打开文件的进程，进程打开的端口(TCP、UDP)。找回/恢复删除的文件。是十分方便的系统监视工具，因为 lsof 需要访问核心内存和各种文件，所以需要root用户执行。lsof打开的文件可以是： 普通文件 目录 网络文件系统的文件 字符或设备文件 (函数)共享库 管道，命名管道 符号链接 网络文件（例如：NFS file、网络socket，unix域名socket） 还有其它类型的文件，等等 命令参数 命令 描述 -a 列出打开文件存在的进程 -c&lt;进程名&gt; 列出指定进程所打开的文件 -g 列出GID号进程详情 -d&lt;文件号&gt; 列出占用该文件号的进程 +d&lt;目录&gt; 列出目录下被打开的文件 +D&lt;目录&gt; 递归列出目录下被打开的文件 -n&lt;目录&gt; 列出使用NFS的文件 -i&lt;条件&gt; 列出符合条件的进程。（4、6、协议、:端口、 @ip ） -p&lt;进程号&gt; 列出指定进程号所打开的文件 -u 列出UID号进程详情 -h 显示帮助信息 -v 显示版本信息 使用实例例一：无任何参数 $ lsof COMMAND PID USER FD TYPE DEVICE SIZE NODE NAME init 1 root cwd DIR 8,2 4096 2 / init 1 root rtd DIR 8,2 4096 2 / init 1 root txt REG 8,2 43496 6121706 /sbin/init init 1 root mem REG 8,2 143600 7823908 /lib64/ld-2.5.so init 1 root mem REG 8,2 1722304 7823915 /lib64/libc-2.5.so init 1 root mem REG 8,2 23360 7823919 /lib64/libdl-2.5.so init 1 root mem REG 8,2 95464 7824116 /lib64/libselinux.so.1 init 1 root mem REG 8,2 247496 7823947 /lib64/libsepol.so.1 init 1 root 10u FIFO 0,17 1233 /dev/initctl migration 2 root cwd DIR 8,2 4096 2 / migration 2 root rtd DIR 8,2 4096 2 / migration 2 root txt unknown /proc/2/exe ksoftirqd 3 root cwd DIR 8,2 4096 2 / ksoftirqd 3 root rtd DIR 8,2 4096 2 / ksoftirqd 3 root txt unknown /proc/3/exe migration 4 root cwd DIR 8,2 4096 2 / migration 4 root rtd DIR 8,2 4096 2 / migration 4 root txt unknown /proc/4/exe ksoftirqd 5 root cwd DIR 8,2 4096 2 / ksoftirqd 5 root rtd DIR 8,2 4096 2 / ksoftirqd 5 root txt unknown /proc/5/exe events/0 6 root cwd DIR 8,2 4096 2 / events/0 6 root rtd DIR 8,2 4096 2 / events/0 6 root txt unknown /proc/6/exe events/1 7 root cwd DIR 8,2 4096 2 / 说明：lsof输出各列信息的意义如下：COMMAND：进程的名称PID：进程标识符PPID：父进程标识符（需要指定-R参数）USER：进程所有者PGID：进程所属组FD：文件描述符，应用程序通过文件描述符识别该文件。如cwd、txt等（1）cwd：表示current work dirctory，即：应用程序的当前工作目录，这是该应用程序启动的目录，除非它本身对这个目录进行更改（2）txt ：该类型的文件是程序代码，如应用程序二进制文件本身或共享库，如上列表中显示的 /sbin/init 程序（3）lnn：library references (AIX);（4）er：FD information error (see NAME column);（5）jld：jail directory (FreeBSD);（6）ltx：shared library text (code and data);（7）mxx ：hex memory-mapped type number xx.（8）m86：DOS Merge mapped file;（9）mem：memory-mapped file;（10）mmap：memory-mapped device;（11）pd：parent directory;（12）rtd：root directory;（13）tr：kernel trace file (OpenBSD);（14）v86 VP/ix mapped file;（15）0：表示标准输出（16）1：表示标准输入（17）2：表示标准错误一般在标准输出、标准错误、标准输入后还跟着文件状态模式：r、w、u等（1）u：表示该文件被打开并处于读取/写入模式（2）r：表示该文件被打开并处于只读模式（3）w：表示该文件被打开并处于（4）空格：表示该文件的状态模式为unknow，且没有锁定（5）-：表示该文件的状态模式为unknow，且被锁定同时在文件状态模式后面，还跟着相关的锁（1）N：for a Solaris NFS lock of unknown type;（2）r：for read lock on part of the file;（3）R：for a read lock on the entire file;（4）w：for a write lock on part of the file;（文件的部分写锁）（5）W：for a write lock on the entire file;（整个文件的写锁）（6）u：for a read and write lock of any length;（7）U：for a lock of unknown type;（8）x：for an SCO OpenServer Xenix lock on part of the file;（9）X：for an SCO OpenServer Xenix lock on the entire file;（10）space：if there is no lock.TYPE：文件类型，如DIR、REG等，常见的文件类型（1）DIR：表示目录（2）CHR：表示字符类型（3）BLK：块设备类型（4）UNIX： UNIX 域套接字（5）FIFO：先进先出 (FIFO) 队列（6）IPv4：网际协议 (IP) 套接字DEVICE：指定磁盘的名称SIZE：文件的大小NODE：索引节点（文件在磁盘上的标识）NAME：打开文件的确切名称 例二：查看谁正在使用某个文件，也就是说查找某个文件相关的进程 $ lsof /bin/bash COMMAND PID USER FD TYPE DEVICE SIZE NODE NAME bash 24159 root txt REG 8,2 801528 5368780 /bin/bash bash 24909 root txt REG 8,2 801528 5368780 /bin/bash bash 24941 root txt REG 8,2 801528 5368780 /bin/bash 例三：递归查看某个目录的文件信息 $ lsof test/test3 COMMAND PID USER FD TYPE DEVICE SIZE NODE NAME bash 24941 root cwd DIR 8,2 4096 2258872 test/test3 vi 24976 root cwd DIR 8,2 4096 2258872 test/test3 说明： 使用了+D，对应目录下的所有子目录和文件都会被列出 例四：不使用+D选项，遍历查看某个目录的所有文件信息的方法 $ lsof |grep &#39;test/test3&#39; 例五：列出某个用户打开的文件信息 # -u 选项，u其实是user的缩写 $ lsof -u username 例六：列出某个程序进程所打开的文件信息 $ lsof -c mysql 说明：-c 选项将会列出所有以mysql这个进程开头的程序的文件，其实你也可以写成 lsof | grep mysql, 但是第一种方法明显比第二种方法要少打几个字符了 例七：列出多个进程多个打开的文件信息 $ lsof -c mysql -c apache 例八：列出某个用户以及某个进程所打开的文件信息 $ lsof -u test -c mysql 例九：列出除了某个用户外的被打开的文件信息 # ^这个符号在用户名之前，将会把是root用户打开的进程不让显示 $ lsof -u ^root 例十：通过某个进程号显示该进行打开的文件 $ lsof -p 1 例十一：列出多个进程号对应的文件信息 $ lsof -p 1,2,3 例十二：列出除了某个进程号，其他进程号所打开的文件信息 $ lsof -p ^1 例十三：列出所有的网络连接 $ lsof -i 例十四：列出所有tcp 网络连接信息 $ lsof -i tcp 例十五：列出所有udp网络连接信息 $ lsof -i udp 例十六：列出谁在使用某个端口 $ lsof -i :3306 例十七：列出谁在使用某个特定的udp/tcp端口 $ lsof -i udp:55 $ lsof -i tcp:80 例十八：列出某个用户的所有活跃的网络端口 $ lsof -a -u test -i 例十九：列出所有网络文件系统 $ lsof -N 例二十：域名socket文件 $ lsof -u 例二十一：某个用户组所打开的文件信息 $ lsof -g 5555 例二十二：根据文件描述列出对应的文件信息 $ lsof -d description(like 2) 例如：lsof -d txt 例如：lsof -d 1 例如：lsof -d 2 说明：0表示标准输入，1表示标准输出，2表示标准错误，从而可知：所以大多数应用程序所打开的文件的 FD 都是从 3 开始 例二十三：根据文件描述范围列出文件信息 $ lsof -d 2-3 例二十四：列出COMMAND列中包含字符串” sshd”，且文件描符的类型为txt的文件信息 $ lsof -c sshd -a -d txt 例二十五：列出被进程号为1234的进程所打开的所有IPV4 network files $ lsof -i 4 -a -p 1234 例二十六：列出目前连接主机peida.linux上端口为：20，21，22，25，53，80相关的所有文件信息，且每隔3秒不断的执行lsof指令 $ lsof -i @peida.linux:20,21,22,25,53,80 -r 3","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"https://jiangxingye.github.io/tags/linux命令/"}]},{"title":"每天一个linux命令（35）: iostat","slug":"linux-command（35）-iostat","date":"2017-01-04T02:10:02.000Z","updated":"2019-09-02T13:03:00.016Z","comments":true,"path":"2017/01/04/linux-command（35）-iostat/","link":"","permalink":"https://jiangxingye.github.io/2017/01/04/linux-command（35）-iostat/","excerpt":"Linux系统中的 iostat是I/O statistics（输入/输出统计）的缩写，iostat工具将对系统的磁盘操作活动进行监视。它的特点是汇报磁盘活动统计情况，同时也会汇报出CPU使用情况。同vmstat一样，iostat也有一个弱点，就是它不能对某个进程进行深入分析，仅对系统的整体情况进行分析。iostat属于sysstat软件包。可以用yum install sysstat 直接安装。","text":"Linux系统中的 iostat是I/O statistics（输入/输出统计）的缩写，iostat工具将对系统的磁盘操作活动进行监视。它的特点是汇报磁盘活动统计情况，同时也会汇报出CPU使用情况。同vmstat一样，iostat也有一个弱点，就是它不能对某个进程进行深入分析，仅对系统的整体情况进行分析。iostat属于sysstat软件包。可以用yum install sysstat 直接安装。 命令格式$ iostat [参数][时间][次数] 命令功能 通过iostat方便查看CPU、网卡、tty设备、磁盘、CD-ROM 等等设备的活动情况, 负载信息。 命令参数 命令 描述 -C 显示CPU使用情况 -d 显示磁盘使用情况 -k 以 KB 为单位显示 -m 以 M 为单位显示 -N 显示磁盘阵列(LVM) 信息 -n 显示 NFS 使用情况 -p[磁盘] 显示磁盘和分区的情况 -t 显示终端和CPU的信息 -x 显示详细信息 -V 显示版本信息 使用实例例一：显示所有设备负载情况 $ iostat Linux 3.10.0-327.el7.x86_64 (s88) 2017年01月22日 _x86_64_ (24 CPU) avg-cpu: %user %nice %system %iowait %steal %idle 0.62 0.00 0.20 1.46 0.00 97.72 Device: tps kB_read/s kB_wrtn/s kB_read kB_wrtn sda 64.59 1726.21 255.56 3159941 467823 dm-0 3.55 141.11 4.46 258319 8162 dm-1 0.10 0.83 0.00 1520 0 dm-2 0.10 2.78 1.14 5080 2082 dm-3 60.44 1565.98 248.84 2866640 455511 dm-4 27.54 463.29 105.38 848088 192897 dm-5 1.25 25.57 17.57 46804 32170 dm-6 0.64 12.86 2.07 23535 3786 dm-7 4.14 80.43 36.60 147240 67004 dm-8 1.13 20.52 2.42 37566 4428 dm-9 1.13 21.18 2.40 38766 4396 dm-10 1.15 21.35 2.41 39082 4412 dm-11 0.70 14.40 2.21 26355 4043 dm-12 1.42 22.42 6.85 41035 12541 dm-13 0.46 12.17 1.25 22275 2289 dm-14 1.15 20.47 2.42 37470 4432 dm-15 8.28 101.07 16.51 185018 30220 dm-16 1.10 20.02 2.45 36646 4488 dm-17 1.81 29.08 4.15 53232 7591 dm-18 0.68 18.40 1.43 33689 2611 dm-19 2.33 43.89 4.63 80340 8483 说明：cpu属性值说明：%user：CPU处在用户模式下的时间百分比。%nice：CPU处在带NICE值的用户模式下的时间百分比。%system：CPU处在系统模式下的时间百分比。%iowait：CPU等待输入输出完成时间的百分比。%steal：管理程序维护另一个虚拟处理器时，虚拟CPU的无意识等待时间百分比。%idle：CPU空闲时间百分比。备注：如果%iowait的值过高，表示硬盘存在I/O瓶颈，%idle值高，表示CPU较空闲，如果%idle值高但系统响应慢时，有可能是CPU等待分配内存，此时应加大内存容量。%idle值如果持续低于10，那么系统的CPU处理能力相对较低，表明系统中最需要解决的资源是CPU。disk属性值说明：rrqm/s: 每秒进行 merge 的读操作数目。即 rmerge/swrqm/s: 每秒进行 merge 的写操作数目。即 wmerge/sr/s: 每秒完成的读 I/O 设备次数。即 rio/sw/s: 每秒完成的写 I/O 设备次数。即 wio/srsec/s: 每秒读扇区数。即 rsect/swsec/s: 每秒写扇区数。即 wsect/srkB/s: 每秒读K字节数。是 rsect/s 的一半，因为每扇区大小为512字节。wkB/s: 每秒写K字节数。是 wsect/s 的一半。avgrq-sz: 平均每次设备I/O操作的数据大小 (扇区)。avgqu-sz: 平均I/O队列长度。await: 平均每次设备I/O操作的等待时间 (毫秒)。svctm: 平均每次设备I/O操作的服务时间 (毫秒)。%util: 一秒中有百分之多少的时间用于 I/O 操作，即被io消耗的cpu百分比备注：如果 %util 接近 100%，说明产生的I/O请求太多，I/O系统已经满负荷，该磁盘可能存在瓶颈。如果 svctm 比较接近 await，说明 I/O 几乎没有等待时间；如果 await 远大于 svctm，说明I/O 队列太长，io响应太慢，则需要进行必要优化。如果avgqu-sz比较大，也表示有当量io在等待。 例二：定时显示所有信息 # 每隔 2秒刷新显示，且显示3次 $ iostat 2 3 例三：显示指定磁盘信息 $ iostat -d sda1 例四：显示tty和Cpu信息 $ iostat -t 例五：以M为单位显示所有信息 $ iostat -m 例六：查看TPS和吞吐量信息 $ iostat -d -k 1 1 说明：tps：该设备每秒的传输次数（Indicate the number of transfers per second that were issued to the device.）。“一次传输”意思是“一次I/O请求”。多个逻辑请求可能会被合并为“一次I/O请求”。“一次传输”请求的大小是未知的。kB_read/s：每秒从设备（drive expressed）读取的数据量；kB_wrtn/s：每秒向设备（drive expressed）写入的数据量；kB_read：读取的总数据量；kB_wrtn：写入的总数量数据量；这些单位都为Kilobytes。上面的例子中，我们可以看到磁盘sda以及它的各个分区的统计数据，当时统计的磁盘总TPS是22.73，下面是各个分区的TPS。（因为是瞬间值，所以总TPS并不严格等于各个分区TPS的总和） 例七：查看设备使用率（%util）、响应时间（await） $ iostat -d -x -k 1 1 说明：rrqm/s： 每秒进行 merge 的读操作数目.即 delta(rmerge)/swrqm/s： 每秒进行 merge 的写操作数目.即 delta(wmerge)/sr/s： 每秒完成的读 I/O 设备次数.即 delta(rio)/sw/s： 每秒完成的写 I/O 设备次数.即 delta(wio)/srsec/s： 每秒读扇区数.即 delta(rsect)/swsec/s： 每秒写扇区数.即 delta(wsect)/srkB/s： 每秒读K字节数.是 rsect/s 的一半,因为每扇区大小为512字节.(需要计算)wkB/s： 每秒写K字节数.是 wsect/s 的一半.(需要计算)avgrq-sz：平均每次设备I/O操作的数据大小 (扇区).delta(rsect+wsect)/delta(rio+wio)avgqu-sz：平均I/O队列长度.即 delta(aveq)/s/1000 (因为aveq的单位为毫秒).await： 平均每次设备I/O操作的等待时间 (毫秒).即 delta(ruse+wuse)/delta(rio+wio)svctm： 平均每次设备I/O操作的服务时间 (毫秒).即 delta(use)/delta(rio+wio)%util： 一秒中有百分之多少的时间用于 I/O 操作,或者说一秒中有多少时间 I/O 队列是非空的，即 delta(use)/s/1000 (因为use的单位为毫秒) 如果 %util 接近 100%，说明产生的I/O请求太多，I/O系统已经满负荷，该磁盘可能存在瓶颈。 idle小于70% IO压力就较大了，一般读取速度有较多的wait。同时可以结合vmstat 查看查看b参数(等待资源的进程数)和wa参数(IO等待所占用的CPU时间的百分比，高过30%时IO压力高)。 另外 await 的参数也要多和 svctm 来参考。差的过高就一定有 IO 的问题。 avgqu-sz 也是个做 IO 调优时需要注意的地方，这个就是直接每次操作的数据的大小，如果次数多，但数据拿的小的话，其实 IO 也会很小。如果数据拿的大，才IO 的数据会高。也可以通过 avgqu-sz × ( r/s or w/s ) = rsec/s or wsec/s。也就是讲，读定速度是这个来决定的。 svctm 一般要小于 await (因为同时等待的请求的等待时间被重复计算了)，svctm 的大小一般和磁盘性能有关，CPU/内存的负荷也会对其有影响，请求过多也会间接导致 svctm 的增加。await 的大小一般取决于服务时间(svctm) 以及 I/O 队列的长度和 I/O 请求的发出模式。如果 svctm 比较接近 await，说明 I/O 几乎没有等待时间；如果 await 远大于 svctm，说明 I/O 队列太长，应用得到的响应时间变慢，如果响应时间超过了用户可以容许的范围，这时可以考虑更换更快的磁盘，调整内核 elevator 算法，优化应用，或者升级 CPU。 队列长度(avgqu-sz)也可作为衡量系统 I/O 负荷的指标，但由于 avgqu-sz 是按照单位时间的平均值，所以不能反映瞬间的 I/O 洪水。形象的比喻：r/s+w/s 类似于交款人的总数平均队列长度(avgqu-sz)类似于单位时间里平均排队人的个数平均服务时间(svctm)类似于收银员的收款速度平均等待时间(await)类似于平均每人的等待时间平均I/O数据(avgrq-sz)类似于平均每人所买的东西多少I/O 操作率 (%util)类似于收款台前有人排队的时间比例 设备IO操作:总IO(io)/s = r/s(读) +w/s(写) =1.46 + 25.28=26.74 平均每次设备I/O操作只需要0.36毫秒完成,现在却需要10.57毫秒完成，因为发出的 请求太多(每秒26.74个)，假如请求时同时发出的，可以这样计算平均等待时间: 平均等待时间=单个I/O服务器时间*(1+2+…+请求总数-1)/请求总数 每秒发出的I/0请求很多,但是平均队列就4,表示这些请求比较均匀,大部分处理还是比较及时。 例八：查看cpu状态 $ iostat -c 1 3","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"https://jiangxingye.github.io/tags/linux命令/"}]},{"title":"每天一个linux命令（34）: vmstat","slug":"linux-command（34）-vmstat","date":"2017-01-03T01:46:57.000Z","updated":"2019-09-02T13:03:00.015Z","comments":true,"path":"2017/01/03/linux-command（34）-vmstat/","link":"","permalink":"https://jiangxingye.github.io/2017/01/03/linux-command（34）-vmstat/","excerpt":"vmstat是Virtual Meomory Statistics（虚拟内存统计）的缩写，可对操作系统的虚拟内存、进程、CPU活动进行监控。他是对系统的整体情况进行统计，不足之处是无法对某个进程进行深入分析。vmstat 工具提供了一种低开销的系统性能观察方式。因为 vmstat 本身就是低开销工具，在非常高负荷的服务器上，你需要查看并监控系统的健康情况,在控制窗口还是能够使用vmstat 输出结果。在学习vmstat命令前，我们先了解一下Linux系统中关于物理内存和虚拟内存相关信息。","text":"vmstat是Virtual Meomory Statistics（虚拟内存统计）的缩写，可对操作系统的虚拟内存、进程、CPU活动进行监控。他是对系统的整体情况进行统计，不足之处是无法对某个进程进行深入分析。vmstat 工具提供了一种低开销的系统性能观察方式。因为 vmstat 本身就是低开销工具，在非常高负荷的服务器上，你需要查看并监控系统的健康情况,在控制窗口还是能够使用vmstat 输出结果。在学习vmstat命令前，我们先了解一下Linux系统中关于物理内存和虚拟内存相关信息。 物理内存和虚拟内存区别 我们知道，直接从物理内存读写数据要比从硬盘读写数据要快的多，因此，我们希望所有数据的读取和写入都在内存完成，而内存是有限的，这样就引出了物理内存与虚拟内存的概念。 物理内存就是系统硬件提供的内存大小，是真正的内存，相对于物理内存，在linux下还有一个虚拟内存的概念，虚拟内存就是为了满足物理内存的不足而提出的策略，它是利用磁盘空间虚拟出的一块逻辑内存，用作虚拟内存的磁盘空间被称为交换空间（Swap Space）。 作为物理内存的扩展，linux会在物理内存不足时，使用交换分区的虚拟内存，更详细的说，就是内核会将暂时不用的内存块信息写到交换空间，这样以来，物理内存得到了释放，这块内存就可以用于其它目的，当需要用到原始的内容时，这些信息会被重新从交换空间读入物理内存。 linux的内存管理采取的是分页存取机制，为了保证物理内存能得到充分的利用，内核会在适当的时候将物理内存中不经常使用的数据块自动交换到虚拟内存中，而将经常使用的信息保留到物理内存。 要深入了解linux内存运行机制，需要知道下面提到的几个方面： 首先，Linux系统会不时的进行页面交换操作，以保持尽可能多的空闲物理内存，即使并没有什么事情需要内存，Linux也会交换出暂时不用的内存页面。这可以避免等待交换所需的时间。 其次，linux进行页面交换是有条件的，不是所有页面在不用时都交换到虚拟内存，linux内核根据”最近最经常使用“算法，仅仅将一些不经常使用的页面文件交换到虚拟内存，有时我们会看到这么一个现象：linux物理内存还有很多，但是交换空间也使用了很多。其实，这并不奇怪，例如，一个占用很大内存的进程运行时，需要耗费很多内存资源，此时就会有一些不常用页面文件被交换到虚拟内存中，但后来这个占用很多内存资源的进程结束并释放了很多内存时，刚才被交换出去的页面文件并不会自动的交换进物理内存，除非有这个必要，那么此刻系统物理内存就会空闲很多，同时交换空间也在被使用，就出现了刚才所说的现象了。关于这点，不用担心什么，只要知道是怎么一回事就可以了。 最后，交换空间的页面在使用时会首先被交换到物理内存，如果此时没有足够的物理内存来容纳这些页面，它们又会被马上交换出去，如此以来，虚拟内存中可能没有足够空间来存储这些交换页面，最终会导致linux出现假死机、服务异常等问题，linux虽然可以在一段时间内自行恢复，但是恢复后的系统已经基本不可用了。 因此，合理规划和设计linux内存的使用，是非常重要的。 虚拟内存原理： 在系统中运行的每个进程都需要使用到内存，但不是每个进程都需要每时每刻使用系统分配的内存空间。当系统运行所需内存超过实际的物理内存，内核会释放某些进程所占用但未使用的部分或所有物理内存，将这部分资料存储在磁盘上直到进程下一次调用，并将释放出的内存提供给有需要的进程使用。 在Linux内存管理中，主要是通过“调页Paging”和“交换Swapping”来完成上述的内存调度。调页算法是将内存中最近不常使用的页面换到磁盘上，把活动页面保留在内存中供进程使用。交换技术是将整个进程，而不是部分页面，全部交换到磁盘上。 分页(Page)写入磁盘的过程被称作Page-Out，分页(Page)从磁盘重新回到内存的过程被称作Page-In。当内核需要一个分页时，但发现此分页不在物理内存中(因为已经被Page-Out了)，此时就发生了分页错误（Page Fault）。 当系统内核发现可运行内存变少时，就会通过Page-Out来释放一部分物理内存。经管Page-Out不是经常发生，但是如果Page-out频繁不断的发生，直到当内核管理分页的时间超过运行程式的时间时，系统效能会急剧下降。这时的系统已经运行非常慢或进入暂停状态，这种状态亦被称作thrashing(颠簸)。 命令格式$ vmstat [-a] [-n] [-S unit] [delay [ count]] $ vmstat [-s] [-n] [-S unit] $ vmstat [-m] [-n] [delay [ count]] $ vmstat [-d] [-n] [delay [ count]] $ vmstat [-p disk partition] [-n] [delay [ count]] $ vmstat [-f] $ vmstat [-V] 命令功能 用来显示虚拟内存的信息 命令参数 命令 描述 -a 显示活跃和非活跃内存 -f 显示从系统启动至今的fork数量 -m 显示slabinfo -n 只在开始时显示一次各字段名称 -s 显示内存相关统计信息及多种系统活动数量 delay 刷新时间间隔。如果不指定，只显示一条结果 count 刷新次数。如果不指定刷新次数，但指定了刷新时间间隔，这时刷新次数为无穷 -d 显示磁盘相关统计信息 -p 显示指定磁盘分区统计信息 -S 使用指定单位显示。参数有 k 、K 、m 、M ，分别代表1000、1024、1000000、1048576字节（byte）。默认单位为K（1024 bytes） -V 显示vmstat版本信息 使用实例例一：显示虚拟内存使用情况 $ vmstat procs -----------memory---------- ---swap-- -----io--- --system--- -----cpu--- r b swpd free buff cache si so bi bo in cs us sy id wa st 0 0 0 7108340 129544 3155916 0 0 184 53 203 995 4 1 95 0 0 说明：Procs（进程）：r: 运行队列中进程数量b: 等待IO的进程数量Memory（内存）：swpd: 使用虚拟内存大小free: 可用内存大小buff: 用作缓冲的内存大小cache: 用作缓存的内存大小Swap：si: 每秒从交换区写到内存的大小so: 每秒写入交换区的内存大小IO：（现在的Linux版本块的大小为1024bytes）bi: 每秒读取的块数bo: 每秒写入的块数系统：in: 每秒中断数，包括时钟中断。cs: 每秒上下文切换数。CPU（以百分比表示）：us: 用户进程执行时间(user time)sy: 系统进程执行时间(system time)id: 空闲时间(包括IO等待时间),中央处理器的空闲时间 。以百分比表示。wa: 等待IO时间备注： 如果 r经常大于 4 ，且id经常少于40，表示cpu的负荷很重。如果pi，po 长期不等于0，表示内存不足。如果disk 经常不等于0， 且在 b中的队列 大于3， 表示 io性能不好。Linux在具有高稳定性、可靠性的同时，具有很好的可伸缩性和扩展性，能够针对不同的应用和硬件环境调整，优化出满足当前应用需要的最佳性能。因此企业在维护Linux系统、进行系统调优时，了解系统性能分析工具是至关重要的。命令：vmstat 5 5表示在5秒时间内进行5次采样。将得到一个数据汇总他能够反映真正的系统情况。 例二：显示活跃和非活跃内存 $ vmstat -a 2 5 说明：使用-a选项显示活跃和非活跃内存时，所显示的内容除增加inact和active外，其他显示内容与例子1相同。Memory（内存）：inact: 非活跃内存大小（当使用-a选项时显示）active: 活跃的内存大小（当使用-a选项时显示） 例三：查看系统已经fork了多少次 $ vmstat -f 说明：这个数据是从/proc/stat中的processes字段里取得的 例四：查看内存使用的详细信息 $ vmstat -s 说明：这些信息的分别来自于/proc/meminfo,/proc/stat和/proc/vmstat。 例五：查看磁盘的读/写 $ vmstat -d 说明：这些信息主要来自于/proc/diskstats.merged:表示一次来自于合并的写/读请求,一般系统会把多个连接/邻近的读/写请求合并到一起来操作. 例六：查看/dev/sda1磁盘的读/写 $ vmstat -p /dev/sda1 说明：这些信息主要来自于/proc/diskstats。reads:来自于这个分区的读的次数。read sectors:来自于这个分区的读扇区的次数。writes:来自于这个分区的写的次数。requested writes:来自于这个分区的写请求次数。 例七：查看系统的slab信息 $ vmstat -m 说明：这组信息来自于/proc/slabinfo。slab:由于内核会有许多小对象，这些对象构造销毁十分频繁，比如i-node，dentry，这些对象如果每次构建的时候就向内存要一个页(4kb)，而其实只有几个字节，这样就会非常浪费，为了解决这个问题，就引入了一种新的机制来处理在同一个页框中如何分配小存储区，而slab可以对小对象进行分配,这样就不用为每一个对象分配页框，从而节省了空间，内核对一些小对象创建析构很频繁，slab对这些小对象进行缓冲,可以重复利用,减少内存分配次数。","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"https://jiangxingye.github.io/tags/linux命令/"}]},{"title":"每天一个linux命令（33）: free","slug":"linux-command（33）-free","date":"2017-01-02T13:43:26.000Z","updated":"2019-09-02T13:03:00.015Z","comments":true,"path":"2017/01/02/linux-command（33）-free/","link":"","permalink":"https://jiangxingye.github.io/2017/01/02/linux-command（33）-free/","excerpt":"free命令可以显示Linux系统中空闲的、已用的物理内存及swap内存,及被内核使用的buffer。在Linux系统监控的工具中，free命令是最经常使用的命令之一。","text":"free命令可以显示Linux系统中空闲的、已用的物理内存及swap内存,及被内核使用的buffer。在Linux系统监控的工具中，free命令是最经常使用的命令之一。 命令格式$ free [参数] 命令功能 free 命令显示系统使用和空闲的内存情况，包括物理内存、交互区内存(swap)和内核缓冲区内存。共享内存将被忽略 命令参数 命令 描述 -b 以Byte为单位显示内存使用情况 -k 以KB为单位显示内存使用情况 -m 以MB为单位显示内存使用情况 -g 以GB为单位显示内存使用情况 -o 不显示缓冲区调节列 -s&lt;间隔秒数&gt; 持续观察内存使用状况 -t 显示内存总和列 -V 显示版本信息 使用实例例一：显示内存使用情况 $ free total used free shared buff/cache available Mem: 12095180 8362640 198460 1379116 3534080 2100004 Swap: 8185112 40008 8145104 说明：total:总计物理内存的大小。used:已使用多大。free:可用有多少。Shared:多个进程共享的内存总额。Buffers/cached:磁盘缓存的大小。 例二：显示内存使用情况 $ free -t 例三：周期性的查询内存使用信息 # 每10s 执行一次命令 $ free -s 10","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"https://jiangxingye.github.io/tags/linux命令/"}]},{"title":"每天一个linux命令（32）: top","slug":"linux-command（32）-top","date":"2017-01-01T11:31:28.000Z","updated":"2019-09-02T13:03:00.013Z","comments":true,"path":"2017/01/01/linux-command（32）-top/","link":"","permalink":"https://jiangxingye.github.io/2017/01/01/linux-command（32）-top/","excerpt":"top命令是Linux下常用的性能分析工具，能够实时显示系统中各个进程的资源占用状况，类似于Windows的任务管理器。下面详细介绍它的使用方法。top是一个动态显示过程,即可以通过用户按键来不断刷新当前状态.如果在前台执行该命令,它将独占前台,直到用户终止该程序为止.比较准确的说,top命令提供了实时的对系统处理器的状态监视.它将显示系统中CPU最“敏感”的任务列表.该命令可以按CPU使用.内存使用和执行时间对任务进行排序；而且该命令的很多特性都可以通过交互式命令或者在个人定制文件中进行设定。","text":"top命令是Linux下常用的性能分析工具，能够实时显示系统中各个进程的资源占用状况，类似于Windows的任务管理器。下面详细介绍它的使用方法。top是一个动态显示过程,即可以通过用户按键来不断刷新当前状态.如果在前台执行该命令,它将独占前台,直到用户终止该程序为止.比较准确的说,top命令提供了实时的对系统处理器的状态监视.它将显示系统中CPU最“敏感”的任务列表.该命令可以按CPU使用.内存使用和执行时间对任务进行排序；而且该命令的很多特性都可以通过交互式命令或者在个人定制文件中进行设定。 命令格式$ top [参数] 命令功能 显示当前系统正在执行的进程的相关信息，包括进程ID、内存占用率、CPU占用率等 命令参数 参数 描述 -b 批处理 -c 显示完整的治命令 -I 忽略失效过程 -s 保密模式 -S 累积模式 -i&lt;时间&gt; 设置间隔时间 -u&lt;用户名&gt; 指定用户名 -p&lt;进程号&gt; 指定进程 -n&lt;次数&gt; 循环显示的次数 top交互命令 在top 命令执行过程中可以使用的一些交互命令。这些命令都是单字母的，如果在命令行中使用了s 选项， 其中一些命令可能会被屏蔽。 参数 描述 h 显示帮助画面，给出一些简短的命令总结说明 k 终止一个进程。 i 忽略闲置和僵死进程。这是一个开关式命令 q 退出程序 r 重新安排一个进程的优先级别 S 切换到累计模式 s 改变两次刷新之间的延迟时间（单位为s），如果有小数，就换算成m s。输入0值则系统将不断刷新，默认值是5 s f或者F 从当前显示中添加或者删除项目 o或者O 改变显示项目的顺序 l 切换显示平均负载和启动时间信息 m 切换显示内存信息 t 切换显示进程和CPU状态信息 c 切换显示命令名称和完整命令行 M 根据驻留内存大小进行排序 P 根据CPU使用百分比大小进行排序 T 根据时间/累计时间进行排序 W 将当前设置写入~/.toprc文件中 使用实例例一：显示进程信息 $ top top讲解其他技巧 数字1，可监控每个逻辑CPU的状况 键盘b（打开/关闭加亮效果），运行状态的进程 键盘x 打开/关闭排序列的加亮效果 shift + &gt;或shift + &lt;改变排序列 例二：显示 完整命令 $ top -c 例三：以批处理模式显示程序信息 $ top -b 例四：以累积模式显示程序信息 $ top -S 例五：设置信息更新次数 # 表示更新两次后终止更新显示 $ top -n 2 例六：设置信息更新时间 # 表示更新周期为3秒 $ top -d 3 例七：显示指定的进程信息 $ top -p 574","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"https://jiangxingye.github.io/tags/linux命令/"}]},{"title":"每天一个linux命令（31）: du","slug":"linux-command（31）-du","date":"2016-12-31T06:36:01.000Z","updated":"2019-09-02T13:03:00.012Z","comments":true,"path":"2016/12/31/linux-command（31）-du/","link":"","permalink":"https://jiangxingye.github.io/2016/12/31/linux-command（31）-du/","excerpt":"Linux du命令也是查看使用空间的，但是与df命令不同的是Linux du命令是对文件和目录磁盘使用的空间的查看，还是和df命令有一些区别的.","text":"Linux du命令也是查看使用空间的，但是与df命令不同的是Linux du命令是对文件和目录磁盘使用的空间的查看，还是和df命令有一些区别的. 命令格式$ du [选项][文件] 命令功能 显示每个文件和目录的磁盘使用空间。 命令参数 参数 描述 -a或-all 显示目录中个别文件的大小。 -b或-bytes 显示目录或文件大小时，以byte为单位。 -c或–total 除了显示个别目录或文件的大小外，同时也显示所有目录或文件的总和。 -k或–kilobytes 以KB(1024bytes)为单位输出。 -m或–megabytes 以MB为单位输出。 -s或–summarize 仅显示总计，只列出最后加总的值。 -h或–human-readable 以K，M，G为单位，提高信息的可读性。 -x或–one-file-xystem 以一开始处理时的文件系统为准，若遇上其它不同的文件系统目录则略过。 -L&lt;符号链接&gt;或–dereference&lt;符号链接&gt; 显示选项中所指定符号链接的源文件大小。 -S或–separate-dirs 显示个别目录的大小时，并不含其子目录的大小。 -X&lt;文件&gt;或–exclude-from=&lt;文件&gt; 在&lt;文件&gt;指定目录或文件。 –exclude=&lt;目录或文件&gt; 略过指定的目录或文件。 -D或–dereference-args 显示指定符号链接的源文件大小。 -H或–si 与-h参数相同，但是K，M，G是以1000为换算单位。 -l或–count-links 重复计算硬件链接的文件。 使用实例例一：显示目录或者文件所占空间 $ du 说明： 只显示当前目录下面的子目录的目录大小和当前目录的总的大小，最下面的1288为当前目录的总大小 例二：显示指定文件所占空间 $ du log2012.log 例三：查看指定目录的所占空间 $ du scf 例四：显示多个文件所占空间 $ du log30.tar.gz log31.tar.gz 例五：只显示总和的大小 $ du -s 例六：方便阅读的格式显示 $ du -h test 例七：文件和目录都显示 $ du -ah test 例八：显示几个文件或目录各自占用磁盘空间的大小，还统计它们的总和 $ du -c log30.tar.gz log31.tar.gz 说明： 加上-c选项后，du不仅显示两个目录各自占用磁盘空间的大小，还在最后一行统计它们的总和。 例九：按照空间大小排序 $ du|sort -nr|more 例十：输出当前目录下各个子目录所使用的空间 $ du -h --max-depth=1","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"https://jiangxingye.github.io/tags/linux命令/"}]},{"title":"每天一个linux命令（30）: df","slug":"linux-command（30）-df","date":"2016-12-30T06:23:31.000Z","updated":"2019-09-02T13:03:00.012Z","comments":true,"path":"2016/12/30/linux-command（30）-df/","link":"","permalink":"https://jiangxingye.github.io/2016/12/30/linux-command（30）-df/","excerpt":"linux中df命令的功能是用来检查linux服务器的文件系统的磁盘空间占用情况。可以利用该命令来获取硬盘被占用了多少空间，目前还剩下多少空间等信息。","text":"linux中df命令的功能是用来检查linux服务器的文件系统的磁盘空间占用情况。可以利用该命令来获取硬盘被占用了多少空间，目前还剩下多少空间等信息。 命令格式$ df [选项] [文件] 命令功能 显示指定磁盘文件的可用空间。如果没有文件名被指定，则所有当前被挂载的文件系统的可用空间将被显示。默认情况下，磁盘空间将以 1KB 为单位进行显示，除非环境变量 POSIXLY_CORRECT 被指定，那样将以512字节为单位进行显示 命令参数必要参数 参数 描述 -a 全部文件系统列表 -h 方便阅读方式显示 -H 等于“-h”，但是计算式，1K=1000，而不是1K=1024 -i 显示inode信息 -k 区块为1024字节 -l 只显示本地文件系统 -m 区块为1048576字节 –no-sync 忽略 sync 命令 -P 输出格式为POSIX –sync 在取得磁盘信息前，先执行sync命令 -T 文件系统类型 选择参数 参数 描述 –block-size=&lt;区块大小&gt; 指定区块大小 -t&lt;文件系统类型&gt; 只显示选定文件系统的磁盘信息 -x&lt;文件系统类型&gt; 不显示选定文件系统的磁盘信息 –help 显示帮助信息 –version 显示版本信息 使用实例例一：显示磁盘使用情况 $ df 说明： linux中df命令的输出清单的第1列是代表文件系统对应的设备文件的路径名（一般是硬盘上的分区）；第2列给出分区包含的数据块（1024字节）的数目；第3，4列分别表示已用的和可用的数据块数目。用户也许会感到奇怪的是，第3，4列块数之和不等于第2列中的块数。这是因为缺省的每个分区都留了少量空间供系统管理员使用。即使遇到普通用户空间已满的情况，管理员仍能登录和留有解决问题所需的工作空间。清单中Use% 列表示普通用户空间使用的百分比，即使这一数字达到100％，分区仍然留有系统管理员使用的空间。最后，Mounted on列表示文件系统的挂载点。 例二：以inode模式来显示磁盘使用情况 $ df -i 例三：显示指定类型磁盘 $ df -t ext3 例四：列出各文件系统的i节点使用情况 $ df -ia 例五：列出文件系统的类型 $ df -T 例六：以更易读的方式显示目前磁盘空间和使用情况 $ df -h 说明：-h更具目前磁盘空间和使用情况 以更易读的方式显示-H根上面的-h参数相同,不过在根式化的时候,采用1000而不是1024进行容量转换-k以单位显示磁盘的使用情况-l显示本地的分区的磁盘空间使用率,如果服务器nfs了远程服务器的磁盘,那么在df上加上-l后系统显示的是过滤nsf驱动器后的结果-i显示inode的使用情况。linux采用了类似指针的方式管理磁盘空间影射.这也是一个比较关键应用","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"https://jiangxingye.github.io/tags/linux命令/"}]},{"title":"每天一个linux命令（29）: /etc/group文件详解","slug":"linux-command（29）-/etc/group文件详解","date":"2016-12-29T06:13:05.000Z","updated":"2019-09-02T13:03:00.010Z","comments":true,"path":"2016/12/29/linux-command（29）-/etc/group文件详解/","link":"","permalink":"https://jiangxingye.github.io/2016/12/29/linux-command（29）-/etc/group文件详解/","excerpt":"Linux /etc/group文件与/etc/passwd和/etc/shadow文件都是有关于系统管理员对用户和用户组管理时相关的文件。linux /etc/group文件是有关于系统管理员对用户和用户组管理的文件,linux用户组的所有信息都存放在/etc/group文件中。具有某种共同特征的用户集合起来就是用户组（Group）。用户组（Group）配置文件主要有 /etc/group和/etc/gshadow，其中/etc/gshadow是/etc/group的加密信息文件。","text":"Linux /etc/group文件与/etc/passwd和/etc/shadow文件都是有关于系统管理员对用户和用户组管理时相关的文件。linux /etc/group文件是有关于系统管理员对用户和用户组管理的文件,linux用户组的所有信息都存放在/etc/group文件中。具有某种共同特征的用户集合起来就是用户组（Group）。用户组（Group）配置文件主要有 /etc/group和/etc/gshadow，其中/etc/gshadow是/etc/group的加密信息文件。 将用户分组是Linux系统中对用户进行管理及控制访问权限的一种手段。每个用户都属于某个用户组；一个组中可以有多个用户，一个用户也可以属于不 同的组。当一个用户同时是多个组中的成员时，在/etc/passwd文件中记录的是用户所属的主组，也就是登录时所属的默认组，而其他组称为附加组。 用户组的所有信息都存放在/etc/group文件中。此文件的格式是由冒号(:)隔开若干个字段，这些字段具体如下： 组名:口令:组标识号:组内用户列表 解释组名： 组名是用户组的名称，由字母或数字构成。与/etc/passwd中的登录名一样，组名不应重复。口令： 口令字段存放的是用户组加密后的口令字。一般Linux系统的用户组都没有口令，即这个字段一般为空，或者是*。组标识号： 组标识号与用户标识号类似，也是一个整数，被系统内部用来标识组。别称GID.组内用户列表： 是属于这个组的所有用户的列表，不同用户之间用逗号(,)分隔。这个用户组可能是用户的主组，也可能是附加组。 使用实例$ cat /etc/group 说明： 我们以root:x:0:root,linuxsir 为例： 用户组root，x是密码段，表示没有设置密码，GID是0,root用户组下包括root、linuxsir以及GID为0的其它用户。","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"https://jiangxingye.github.io/tags/linux命令/"}]},{"title":"每天一个linux命令（28）: chown","slug":"linux-command（28）-chown","date":"2016-12-28T01:51:30.000Z","updated":"2019-09-02T13:03:00.010Z","comments":true,"path":"2016/12/28/linux-command（28）-chown/","link":"","permalink":"https://jiangxingye.github.io/2016/12/28/linux-command（28）-chown/","excerpt":"chown将指定文件的拥有者改为指定的用户或组，用户可以是用户名或者用户ID；组可以是组名或者组ID；文件是以空格分开的要改变权限的文件列表，支持通配符。系统管理员经常使用chown命令，在将文件拷贝到另一个用户的名录下之后，让用户拥有使用该文件的权限。","text":"chown将指定文件的拥有者改为指定的用户或组，用户可以是用户名或者用户ID；组可以是组名或者组ID；文件是以空格分开的要改变权限的文件列表，支持通配符。系统管理员经常使用chown命令，在将文件拷贝到另一个用户的名录下之后，让用户拥有使用该文件的权限。 命令格式$ chown [选项]... [所有者][:[组]] 文件... 命令功能 通过chown改变文件的拥有者和群组。在更改文件的所有者或所属群组时，可以使用用户名称和用户识别码设置。普通用户不能将自己的文件改变成其他的拥有者。其操作权限一般为管理员。 命令参数必要参数 参数 描述 -c 显示更改的部分的信息 -f 忽略错误信息 -h 修复符号链接 -R 处理指定目录以及其子目录下的所有文件 -v 显示详细的处理信息 -deference 作用于符号链接的指向，而不是链接文件本身 选择参数 参数 描述 –reference=&lt;目录或文件&gt; 把指定的目录/文件作为参考，把操作的文件/目录设置成参考文件/目录相同拥有者和群组 –from=&lt;当前用户：当前群组&gt; 只有当前用户和群组跟指定的用户和群组相同时才进行改变 –help 显示帮助信息 –version 显示版本信息 命令实例例一：改变拥有者和群组 $ chown mail:mail log2012.log 例二：改变文件拥有者和群组 # 组可为空，默认为root所在组 $ chown root: log2012.log 例三：改变文件群组 # 只改变所在组 $ chown :mail log2012.log 例四：改变指定目录以及其子目录下的所有文件的拥有者和群组 $ chown -R -v root:mail test6","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"https://jiangxingye.github.io/tags/linux命令/"}]},{"title":"每天一个linux命令（27）: chgrp","slug":"linux-command（27）-chgrp","date":"2016-12-27T01:40:06.000Z","updated":"2019-09-02T13:03:00.010Z","comments":true,"path":"2016/12/27/linux-command（27）-chgrp/","link":"","permalink":"https://jiangxingye.github.io/2016/12/27/linux-command（27）-chgrp/","excerpt":"在lunix系统里，文件或目录的权限的掌控以拥有者及所诉群组来管理。可以使用chgrp指令取变更文件与目录所属群组，这种方式采用群组名称或群组识别码都可以。Chgrp命令就是change group的缩写！要被改变的组名必须要在/etc/group文件内存在才行。","text":"在lunix系统里，文件或目录的权限的掌控以拥有者及所诉群组来管理。可以使用chgrp指令取变更文件与目录所属群组，这种方式采用群组名称或群组识别码都可以。Chgrp命令就是change group的缩写！要被改变的组名必须要在/etc/group文件内存在才行。 命令格式$ chgrp [选项] [组] [文件] 命令功能 chgrp命令可采用群组名称或群组识别码的方式改变文件或目录的所属群组。使用权限是超级用户。 命令参数必要参数 参数 描述 -c 当发生改变时，报告处理信息 -f 不显示错误信息 -R 处理指定目录以及其子目录下的所有文件 -v 运行时显示详细的处理信息 –dereference 作用于符号链接的指向，而不是符号链接本身 –no-dereference 作用于符号链接本身 选择参数 参数 描述 –reference=&lt;文件或者目录&gt; 设置为和指定的文件或目录的权限一样 –help 显示帮助信息 –version 显示版本信息 命令实例例一：改变文件的群组属性 # 将log2012.log文件由root群组改为bin群组 $ chgrp -v bin log2012.log “log2012.log” 的所属组已更改为 bin 例二：根据指定文件改变文件的群组属性 # 改变文件log2013.log 的群组属性，使得文件log2013.log的群组属性和参考文件log2012.log的群组属性相同 $ chgrp --reference=log2012.log log2013.log 例三：改变指定目录以及其子目录下的所有文件的群组属性 # 改变指定目录以及其子目录下的所有文件的群组属性 $ chgrp -R bin test6 例四：通过群组识别码改变文件群组属性 # 通过群组识别码改变文件群组属性，100为users群组的识别码，具体群组和群组识别码可以去/etc/group文件中查看 $ chgrp -R 100 test6","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"https://jiangxingye.github.io/tags/linux命令/"}]},{"title":"每天一个linux命令（26）: chmod","slug":"linux-command（26）-chmod","date":"2016-12-26T12:22:43.000Z","updated":"2019-09-02T13:03:00.009Z","comments":true,"path":"2016/12/26/linux-command（26）-chmod/","link":"","permalink":"https://jiangxingye.github.io/2016/12/26/linux-command（26）-chmod/","excerpt":"chmod命令用于改变linux系统文件或目录的访问权限。用它控制文件或目录的访问权限。该命令有两种用法。一种是包含字母和操作符表达式的文字设定法；另一种是包含数字的数字设定法。","text":"chmod命令用于改变linux系统文件或目录的访问权限。用它控制文件或目录的访问权限。该命令有两种用法。一种是包含字母和操作符表达式的文字设定法；另一种是包含数字的数字设定法。 Linux系统中的每个文件和目录都有访问许可权限，用它来确定谁可以通过何种方式对文件和目录进行访问和操作。 文件或目录的访问权限分为只读，只写和可执行三种。以文件为例，只读权限表示只允许读其内容，而禁止对其做任何的更改操作。可执行权限表示允许将该文件作为一个程序执行。文件被创建时，文件所有者自动拥有对该文件的读、写和可执行权限，以便于对文件的阅读和修改。用户也可根据需要把访问权限设置为需要的任何组合。 有三种不同类型的用户可对文件或目录进行访问：文件所有者，同组用户、其他用户。所有者一般是文件的创建者。所有者可以允许同组用户有权访问文件，还可以将文件的访问权限赋予系统中的其他用户。在这种情况下，系统中每一位用户都能访问该用户拥有的文件或目录。 每一文件或目录的访问权限都有三组，每组用三位表示，分别为文件属主的读、写和执行权限；与属主同组的用户的读、写和执行权限；系统中其他用户的读、写和执行权限。当用ls -l命令显示文件或目录的详细信息时，最左边的一列为文件的访问权限。 例如： $ ls -al -rw-r--r-- 1 root root 296K 11-13 06:03 log2012.log 第一列共有10个位置，第一个字符指定了文件类型。在通常意义上，一个目录也是一个文件。如果第一个字符是横线，表示是一个非目录的文件。如果是d，表示是一个目录。从第二个字符开始到第十个共9个字符，3个字符一组，分别表示了3组用户对文件或者目录的权限。权限字符用横线代表空许可，r代表只读，w代表写，x代表可执行。 - rw- r-- r-- 表示log2012.log是一个普通文件；log2012.log的属主有读写权限；与log2012.log属主同组的用户只有读权限；其他用户也只有读权限。 确定了一个文件的访问权限后，用户可以利用Linux系统提供的chmod命令来重新设定不同的访问权限。也可以利用chown命令来更改某个文件或目录的所有者。利用chgrp命令来更改某个文件或目录的用户组。 chmod命令是非常重要的，用于改变文件或目录的访问权限。用户用它控制文件或目录的访问权限。chmod命令详细情况如下。 命令格式$ chmod [-cfvR] [--help] [--version] mode file 命令功能用于改变文件或目录的访问权限，用它控制文件或目录的访问权限。 命令参数必要参数 参数 描述 -c 当发生改变时，报告处理信息 -f 错误信息不输出 -R 处理指定目录以及其子目录下的所有文件 -v 运行时显示详细处理信息 选择参数 参数 描述 –reference=&lt;目录或者文件&gt; 设置成具有指定目录或者文件具有相同的权限 –version 显示版本信息 &lt;权限范围&gt;+&lt;权限设置&gt; 使权限范围内的目录或者文件具有指定的权限 &lt;权限范围&gt;-&lt;权限设置&gt; 删除权限范围的目录或者文件的指定权限 &lt;权限范围&gt;=&lt;权限设置&gt; 设置权限范围内的目录或者文件的权限为指定的值 权限范围 参数 描述 u 目录或者文件的当前的用户 g 目录或者文件的当前的群组 o 除了目录或者文件的当前用户或群组之外的用户或者群组 a 所有的用户及群组 权限代号 参数 描述 r 读权限，用数字4表示 w 写权限，用数字2表示 x 执行权限，用数字1表示 - 删除权限，用数字0表示 s 特殊权限》该命令有两种用法。一种是包含字母和操作符表达式的文字设定法；另一种是包含数字的数字设定法。 文字设定法 $ chmod ［who］ ［+ | - | =］ ［mode］ 文件名 数字设定法 我们必须首先了解用数字表示的属性的含义：0表示没有权限，1表示可执行权限，2表示可写权限，4表示可读权限，然后将其相加。所以数字属性的格式应为3个从0到7的八进制数，其顺序是（u）（g）（o）。 例如，如果想让某个文件的属主有“读/写”二种权限，需要把4（可读）+2（可写）＝6（读/写）。 数字设定法的一般形式为： chmod ［mode］ 文件名数字与字符对应关系如下：r=4，w=2，x=1若要rwx属性则4+2+1=7若要rw-属性则4+2=6；若要r-x属性则4+1=7。 命令实例例一：增加文件所有用户组可执行权限 $ chmod a+x log2012.log 例二：同时修改不同用户权限 $ chmod ug+w,o-x log2012.log 例三：删除文件权限 $ chmod a-x log2012.log 例四：使用“=”设置权限 $ chmod u=x log2012.log 例五：其他 # 给file的属主分配读、写、执行(7)的权限，给file的所在组分配读、执行(5)的权限，给其他用户分配执行(1)的权限 $ chmod 751 file # 上例的另一种形式 $ chmod u=rwx,g=rx,o=x file # 为所有用户分配读权限 $ chmod =r file # 同上例 $ chmod 444 file # 同上例 $ chmod a-wx,a+r file","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"https://jiangxingye.github.io/tags/linux命令/"}]},{"title":"每天一个linux命令（25）: gzip","slug":"linux-command（25）-gzip","date":"2016-12-25T08:55:15.000Z","updated":"2019-09-02T13:03:00.009Z","comments":true,"path":"2016/12/25/linux-command（25）-gzip/","link":"","permalink":"https://jiangxingye.github.io/2016/12/25/linux-command（25）-gzip/","excerpt":"减少文件大小有两个明显的好处，一是可以减少存储空间，二是通过网络传输文件时，可以减少传输的时间。gzip是在Linux系统中经常使用的一个对文件进行压缩和解压缩的命令，既方便又好用。gzip不仅可以用来压缩大的、较少使用的文件以节省磁盘空间，还可以和tar命令一起构成Linux操作系统中比较流行的压缩文件格式。据统计，gzip命令对文本文件有60%～70%的压缩率。","text":"减少文件大小有两个明显的好处，一是可以减少存储空间，二是通过网络传输文件时，可以减少传输的时间。gzip是在Linux系统中经常使用的一个对文件进行压缩和解压缩的命令，既方便又好用。gzip不仅可以用来压缩大的、较少使用的文件以节省磁盘空间，还可以和tar命令一起构成Linux操作系统中比较流行的压缩文件格式。据统计，gzip命令对文本文件有60%～70%的压缩率。 命令格式$ gzip [参数] [文件或者目录] 命令功能 gzip是个使用广泛的压缩程序，文件经它压缩过后，其名称后面会多出”.gz”的扩展名。 命令参数 参数 描述 -a或–ascii 使用ASCII文字模式。 -c或–stdout或–to-stdout 把压缩后的文件输出到标准输出设备，不去更动原始文件。 -d或–decompress或—-uncompress 解开压缩文件。 -f或–force 强行压缩文件。不理会文件名称或硬连接是否存在以及该文件是否为符号连接。 -h或–help 在线帮助。 -l或–list 列出压缩文件的相关信息。 -L或–license 显示版本与版权信息。 -n或–no-name 压缩文件时，不保存原来的文件名称及时间戳记。 -N或–name 压缩文件时，保存原来的文件名称及时间戳记。 -q或–quiet 不显示警告信息 -r或–recursive 递归处理，将指定目录下的所有文件及子目录一并处理。 -S&lt;压缩字尾字符串&gt;或—-suffix&lt;压缩字尾字符串&gt; 更改压缩字尾字符串。 -t或–test 测试压缩文件是否正确无误。 -v或–verbose 显示指令执行过程。 -V或–version 显示版本信息。 -num 用指定的数字num调整压缩的速度，-1或–fast表示最快压缩方法（低压缩比），-9或–best表示最慢压缩方法（高压缩比）。系统缺省值为6。 命令实例例一：把test目录下的每个文件压缩成.gz文件 # 忽略目录，只打包其中文件 $ gzip * 例二：把例1中每个压缩的文件解压，并列出详细的信息 $ gzip -dv * 例三：详细显示例1中每个压缩的文件的信息，并不解压 $ gzip -l * 例四：压缩一个tar备份文件，此时压缩文件的扩展名为.tar.gz $ gzip -r log.tar 例五：递归的压缩目录 $ gzip -rv test6 例六：递归地解压目录 $ gzip -dr test6","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"https://jiangxingye.github.io/tags/linux命令/"}]},{"title":"每天一个linux命令（24）: tar","slug":"linux-command（24）-tar","date":"2016-12-24T02:24:17.000Z","updated":"2019-09-02T13:03:00.009Z","comments":true,"path":"2016/12/24/linux-command（24）-tar/","link":"","permalink":"https://jiangxingye.github.io/2016/12/24/linux-command（24）-tar/","excerpt":"通过SSH访问服务器，难免会要用到压缩，解压缩，打包，解包等，这时候tar命令就是是必不可少的一个功能强大的工具。linux中最流行的tar是麻雀虽小，五脏俱全，功能强大。","text":"通过SSH访问服务器，难免会要用到压缩，解压缩，打包，解包等，这时候tar命令就是是必不可少的一个功能强大的工具。linux中最流行的tar是麻雀虽小，五脏俱全，功能强大。 tar命令可以为linux的文件和目录创建档案。利用tar，可以为某一特定文件创建档案（备份文件），也可以在档案中改变文件，或者向档案中加入新的文件。tar最初被用来在磁带上创建档案，现在，用户可以在任何设备上创建档案。利用tar命令，可以把一大堆的文件和目录全部打包成一个文件，这对于备份文件或将几个文件组合成为一个文件以便于网络传输是非常有用的。 首先要弄清两个概念：打包和压缩。打包是指将一大堆文件或目录变成一个总的文件；压缩则是将一个大的文件通过一些压缩算法变成一个小文件。 为什么要区分这两个概念呢？这源于Linux中很多压缩程序只能针对一个文件进行压缩，这样当你想要压缩一大堆文件时，你得先将这一大堆文件先打成一个包（tar命令），然后再用压缩程序进行压缩（gzip bzip2命令）。 linux下最常用的打包程序就是tar了，使用tar程序打出来的包我们常称为tar包，tar包文件的命令通常都是以.tar结尾的。生成tar包后，就可以用其它的程序来进行压缩。 命令格式$ tar [必要参数] [选择参数] [文件] 命令功能 用来压缩和解压文件。tar本身不具有压缩功能。他是调用压缩功能实现的 命令参数必要参数 参数 描述 -A 新增压缩文件到已存在的压缩 -B 设置区块大小 -c 建立新的压缩文件 -d 记录文件的差别 -r 添加文件到已经压缩的文件 -u 添加改变了和现有的文件到已经存在的压缩文件 -x 从压缩的文件中提取文件 -t 显示压缩文件的内容 -z 支持gzip解压文件 -j 支持bzip2解压文件 -Z 支持compress解压文件 -v 显示操作过程 -l 文件系统边界设置 -k 保留原有文件不覆盖 -m 保留文件不被覆盖 -W 确认压缩文件的正确性 可选参数 参数 描述 -b 设置区块数目 -C 切换到指定目录 -f 指定压缩文件 –help 显示帮助信息 –version 显示版本信息 使常见解压/压缩命令例一：.tar文件 $ tar xvf FileName.tar # 解包 $ tar cvf FileName.tar DirName # 打包 # 注：tar是打包，不是压缩！ 例二：.gz文件 # 解压 $ gunzip FileName.gz $ gzip -d FileName.gz # 压缩 gzip FileName 例三：.tar.gz和.tgz文件 $ tar xvf FileName.tar.gz # 解包 $ tar cvf FileName.tar.gz DirName # 打包 # 注：tar是打包，不是压缩！ 例四：.bz2文件 # 解压 $ bzip2 -d FileName.bz2 $ bunzip2 FileName.bz2 # 压缩 $ bzip2 -z FileName 例五：.tar.bz2文件 $ tar jxvf FileName.tar.bz2 # 解压 $ tar jcvf FileName.tar.bz2 DirName # 压缩 例六：.bz文件 # 解压 $ bzip2 -d FileName.bz $ bunzip2 FileName.bz 例七：.tar.bz文件 $ tar jxvf FileName.tar.bz # 解压 例八：.Z文件 $ uncompress FileName.Z # 解压 $ compress FileName # 压缩 例九：.tar.Z文件 $ tar Zxvf FileName.tar.Z # 解压 $ tar Zcvf FileName.tar.Z DirName # 压缩 例十：.zip文件 $ unzip FileName.zip # 解压 $ zip FileName.zip DirName # 压缩 例十一：.rar文件 $ rar x FileName.rar # 解压 $ rar a FileName.rar DirName # 压缩 使用实例例一：将文件全部打包成tar包 $ tar -cvf log.tar log2012.log # 仅打包，不压缩！ $ tar -zcvf log.tar.gz log2012.log # 打包后，以 gzip 压缩 $ tar -jcvf log.tar.bz2 log2012.log # 打包后，以 bzip2 压缩 在参数 f 之后的文件档名是自己取的，我们习惯上都用 .tar 来作为辨识。 如果加 z 参数，则以 .tar.gz 或 .tgz 来代表 gzip 压缩过的 tar包； 如果加 j 参数，则以 .tar.bz2 来作为tar包名。 例二：查阅上述 tar包内有哪些文件 $ tar -ztvf log.tar.gz # 由于我们使用 gzip 压缩的log.tar.gz，所以要查阅log.tar.gz包内的文件时，就得要加上 z 这个参数了 例三：将tar 包解压缩 $ tar -zxvf /opt/soft/test/log.tar.gz # 在预设的情况下，我们可以将压缩档在任何地方解开的 例四：只将 /tar 内的 部分文件解压出来 $ tar -zxvf /opt/soft/test/log30.tar.gz log2013.log # 我可以透过 tar -ztvf 来查阅 tar 包内的文件名称，如果单只要一个文件，就可以透过这个方式来解压部分文件！ 例五：文件备份下来，并且保存其权限 $ tar -zcvpf log31.tar.gz log2014.log log2015.log log2016.log # 这个 -p 的属性是很重要的，尤其是当您要保留原本文件的属性时 例六：在 文件夹当中，比某个日期新的文件才备份 $ tar -N &quot;2012/11/13&quot; -zcvf log17.tar.gz test 例七：备份文件夹内容是排除部分文件 $ tar --exclude scf/service -zcvf scf.tar.gz scf/*","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"https://jiangxingye.github.io/tags/linux命令/"}]},{"title":"每天一个linux命令（23）: 用SecureCRT来上传和下载文件","slug":"linux-command（23）-用SecureCRT来上传和下载文件","date":"2016-12-23T01:48:15.000Z","updated":"2019-09-02T13:03:00.007Z","comments":true,"path":"2016/12/23/linux-command（23）-用SecureCRT来上传和下载文件/","link":"","permalink":"https://jiangxingye.github.io/2016/12/23/linux-command（23）-用SecureCRT来上传和下载文件/","excerpt":"用SSH管理linux服务器时经常需要远程与本地之间交互文件.而直接用SecureCRT自带的上传下载功能无疑是最方便的，SecureCRT下的文件传输协议有ASCII、Xmodem、Zmodem。","text":"用SSH管理linux服务器时经常需要远程与本地之间交互文件.而直接用SecureCRT自带的上传下载功能无疑是最方便的，SecureCRT下的文件传输协议有ASCII、Xmodem、Zmodem。文件传输协议 文件传输是数据交换的主要形式。在进行文件传输时，为使文件能被正确识别和传送，我们需要在两台计算机之间建立统一的传输协议。这个协议包括了文件的识别、传送的起止时间、错误的判断与纠正等内容。常见的传输协议有以下几种： ASCII：这是最快的传输协议，单只能传输文本文件。 Xmodem：这种古老的传输协议速度较慢，但由于使用了CRC错误侦测方法，传输的准确率可高达99.6%。 Ymodem：这是Xmodem的改良版，使用了1024位区段传送，速度比Xmodem要快 Zmodem：Zmodem采用了串流式（streaming）传输方式，传输速度较快，而且还具有自动改变区段大小和断点续传、快速错误侦测等功能。这是目前最流行的文件传输协议。 除以上几种外，还有Imodem、Jmodem、Bimodem、Kermit、Lynx等协议，由于没有多数厂商支持，这里就略去不讲。 SecureCRT可以使用linux下的zmodem协议来快速的传送文件,使用非常方便.具体步骤： 在使用SecureCRT上传下载之前需要给服务器安装lrzsz 从下面的地址下载 lrzsz-0.12.20.tar.gz 我是下载地址 查看里面的INSTALL文档了解安装参数说明和细节 解压文件 $ tar zxvf lrzsz-0.12.20.tar.gz 进入目录，配置编译 $ cd lrzsz-0.12.20 $ ./configure --prefix=/usr/local/lrzsz $ make $ make install 建立软链接 $ cd /usr/bin $ ln -s /usr/local/lrzsz/bin/lrz rz $ ln -s /usr/local/lrzsz/bin/lsz sz 测试 运行 rz 弹出 SecureCrt上传窗口，用SecureCRT来上传和下载文件。 设置SecureCRT上传和下载的默认目录 options-&gt;session options -&gt;Terminal-&gt;Xmodem/Zmodem 右栏directory设置上传和下载的目录 使用Zmodem从客户端上传文件到linux服务器 用SecureCRT登陆linux终端 选中你要放置上传文件的路径，在目录下然后输入rz命令,SecureCRT会弹出文件选择对话框，在查找范围中找到你要上传的文件，按Add按钮。然后OK就可以把文件上传到linux上了。 或者在Transfer-&gt;Zmodem Upoad list弹出文件选择对话框，选好文件后按Add按钮。然后OK窗口自动关闭。然后在linux下选中存放文件的目录，输入rz命令。liunx就把那个文件上传到这个目录下了。 使用Zmodem下载文件到客户端$ sz filename zmodem 接收可以自行启动.下载的文件存放在你设定的默认下载目录下 rz，sz 是 Linux/Unix 同 Windows 进行 ZModem 文件传输的命令行工具 , windows 端需要支持ZModem的telnet/ssh客户端，SecureCRT 就可以用 SecureCRT 登陆到 Unix/Linux 主机（telnet或ssh均可）O 运行命令rz，即是接收文件，SecureCRT就会弹出文件选择对话框，选好文件之后关闭对话框，文件就会上传到当前目录 O 运行命令sz file1 file2就是发文件到windows上（保存的目录是可以配置） 比ftp命令方便多了，而且服务器不用再开FTP服务了","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"https://jiangxingye.github.io/tags/linux命令/"}]},{"title":"每天一个linux命令（22）: find命令的参数详解","slug":"linux-command（22）-find命令的参数详解","date":"2016-12-22T03:44:14.000Z","updated":"2019-09-02T13:03:00.007Z","comments":true,"path":"2016/12/22/linux-command（22）-find命令的参数详解/","link":"","permalink":"https://jiangxingye.github.io/2016/12/22/linux-command（22）-find命令的参数详解/","excerpt":"find一些常用参数的一些常用实例和一些具体用法和注意事项。","text":"find一些常用参数的一些常用实例和一些具体用法和注意事项。 使用name选项 文件名选项是find命令最常用的选项，要么单独使用该选项，要么和其他选项一起使用。可以使用某种文件名模式来匹配文件，记住要用引号将文件名模式引起来。 # 在自己的根目录$HOME中查找文件名符合*.log的文件，使用~作为 &#39;pathname&#39;参数，波浪号~代表了你的$HOME目录。 $ find ~ -name &quot;*.log&quot; -print # 在当前目录及子目录中查找所有的‘ *.log‘文件 $ find . -name &quot;*.log&quot; -print # 当前目录及子目录中查找文件名以一个大写字母开头的文件 $ find . -name &quot;[A-Z]*&quot; -print # 在/etc目录中查找文件名以host开头的文件 $ find /etc -name &quot;host*&quot; -print # 想要查找$HOME目录中的文件 $ find ~ -name &quot;*&quot; -print $ find . -print # 让系统高负荷运行，就从根目录开始查找所有的文件 $ find / -name &quot;*&quot; -print # 在当前目录查找文件名以一个个小写字母开头，最后是4到9加上.log结束的文件 $ find . -name &quot;[a-z]*[4-9].log&quot; -print 用perm选项 按照文件权限模式用-perm选项,按文件权限模式来查找文件的话。最好使用八进制的权限表示法 # 在当前目录下查找文件权限位为755的文件 $ find . -perm 755 -print 还有一种表达方法：在八进制数字前面要加一个横杠-，表示都匹配，如-007就相当于777，-005相当于555, $ find . -perm -005 忽略某个目录 如果在查找文件时希望忽略某个目录，因为你知道那个目录中没有你所要查找的文件，那么可以使用-prune选项来指出需要忽略的目录。在使用-prune选项时要当心，因为如果你同时使用了-depth选项，那么-prune选项就会被find命令忽略。如果希望在test目录下查找文件，但不希望在test/test3目录下查找，可以用: $ find test -path &quot;test/test3&quot; -prune -o -print 使用find查找文件的时候怎么避开某个文件目录例一：在test 目录下查找不在test4子目录之内的所有文件 $ find test -path &quot;test/test4&quot; -prune -o -print 说明：find [-path ..] [expression]在路径列表的后面的是表达式-path “test” -prune -o -print 是 -path “test” -a -prune -o -print 的简写表达式按顺序求值, -a 和 -o 都是短路求值，与 shell 的 &amp;&amp; 和 || 类似如果-path “test” 为真，则求值 -prune , -prune 返回真，与逻辑表达式为真；否则不求值 -prune，与逻辑表达式为假。如果 -path “test” -a -prune 为假，则求值 -print ，-print返回真，或逻辑表达式为真；否则不求值 -print，或逻辑表达式为真。这个表达式组合特例可以用伪码写为:if -path “test” then-pruneelse-print 例二：避开多个文件夹 # 圆括号表示表达式的结合。\\ 表示引用，即指示 shell 不对后面的字符作特殊解释，而留给 find 命令去解释其意义 $ find test \\( -path test/test4 -o -path test/test3 \\) -prune -o -print 例三：查找某一确定文件，-name等选项加在-o 之后 $ find test \\(-path test/test4 -o -path test/test3 \\) -prune -o -name &quot;*.log&quot; -print 使用user和nouser选项# 在$HOME目录中查找文件属主为peida的文件 $ find ~ -user peida -print # 在/etc目录下查找文件属主为peida的文件 $ find /etc -user peida -print # 为了查找属主帐户已经被删除的文件，可以使用-nouser选项。在/home目录下查找所有的这类文件 $ find /home -nouser -print 使用group和nogroup选项# 在/apps目录下查找属于gem用户组的文件 $ find /apps -group gem -print # 查找没有有效所属用户组的所有文件 $ find / -nogroup-print 按照更改时间或访问时间等查找文件 如果希望按照更改时间来查找文件，可以使用mtime,atime或ctime选项。如果系统突然没有可用空间了，很有可能某一个文件的长度在此期间增长迅速，这时就可以用mtime选项来查找这样的文件。用减号-来限定更改时间在距今n日以内的文件，而用加号+来限定更改时间在距今n日以前的文件 # 在系统根目录下查找更改时间在5日以内的文件 $ find / -mtime -5 -print # 在/var/adm目录下查找更改时间在3日以前的文件 $ find /var/adm -mtime +3 -print 查找比某个文件新或旧的文件 如果希望查找更改时间比某个文件新但比另一个文件旧的所有文件，可以使用-newer选项。 # 查找更改时间比文件log2012.log新但比文件log2017.log旧的文件 $ find -newer log2012.log ! -newer log2017.log # 查找更改时间在比log2012.log文件新的文件 $ find . -newer log2012.log -print 使用type选项# 在/etc目录下查找所有的目录 $ find /etc -type d -print # 在当前目录下查找除目录以外的所有类型的文件 $ find . ! -type d -print # 在/etc目录下查找所有的符号链接文件 $ find /etc -type l -print 使用size选项 可以按照文件长度来查找文件，这里所指的文件长度既可以用块（block）来计量，也可以用字节来计量。以字节计量文件长度的表达形式为N c；以块计量文件长度只用数字表示即可。在按照文件长度查找文件时，一般使用这种以字节表示的文件长度，在查看文件系统的大小，因为这时使用块来计量更容易转换。 # 在当前目录下查找文件长度大于1 M字节的文件 $ find . -size +1000000c -print # 在/home/apache目录下查找文件长度恰好为100字节的文件 $ find /home/apache -size 100c -print # 在当前目录下查找长度超过10块的文件（一块等于512字节） $ find . -size +10 -print 使用depth选项 在使用find命令时，可能希望先匹配所有的文件，再在子目录中查找。使用depth选项就可以使find命令这样做。这样做的一个原因就是，当在使用find命令向磁带上备份文件系统时，希望首先备份所有的文件，其次再备份子目录中的文件。 # find命令从文件系统的根目录开始，查找一个名为CON.FILE的文件 # 它将首先匹配所有的文件然后再进入子目录中查找 $ find / -name &quot;CON.FILE&quot; -depth -print 使用mount选项 在当前的文件系统中查找文件（不进入其他文件系统），可以使用find命令的mount选项 # 从当前目录开始查找位于本文件系统中文件名以XC结尾的文件 $ find . -name &quot;*.XC&quot; -mount -print","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"https://jiangxingye.github.io/tags/linux命令/"}]},{"title":"每天一个linux命令（21）: find命令之xargs","slug":"linux-command（21）-find命令之xargs","date":"2016-12-21T03:08:01.000Z","updated":"2019-09-02T13:03:00.006Z","comments":true,"path":"2016/12/21/linux-command（21）-find命令之xargs/","link":"","permalink":"https://jiangxingye.github.io/2016/12/21/linux-command（21）-find命令之xargs/","excerpt":"在使用 find命令的-exec选项处理匹配到的文件时， find命令将所有匹配到的文件一起传递给exec执行。但有些系统对能够传递给exec的命令长度有限制，这样在find命令运行几分钟之后，就会出现溢出错误。错误信息通常是“参数列太长”或“参数列溢出”。这就是xargs命令的用处所在，特别是与find命令一起使用。","text":"在使用 find命令的-exec选项处理匹配到的文件时， find命令将所有匹配到的文件一起传递给exec执行。但有些系统对能够传递给exec的命令长度有限制，这样在find命令运行几分钟之后，就会出现溢出错误。错误信息通常是“参数列太长”或“参数列溢出”。这就是xargs命令的用处所在，特别是与find命令一起使用。 find命令把匹配到的文件传递给xargs命令，而xargs命令每次只获取一部分文件而不是全部，不像-exec选项那样。这样它可以先处理最先获取的一部分文件，然后是下一批，并如此继续下去。 在有些系统中，使用-exec选项会为处理每一个匹配到的文件而发起一个相应的进程，并非将匹配到的文件全部作为参数一次执行；这样在有些情况下就会出现进程过多，系统性能下降的问题，因而效率不高； 而使用xargs命令则只有一个进程。另外，在使用xargs命令时，究竟是一次获取所有的参数，还是分批取得参数，以及每一次获取参数的数目都会根据该命令的选项及系统内核中相应的可调参数来确定。 使用实例例一：查找系统中的每一个普通文件，然后使用xargs命令来测试它们分别属于哪类文件 $ find . -type f -print | xargs file 例二：在整个系统中查找内存信息转储文件(core dump) ，然后把结果保存到/tmp/core.log 文件中 $ find / -name &quot;core&quot; -print | xargs echo &quot;&quot; &gt;/tmp/core.log 例三：在当前目录下查找所有用户具有读、写和执行权限的文件，并收回相应的写权限 $ find . -perm -7 -print | xargs chmod o-w 例四：用grep命令在所有的普通文件中搜索hostname这个词 $ find . -type f -print | xargs grep &quot;hostname&quot; 例五：用grep命令在当前目录下的所有普通文件中搜索hostnames这个词 # \\用来取消find命令中的*在shell中的特殊含义 $ find . -name \\* -type f -print | xargs grep &quot;hostnames&quot; 例六：使用xargs执行mv $ find . -name &quot;*.log&quot; | xargs -i mv {} test4 例七：find后执行xargs提示xargs: argument line too long解决方法 # -l1是一次处理一个；-t是处理之前打印出命令 $ find . -type f -atime +0 -print0 | xargs -0 -l1 -t rm -f 例八：使用-i参数默认的前面输出用{}代替，-I参数可以指定其他代替字符，如例子中的[] $ find . -name &quot;file&quot; | xargs -I [] cp [] .. 例九：xargs的-p参数的使用 # -p参数会提示让你确认是否执行后面的命令,y执行，n不执行 $ find . -name &quot;*.log&quot; | xargs -p -i mv {} ..","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"https://jiangxingye.github.io/tags/linux命令/"}]},{"title":"每天一个linux命令（20）: find命令之exec","slug":"linux-command（20）-find命令之exec","date":"2016-12-20T02:47:32.000Z","updated":"2019-09-02T13:03:00.006Z","comments":true,"path":"2016/12/20/linux-command（20）-find命令之exec/","link":"","permalink":"https://jiangxingye.github.io/2016/12/20/linux-command（20）-find命令之exec/","excerpt":"find是我们很常用的一个Linux命令，但是我们一般查找出来的并不仅仅是看看而已，还会有进一步的操作，这个时候exec的作用就显现出来了","text":"find是我们很常用的一个Linux命令，但是我们一般查找出来的并不仅仅是看看而已，还会有进一步的操作，这个时候exec的作用就显现出来了 命令介绍 -exec 参数后面跟的是command命令，它的终止是以;为结束标志的，所以这句命令后面的分号是不可缺少的，考虑到各个系统中分号会有不同的意义，所以前面加反斜杠。 {} 花括号代表前面find查找出来的文件名。 使用find时，只要把想要的操作写在一个文件里，就可以用exec来配合find查找，很方便的。在有些操作系统中只允许-exec选项执行诸如ls或ls -l这样的命令。大多数用户使用这一选项是为了查找旧文件并删除它们。建议在真正执行rm命令删除文件之前，最好先用ls命令看一下，确认它们是所要删除的文件。 exec选项后面跟随着所要执行的命令或脚本，然后是一对儿{ }，一个空格和一个\\，最后是一个分号。为了使用exec选项，必须要同时使用print选项。如果验证一下find命令，会发现该命令只输出从当前路径起的相对路径及文件名。 使用实例例一：ls -l命令放在find命令的-exec选项中 # find命令匹配到了当前目录下的所有普通文件，并在-exec选项中使用ls -l命令将它们列出 $ find . -type f -exec ls -l {} \\; 例二：在目录中查找更改时间在n日以前的文件并删除它们 $ find . -type f -mtime +14 -exec rm {} \\; 例三：在目录中查找更改时间在n日以前的文件并删除它们，在删除之前先给出提示 $ find . -name &quot;*.log&quot; -mtime +5 -ok rm {} \\; 例四：-exec中使用grep命令 $ find /etc -name &quot;passwd*&quot; -exec grep &quot;root&quot; {} \\; 例五：查找文件移动到指定目录 $ find . -name &quot;*.log&quot; -exec mv {} .. \\; 例六：用exec选项执行cp命令 $ find . -name &quot;*.log&quot; -exec cp {} test3 \\;","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"https://jiangxingye.github.io/tags/linux命令/"}]},{"title":"每天一个linux命令（19）: find命令概览","slug":"linux-command（19）-find命令概览","date":"2016-12-19T07:19:10.000Z","updated":"2019-09-02T13:03:00.005Z","comments":true,"path":"2016/12/19/linux-command（19）-find命令概览/","link":"","permalink":"https://jiangxingye.github.io/2016/12/19/linux-command（19）-find命令概览/","excerpt":"Linux下find命令在目录结构中搜索文件，并执行指定的操作。Linux下find命令提供了相当多的查找条件，功能很强大。由于find具有强大的功能，所以它的选项也很多，其中大部分选项都值得我们花时间来了解一下。即使系统中含有网络文件系统( NFS)，find命令在该文件系统中同样有效，只你具有相应的权限。 在运行一个非常消耗资源的find命令时，很多人都倾向于把它放在后台执行，因为遍历一个大的文件系统可能会花费很长的时间(这里是指30G字节以上的文件系统)。","text":"Linux下find命令在目录结构中搜索文件，并执行指定的操作。Linux下find命令提供了相当多的查找条件，功能很强大。由于find具有强大的功能，所以它的选项也很多，其中大部分选项都值得我们花时间来了解一下。即使系统中含有网络文件系统( NFS)，find命令在该文件系统中同样有效，只你具有相应的权限。 在运行一个非常消耗资源的find命令时，很多人都倾向于把它放在后台执行，因为遍历一个大的文件系统可能会花费很长的时间(这里是指30G字节以上的文件系统)。 命令格式$ find pathname -options [-print -exec -ok ...] 命令功能 用于在文件树种查找文件，并作出相应的处理 命令参数 参数 描述 pathname find命令所查找的目录路径。例如用.来表示当前目录，用/来表示系统根目录 -print find命令将匹配的文件输出到标准输出 -exec find命令对匹配的文件执行该参数所给出的shell命令。相应命令的形式为’command’ { } \\;，注意{ }和\\；之间的空格 -ok 和-exec的作用相同，只不过以一种更为安全的模式来执行该参数所给出的shell命令，在执行每一个命令之前，都会给出提示，让用户来确定是否执行 命令选项 选项 描述 -name 按照文件名查找文件 -perm 按照文件权限来查找文件 -prune 使用这一选项可以使find命令不在当前指定的目录中查找，如果同时使用-depth选项，那么-prune将被find命令忽略 -user 按照文件属主来查找文件 -group 按照文件所属的组来查找文件 -mtime -n +n 按照文件的更改时间来查找文件， - n表示文件更改时间距现在n天以内，+ n表示文件更改时间距现在n天以前。find命令还有-atime和-ctime 选项，但它们都和-m time选项 -nogroup 查找无有效所属组的文件，即该文件所属的组在/etc/groups中不存在 -nouser 查找无有效属主的文件，即该文件的属主在/etc/passwd中不存在 -newer file1 ! file2 查找更改时间比文件file1新但比文件file2旧的文件 -type 查找某一类型的文件,诸如：b - 块设备文件d - 目录c - 字符设备文件p - 管道文件l - 符号链接文件f - 普通文件 -size n：[c] 查找文件长度为n块的文件，带有c时表示文件长度以字节计。-depth：在查找文件时，首先查找当前目录中的文件，然后再在其子目录中查找 -fstype 查找位于某一类型文件系统中的文件，这些文件系统类型通常可以在配置文件/etc/fstab中找到，该配置文件中包含了本系统中有关文件系统的信息 -mount 在查找文件时不跨越文件系统mount点 -follow 如果find命令遇到符号链接文件，就跟踪至链接所指向的文件 -cpio 对匹配的文件使用cpio命令，将这些文件备份到磁带设备中 -amin n 查找系统中最后N分钟访问的文件 -atime n 查找系统中最后n*24小时访问的文件 -cmin n 查找系统中最后N分钟被改变文件状态的文件 -ctime n 查找系统中最后n*24小时被改变文件状态的文件 -mmin n 查找系统中最后N分钟被改变文件数据的文件 -mtime n 查找系统中最后n*24小时被改变文件数据的文件 使用实例例一：查找指定时间内修改过的文件 # 查找48小时内修改过的文件 $ find -atime -2 例二：根据关键字查找 # 在当前目录查找一.log结尾的文件。 &quot;. &quot;代表当前目录 $ find . -name &quot;*.log&quot; 例三：按照目录或文件的权限来查找文件 # 查找/opt/soft/test/目录下 权限为 777的文件 $ find /opt/soft/test/ -perm 777 例四：按类型查找 # 查找当目录，以.log结尾的普通文件 $ find . -type f -name &quot;*.log&quot; 例五：查找当前所有目录并排序 $ find . -type d | sort 例六：按大小查找文件 # 查找当前目录大于1K的文件 $ find . -size +1000c -print","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"https://jiangxingye.github.io/tags/linux命令/"}]},{"title":"每天一个linux命令（18）: locate","slug":"linux-command（18）-locate","date":"2016-12-18T07:09:28.000Z","updated":"2019-09-02T13:03:00.005Z","comments":true,"path":"2016/12/18/linux-command（18）-locate/","link":"","permalink":"https://jiangxingye.github.io/2016/12/18/linux-command（18）-locate/","excerpt":"locate 让使用者可以很快速的搜寻档案系统内是否有指定的档案。其方法是先建立一个包括系统内所有档案名称及路径的数据库，之后当寻找时就只需查询这个数据库，而不必实际深入档案系统之中了。在一般的 distribution 之中，数据库的建立都被放在 crontab 中自动执行。","text":"locate 让使用者可以很快速的搜寻档案系统内是否有指定的档案。其方法是先建立一个包括系统内所有档案名称及路径的数据库，之后当寻找时就只需查询这个数据库，而不必实际深入档案系统之中了。在一般的 distribution 之中，数据库的建立都被放在 crontab 中自动执行。 命令格式$ locate [选择参数] [样式] 命令功能 locate命令可以在搜寻数据库时快速找到档案，数据库由updatedb程序来更新，updatedb是由cron daemon周期性建立的，locate命令在搜寻数据库时比由整个由硬盘资料来搜寻资料来得快，但较差劲的是locate所找到的档案若是最近才建立或 刚更名的，可能会找不到，在内定值中，updatedb每天会跑一次，可以由修改crontab来更新设定值。(etc/crontab) locate指定用在搜寻符合条件的档案，它会去储存档案与目录名称的数据库内，寻找合乎范本样式条件的档案或目录录，可以使用特殊字元（如* 或 ?等）来指定范本样式，如指定范本为kcpa*ner, locate会找出所有起始字串为kcpa且结尾为ner的档案或目录，如名称为kcpartner若目录录名称为kcpa_ner则会列出该目录下包括 子目录在内的所有档案。 locate指令和find找寻档案的功能类似，但locate是透过update程序将硬盘中的所有档案和目录资料先建立一个索引数据库，在 执行loacte时直接找该索引，查询速度会较快，索引数据库一般是由操作系统管理，但也可以直接下达update强迫系统立即修改索引数据库。 命令参数 参数 描述 -e 将排除在寻找的范围之外 -1 如果 是 1．则启动安全模式。在安全模式下，使用者不会看到权限无法看到的档案。这会始速度减慢，因为 locate 必须至实际的档案系统中取得档案的权限资料 -f 将特定的档案系统排除在外，例如我们没有到理要把 proc 档案系统中的档案放在资料库中 -q 安静模式，不会显示任何错误讯息 -n 至多显示 n个输出 -r 使用正规运算式 做寻找的条件 -o 指定资料库存的名称 -d 指定资料库的路径 -h 显示辅助讯息 -V 显示程式的版本讯息 使用实例例一：查找和pwd相关的所有文件 $ locate pwd 例二：搜索etc目录下所有以sh开头的文件 $ locate /etc/sh","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"https://jiangxingye.github.io/tags/linux命令/"}]},{"title":"每天一个linux命令（17）: whereis","slug":"linux-command（17）-whereis","date":"2016-12-17T02:42:58.000Z","updated":"2019-09-02T13:03:00.005Z","comments":true,"path":"2016/12/17/linux-command（17）-whereis/","link":"","permalink":"https://jiangxingye.github.io/2016/12/17/linux-command（17）-whereis/","excerpt":"whereis命令只能用于程序名的搜索，而且只搜索二进制文件（参数-b）、man说明文件（参数-m）和源代码文件（参数-s）。如果省略参数，则返回所有信息。","text":"whereis命令只能用于程序名的搜索，而且只搜索二进制文件（参数-b）、man说明文件（参数-m）和源代码文件（参数-s）。如果省略参数，则返回所有信息。 和find相比，whereis查找的速度非常快，这是因为linux系统会将 系统内的所有文件都记录在一个数据库文件中，当使用whereis和下面即将介绍的locate时，会从数据库中查找数据，而不是像find命令那样，通 过遍历硬盘来查找，效率自然会很高。 但是该数据库文件并不是实时更新，默认情况下时一星期更新一次，因此，我们在用whereis和locate 查找文件时，有时会找到已经被删除的数据，或者刚刚建立文件，却无法查找到，原因就是因为数据库文件没有被更新。 命令格式$ whereis [-bmsu] [BMS 目录名 -f ] 文件名 命令功能 whereis命令是定位可执行文件、源代码文件、帮助文件在文件系统中的位置。这些文件的属性应属于原始代码，二进制文件，或是帮助文件。whereis 程序还具有搜索源代码、指定备用搜索路径和搜索不寻常项的能力。 命令参数 参数 描述 -b 定位可执行文件 -m 定位帮助文件 -s 定位源代码文件 -u 搜索默认路径下除可执行文件、源代码文件、帮助文件以外的其它文件 -B 指定搜索可执行文件的路径 -M 指定搜索帮助文件的路径 -S 指定搜索源代码文件的路径 使用实例例一：将和git文件相关的文件都查找出来 $ whereis git 例二：只将二进制文件 查找出来 $ whereis -b svn whereis -m svn 查出说明文档路径，whereis -s svn 找source源文件","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"https://jiangxingye.github.io/tags/linux命令/"}]},{"title":"每天一个linux命令（16）: which","slug":"linux-command（16）-which","date":"2016-12-16T03:25:49.000Z","updated":"2019-09-02T13:03:00.004Z","comments":true,"path":"2016/12/16/linux-command（16）-which/","link":"","permalink":"https://jiangxingye.github.io/2016/12/16/linux-command（16）-which/","excerpt":"我们经常在linux要查找某个文件，但不知道放在哪里了，可以使用下面的一些命令来搜索：which 查看可执行文件的位置。whereis 查看文件的位置。locate 配合数据库查看文件位置。find 实际搜寻硬盘查询文件名称。 which命令的作用是，在PATH变量指定的路径中，搜索某个系统命令的位置，并且返回第一个搜索结果。也就是说，使用which命令，就可以看到某个系统命令是否存在，以及执行的到底是哪一个位置的命令。","text":"我们经常在linux要查找某个文件，但不知道放在哪里了，可以使用下面的一些命令来搜索：which 查看可执行文件的位置。whereis 查看文件的位置。locate 配合数据库查看文件位置。find 实际搜寻硬盘查询文件名称。 which命令的作用是，在PATH变量指定的路径中，搜索某个系统命令的位置，并且返回第一个搜索结果。也就是说，使用which命令，就可以看到某个系统命令是否存在，以及执行的到底是哪一个位置的命令。 命令格式$ which 可执行文件名称 命令功能 which指令会在PATH变量指定的路径中，搜索某个系统命令的位置，并且返回第一个搜索结果。 命令参数 参数 描述 -n 指定文件名长度，指定的长度必须大于或等于所有文件中最长的文件名 -p 与-n参数相同，但此处的包括了文件的路径 -w 指定输出时栏位的宽度 -V 显示版本信息 使用实例例一：查找文件、显示命令路径 # which 是根据使用者所配置的 PATH 变量内的目录去搜寻可运行档的！ # 所以，不同的 PATH 配置内容所找到的命令当然不一样的！ $ which pwd 例二：用 which 去找出 which # 竟然会有两个 which ，其中一个是 alias 这就是所谓的『命令别名』，意思是输入 which 会等於后面接的那串命令！ $ which which 例三：找出 cd 这个命令 # cd 这个常用的命令竟然找不到啊！为什么呢？这是因为 cd 是bash 内建的命令！ # 但是 which 默认是找 PATH 内所规范的目录，所以当然一定找不到的！ $ which cd","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"https://jiangxingye.github.io/tags/linux命令/"}]},{"title":"每天一个linux命令（15）: tail","slug":"linux-command（15）-tail","date":"2016-12-15T07:00:26.000Z","updated":"2019-09-02T13:03:00.004Z","comments":true,"path":"2016/12/15/linux-command（15）-tail/","link":"","permalink":"https://jiangxingye.github.io/2016/12/15/linux-command（15）-tail/","excerpt":"tail 命令从指定点开始将文件写到标准输出.使用tail命令的-f选项可以方便的查阅正在改变的日志文件,tail -f filename会把filename里最尾部的内容显示在屏幕上,并且不但刷新,使你看到最新的文件内容.","text":"tail 命令从指定点开始将文件写到标准输出.使用tail命令的-f选项可以方便的查阅正在改变的日志文件,tail -f filename会把filename里最尾部的内容显示在屏幕上,并且不但刷新,使你看到最新的文件内容. 命令格式tail[必要参数][选择参数][文件] 命令功能 用于显示指定文件末尾内容，不指定文件时，作为输入信息进行处理。常用查看日志文件。 命令参数 参数 描述 -f 循环读取 -q 不显示处理信息 -v 显示详细的处理信息 -c&lt;数目&gt; 显示的字节数 -n&lt;行数&gt; 显示行数 –pid=PID 与-f合用,表示在进程ID,PID死掉之后结束 -q, –quiet, –silent 从不输出给出文件名的首部 -s, –sleep-interval=S 与-f合用,表示在每次反复的间隔休眠S秒 使用实例例一：显示文件末尾内容 # 显示文件最后5行内容 $ tail -n 5 log2014.log 例二：循环查看文件内容 $ tail -f test.log 例三：从第5行开始显示文件 $ tail -n +5 log2014.log","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"https://jiangxingye.github.io/tags/linux命令/"}]},{"title":"每天一个linux命令（14）: head","slug":"linux-command（14）-head","date":"2016-12-14T06:35:49.000Z","updated":"2019-09-02T13:03:00.003Z","comments":true,"path":"2016/12/14/linux-command（14）-head/","link":"","permalink":"https://jiangxingye.github.io/2016/12/14/linux-command（14）-head/","excerpt":"head 与 tail 就像它的名字一样的浅显易懂，它是用来显示开头或结尾某个数量的文字区块，head 用来显示档案的开头至标准输出中，而 tail 想当然尔就是看档案的结尾。","text":"head 与 tail 就像它的名字一样的浅显易懂，它是用来显示开头或结尾某个数量的文字区块，head 用来显示档案的开头至标准输出中，而 tail 想当然尔就是看档案的结尾。 命令格式head [参数]... [文件]... 命令功能 head 用来显示档案的开头至标准输出中，默认head命令打印其相应文件的开头10行。 命令参数 参数 描述 -q 隐藏文件名 -v 显示文件名 -c&lt;字节&gt; 显示字节数 -n&lt;行数&gt; 显示的行数 使用实例例一：显示文件的前n行 $ head -n 5 log2014.log 例二：显示文件前n个字节 $ head -c 20 log2014.log 例三：文件的除了最后n个字节以外的内容 $ head -c -32 log2014.log 例四：输出文件除了最后n行的全部内容 $ head -n -6 log2014.log","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"https://jiangxingye.github.io/tags/linux命令/"}]},{"title":"每天一个linux命令（13）: less","slug":"linux-command（13）-less","date":"2016-12-13T13:46:14.000Z","updated":"2019-09-02T13:03:00.003Z","comments":true,"path":"2016/12/13/linux-command（13）-less/","link":"","permalink":"https://jiangxingye.github.io/2016/12/13/linux-command（13）-less/","excerpt":"less 工具也是对文件或其它输出进行分页显示的工具，应该说是linux正统查看文件内容的工具，功能极其强大。less 的用法比起 more 更加的有弹性。在 more 的时候，我们并没有办法向前面翻， 只能往后面看，但若使用了 less 时，就可以使用 [pageup] [pagedown] 等按键的功能来往前往后翻看文件，更容易用来查看一个文件的内容！除此之外，在 less 里头可以拥有更多的搜索功能，不止可以向下搜，也可以向上搜。","text":"less 工具也是对文件或其它输出进行分页显示的工具，应该说是linux正统查看文件内容的工具，功能极其强大。less 的用法比起 more 更加的有弹性。在 more 的时候，我们并没有办法向前面翻， 只能往后面看，但若使用了 less 时，就可以使用 [pageup] [pagedown] 等按键的功能来往前往后翻看文件，更容易用来查看一个文件的内容！除此之外，在 less 里头可以拥有更多的搜索功能，不止可以向下搜，也可以向上搜。 命令格式$ less [参数] 文件 命令功能 less 与 more 类似，但使用 less 可以随意浏览文件，而 more 仅能向前移动，却不能向后移动，而且 less 在查看之前不会加载整个文件。 命令参数 参数 描述 -b &lt;缓冲区大小&gt; 设置缓冲区的大小 -e 当文件显示结束后，自动离开 -f 强迫打开特殊文件，例如外围设备代号、目录和二进制文件 -g 只标志最后搜索的关键词 -i 忽略搜索时的大小写 -m 显示类似more命令的百分比 -N 显示每行的行号 -o &lt;文件名&gt; 将less 输出的内容在指定文件中保存起来 -Q 不使用警告音 -s 显示连续空行为一行 -S 行过长时间将超出部分舍弃 -x &lt;数字&gt; 将“tab”键显示为规定的数字空格 /字符串 向下搜索“字符串”的功能 ?字符串 向上搜索“字符串”的功能 n 重复前一个搜索（与 / 或 ? 有关） N 反向重复前一个搜索（与 / 或 ? 有关） b 向后翻一页 d 向后翻半页 h 显示帮助界面 Q 退出less 命令 u 向前滚动半页 y 向前滚动一行 空格键 滚动一行 回车键 滚动一页 [pagedown] 向下翻动一页 [pageup] 向上翻动一页 常用操作全屏导航 操作 描述 ctrl + F 向前移动一屏 ctrl + B 向后移动一屏 ctrl + D 向前移动半屏 ctrl + U 向后移动半屏 单行导航 操作 描述 j 向前移动一行 k 向后移动一行 其他导航 操作 描述 G 移动到最后一行 g 移动到第一行 q / ZZ 退出 less 命令 其它有用的命令 操作 描述 v 使用配置的编辑器编辑当前文件 h 显示 less 的帮助文档 &amp;pattern 仅显示匹配模式的行，而不是整个文件 标记导航 当使用 less 查看大文件时，可以在任何一个位置作标记，可以通过命令导航到标有特定标记的文本位置 操作 描述 ma 使用 a 标记文本的当前位置 ‘a 导航到标记 a 处 使用实例例一：查看文件 $ less log2013.log 例二：ps查看进程信息并通过less分页显示 $ ps -ef |less 例三：查看命令历史使用记录并通过less分页显示 $ history | less 例三：浏览多个文件 $ Less log2013.log log2014.log 输入 ：n后，切换到 log2014.log输入 ：p 后，切换到log2013.log","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"https://jiangxingye.github.io/tags/linux命令/"}]},{"title":"每天一个linux命令（12）: more","slug":"linux-command（12）-more","date":"2016-12-12T13:29:39.000Z","updated":"2019-09-02T13:03:00.002Z","comments":true,"path":"2016/12/12/linux-command（12）-more/","link":"","permalink":"https://jiangxingye.github.io/2016/12/12/linux-command（12）-more/","excerpt":"more命令，功能类似 cat ，cat命令是整个文件的内容从上到下显示在屏幕上。 more会以一页一页的显示方便使用者逐页阅读，而最基本的指令就是按空白键（space）就往下一页显示，按 b 键就会往回（back）一页显示，而且还有搜寻字串的功能 。more命令从前向后读取文件，因此在启动时就加载整个文件。","text":"more命令，功能类似 cat ，cat命令是整个文件的内容从上到下显示在屏幕上。 more会以一页一页的显示方便使用者逐页阅读，而最基本的指令就是按空白键（space）就往下一页显示，按 b 键就会往回（back）一页显示，而且还有搜寻字串的功能 。more命令从前向后读取文件，因此在启动时就加载整个文件。 命令格式$ more [-dlfpcsu ] [-num ] [+/ pattern] [+ linenum] [file ... ] 命令功能 more命令和cat的功能一样都是查看文件里的内容，但有所不同的是more可以按页来查看文件的内容，还支持直接跳转行等功能。 命令参数 参数 描述 +n 从笫n行开始显示 -n 定义屏幕大小为n行 +/pattern 每个档案显示前搜寻该字串（pattern），然后从该字串前两行之后开始显示 -c 从顶部清屏，然后显示 -d 提示“Press space to continue，’q’ to quit（按空格键继续，按q键退出）”，禁用响铃功能 -l 忽略Ctrl+l（换页）字符 -p 通过清除窗口而不是滚屏来对文件进行换页，与-c选项相似 -s 把连续的多个空行显示为一行 -u 把文件内容中的下画线去掉 常用操作 操作 描述 Enter 向下n行，需要定义。默认为1行 Ctrl+F 向下滚动一屏 空格键 向下滚动一屏 Ctrl+B 返回上一屏 = 输出当前行的行号 ：f 输出文件名和当前行的行号 V 调用vi编辑器 !命令 调用Shell，并执行命令 q 退出more 命令实例例一：显示文件中从第3行起的内容 $ more +3 log2012.log 例二：从文件中查找第一个出现”day3”字符串的行，并从该处前两行开始显示输出 $ more +/day3 log2012.log 例三：设定每屏显示行数 $ more -5 log2012.log 例四：列一个目录下的文件，由于内容太多，我们应该学会用more来分页显示。这得和管道 | 结合起来 $ ls -l | more -5 说明：每页显示5个文件信息，按 Ctrl+F 或者 空格键 将会显示下5条文件信息。","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"https://jiangxingye.github.io/tags/linux命令/"}]},{"title":"每天一个linux命令（11）: nl","slug":"linux-command（11）-nl","date":"2016-12-11T13:11:48.000Z","updated":"2019-09-02T13:03:00.002Z","comments":true,"path":"2016/12/11/linux-command（11）-nl/","link":"","permalink":"https://jiangxingye.github.io/2016/12/11/linux-command（11）-nl/","excerpt":"nl命令在linux系统中用来计算文件中行号。nl 可以将输出的文件内容自动的加上行号！其默认的结果与 cat -n 有点不太一样， nl 可以将行号做比较多的显示设计，包括位数与是否自动补齐 0 等等的功能。","text":"nl命令在linux系统中用来计算文件中行号。nl 可以将输出的文件内容自动的加上行号！其默认的结果与 cat -n 有点不太一样， nl 可以将行号做比较多的显示设计，包括位数与是否自动补齐 0 等等的功能。 命令格式$ nl [选项]... [文件]... 命令功能 nl 命令读取 File 参数（缺省情况下标准输入），计算输入中的行号，将计算过的行号写入标准输出。 在输出中，nl 命令根据您在命令行中指定的标志来计算左边的行。 输入文本必须写在逻辑页中。每个逻辑页有头、主体和页脚节（可以有空节）。 除非使用 -p 标志，nl 命令在每个逻辑页开始的地方重新设置行号。 可以单独为头、主体和页脚节设置行计算标志（例如，头和页脚行可以被计算然而文本行不能）。 命令参数 种类 参数 描述 -b -b a 表示不论是否为空行，也同样列出行号(类似 cat -n) -b t 如果有空行，空的那一行不要列出行号(默认值) -n -n ln 行号在萤幕的最左方显示 -n rn 行号在自己栏位的最右方显示，且不加 0 -n rz 行号在自己栏位的最右方显示，且加 0 -w -w 行号栏位的占用的位数 -p -p 在逻辑定界符处不重新开始计算 命令实例例一：用 nl 列出 log2012.log 的内容 # 文件中的空白行，nl 不会加上行号 $ nl log2012.log 例二：用 nl 列出 log2012.log 的内容，空本行也加上行号 $ nl -b a log2012.log 例三：让行号前面自动补上0,统一输出格式 $ nl -b a -n rz log2014.log nl -b a -n rz 命令行号默认为六位，要调整位数可以加上参数 -w 3 调整为3位。","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"https://jiangxingye.github.io/tags/linux命令/"}]},{"title":"每天一个linux命令（10）: cat","slug":"linux-command（10）-cat","date":"2016-12-10T02:52:50.000Z","updated":"2019-09-02T13:03:00.001Z","comments":true,"path":"2016/12/10/linux-command（10）-cat/","link":"","permalink":"https://jiangxingye.github.io/2016/12/10/linux-command（10）-cat/","excerpt":"cat命令的用途是连接文件或标准输入并打印。这个命令常用来显示文件内容，或者将几个文件连接起来显示，或者从标准输入读取内容并显示，它常与重定向符号配合使用。","text":"cat命令的用途是连接文件或标准输入并打印。这个命令常用来显示文件内容，或者将几个文件连接起来显示，或者从标准输入读取内容并显示，它常与重定向符号配合使用。 命令格式$ cat [选项] [文件]... 命令功能cat主要有三大功能 一次显示整个文件:cat filename 从键盘创建一个文件:cat &gt; filename 只能创建新文件,不能编辑已有文件. 将几个文件合并为一个文件:cat file1 file2 &gt; file 命令参数 参数 描述 -A, –show-all 等价于 -vET -b, –number-nonblank 对非空输出行编号 -e 等价于 -vE -E, –show-ends 在每行结束处显示 $ -n, –number 对输出的所有行编号,由1开始对所有输出的行数编号 -s, –squeeze-blank 有连续两行以上的空白行，就代换为一行的空白行 -t 与 -vT 等价 -T, –show-tabs 将跳格字符显示为 ^I -u (被忽略) -v, –show-nonprinting 使用 ^ 和 M- 引用，除了 LFD 和 TAB 之外 命令实例例一：把 log2012.log 的文件内容加上行号后输入 log2013.log 这个文件里 $ cat -n log2012.log log2013.log 例二：把 log2012.log 和 log2013.log 的文件内容加上行号（空白行不加）之后将内容附加到 log.log 里 $ cat -b log2012.log log2013.log log.log 例三：把 log2012.log 的文件内容加上行号后输入 log.log 这个文件里 $ cat -n log2012.log &gt; log.log 例四：使用here doc来生成文件 $ cat &gt;log.txt &lt;&lt;EOF &gt; Hello &gt; World &gt; Linux &gt; PWD=$(pwd) &gt; EOF 例五：tac (反向列示) $ tac log.txt PWD=/opt/soft/test Linux World Hello tac 是将 cat 反写过来，所以他的功能就跟 cat 相反， cat 是由第一行到最后一行连续显示在萤幕上，而 tac 则是由最后一行到第一行反向在萤幕上显示出来！","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"https://jiangxingye.github.io/tags/linux命令/"}]},{"title":"每天一个linux命令（9）: touch","slug":"linux-command（9）-touch","date":"2016-12-08T23:15:12.000Z","updated":"2019-09-02T13:03:00.031Z","comments":true,"path":"2016/12/09/linux-command（9）-touch/","link":"","permalink":"https://jiangxingye.github.io/2016/12/09/linux-command（9）-touch/","excerpt":"linux的touch命令不常用，一般在使用make的时候可能会用到，用来修改文件时间戳，或者新建一个不存在的文件。","text":"linux的touch命令不常用，一般在使用make的时候可能会用到，用来修改文件时间戳，或者新建一个不存在的文件。 命令格式$ touch [选项]... 文件... 命令功能 touch命令参数可更改文档或目录的日期时间，包括存取时间和更改时间。 命令参数 参数 描述 -a 或–time=atime或–time=access或–time=use 只更改存取时间 -c 或–no-create 不建立任何文档 -d 使用指定的日期时间，而非现在的时间 -f 此参数将忽略不予处理，仅负责解决BSD版本touch指令的兼容性问题 -m 或–time=mtime或–time=modify 只更改变动时间 -r 把指定文档或目录的日期时间，统统设成和参考文档或目录的日期时间相同 -t 使用指定的日期时间，而非现在的时间 命令实例例一：创建不存在的文件 $ touch 1.txt 例二：更新1.txt的时间和2.txt时间戳相同 $ touch -r 1.txt 2.txt 例三：设定文件的时间戳 $ touch -t 201211142234.50 1.txt 例四：创建不存在的文件 $ touch 1.txt 说明： -t time 使用指定的时间值 time 作为指定文件相应时间戳记的新值．此处的 time规定为如下形式的十进制数: [[CC]YY]MMDDhhmm[.SS] 这里，CC为年数中的前两位，即”世纪数”；YY为年数的后两位，即某世纪中的年数．如果不给出CC的值，则touch 将把年数CCYY限定在1969–2068之内．MM为月数，DD为天将把年数CCYY限定在1969–2068之内．MM为月数，DD为天数，hh 为小时数(几点)，mm为分钟数，SS为秒数．此处秒的设定范围是0–61，这样可以处理闰秒．这些数字组成的时间是环境变量TZ指定的时区中的一个时 间．由于系统的限制，早于1970年1月1日的时间是错误的。","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"https://jiangxingye.github.io/tags/linux命令/"}]},{"title":"每天一个linux命令（8）: cp","slug":"linux-command（8）-cp","date":"2016-12-08T08:31:43.000Z","updated":"2019-09-02T13:03:00.031Z","comments":true,"path":"2016/12/08/linux-command（8）-cp/","link":"","permalink":"https://jiangxingye.github.io/2016/12/08/linux-command（8）-cp/","excerpt":"cp命令用来复制文件或者目录，是Linux系统中最常用的命令之一。一般情况下，shell会设置一个别名，在命令行下复制文件时，如果目标文件已经存在，就会询问是否覆盖，不管你是否使用-i参数。但是如果是在shell脚本中执行cp时，没有-i参数时不会询问是否覆盖。这说明命令行和shell脚本的执行方式有些不同。","text":"cp命令用来复制文件或者目录，是Linux系统中最常用的命令之一。一般情况下，shell会设置一个别名，在命令行下复制文件时，如果目标文件已经存在，就会询问是否覆盖，不管你是否使用-i参数。但是如果是在shell脚本中执行cp时，没有-i参数时不会询问是否覆盖。这说明命令行和shell脚本的执行方式有些不同。 命令格式$ cp [选项]... [-T] 源 目的 $ cp [选项]... -t 目录 源... 命令功能 将源文件复制至目标文件，或将多个源文件复制至目标目录。 命令参数 参数 描述 -a,–archive 为每个已存在的目标文件创建备份 -f, –force 如果目标文件无法打开则将其移除并重试(当 -n 选项存在时则不需再选此项) -i, –interactive 覆盖前询问(使前面的 -n 选项失效) -H 跟随源文件中的命令行符号链接 -l, –link 链接文件而不复制 -L, –dereference 总是跟随符号链接 -n, –no-clobber 不要覆盖已存在的文件(使前面的 -i 选项失效) -P, –no-dereference 不跟随源文件中的符号链接 -p 等于–preserve=模式,所有权,时间戳 -R, -r, –recursive 复制目录及目录内的所有项目 命令实例例一：复制单个文件到目标目录，文件在目标文件中存在，会询问覆盖 # 在没有带-a参数时，两个文件的时间是不一样的。在带了-a参数时，两个文件的时间是一致的。 $ cp 1.txt test5 例二：复制整个目录 # 注意目标目录存在与否结果是不一样的。目标目录存在时，整个源目录被复制到目标目录里面。 $ cp -a test3 test5 例三：复制的 log.log 建立一个连结档 log_link.log $ cp -s log.log log_link.log ```","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"https://jiangxingye.github.io/tags/linux命令/"}]},{"title":"每天一个linux命令（7）: mv","slug":"linux-command（7）-mv","date":"2016-12-07T07:55:20.000Z","updated":"2019-09-02T13:03:00.030Z","comments":true,"path":"2016/12/07/linux-command（7）-mv/","link":"","permalink":"https://jiangxingye.github.io/2016/12/07/linux-command（7）-mv/","excerpt":"mv命令是move的缩写，可以用来移动文件或者将文件改名（move (rename) files），是Linux系统下常用的命令，经常用来备份文件或者目录","text":"mv命令是move的缩写，可以用来移动文件或者将文件改名（move (rename) files），是Linux系统下常用的命令，经常用来备份文件或者目录 命令格式$ mv [选项] 源文件或目录 目标文件或目录 命令功能 视mv命令中第二个参数类型的不同（是目标文件还是目标目录），mv命令将文件重命名或将其移至一个新的目录中。当第二个参数类型是文件时，mv命令完成文件重命名，此时，源文件只能有一个（也可以是源目录名），它将所给的源文件或目录重命名为给定的目标文件名。当第二个参数是已存在的目录名称时，源文件或目录参数可以有多个，mv命令将各参数指定的源文件均移至目标目录中。在跨文件系统移动文件时，mv先拷贝，再将原有文件删除，而链至该文件的链接也将丢失。 命令参数 参数 描述 -b 若需覆盖文件，则覆盖前先行备份。 -f force 强制的意思，如果目标文件已经存在，不会询问而直接覆盖 -i 若目标文件 (destination) 已经存在时，就会询问是否覆盖！ -u 若目标文件已经存在，且 source 比较新，才会更新(update) -t –target-directory=DIRECTORY move all SOURCE arguments into DIRECTORY，即指定mv的目标目录，该选项适用于移动多个源文件到一个目录的情况，此时目标目录在前，源文件在后。 命令实例例一：文件改名 $ mv test.txt test1.txt 例二：移动文件 #将文件test.txt 移动到/usr/doc目录下 $ mv test.txt /usr/doc 例三：将文件log1.txt,log2.txt,log3.txt移动到目录/usr/doc中 $ mv log1.txt log2.txt log3.txt /usr/doc $ mv -t /usr/doc log1.txt log2.txt log3.txt 例四：将文件file1改名为file2，如果file2已经存在，则询问是否覆盖 $ mv -i log1.txt log2.txt 例五：将文件file1改名为file2，即使file2存在，也是直接覆盖掉 $ mv -f log3.txt log2.txt 例六：目录的移动 #将doc下的product目录移动到/usr/doc目录下 $ mv doc/product /usr/doc 例七：移动当前文件夹下的所有文件到上一级目录 $ mv * ../ 例八：文件被覆盖前做简单备份，前面加参数-b $ mv log1.txt -b log2.txt -b不接受参数，mv会去读取环境变量VERSION_CONTROL来作为备份策略。–backup该选项指定如果目标文件存在时的动作，共有四种备份策略： CONTROL=none或off : 不备份。 CONTROL=numbered或t：数字编号的备份 CONTROL=existing或nil：如果存在以数字编号的备份，则继续编号备份m+1…n：执行mv操作前已存在以数字编号的文件log2.txt.~1~，那么再次执行将产生log2.txt~2~，以次类推。如果之前没有以数字编号的文件，则使用下面讲到的简单备份。 CONTROL=simple或never：使用简单备份：在被覆盖前进行了简单备份，简单备份只能有一份，再次被覆盖时，简单备份也会被覆盖。","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"https://jiangxingye.github.io/tags/linux命令/"}]},{"title":"每天一个linux命令（6）: rmdir","slug":"linux-command（6）-rmdir","date":"2016-12-06T07:24:32.000Z","updated":"2019-09-02T13:03:00.030Z","comments":true,"path":"2016/12/06/linux-command（6）-rmdir/","link":"","permalink":"https://jiangxingye.github.io/2016/12/06/linux-command（6）-rmdir/","excerpt":"今天学习一下linux中命令： rmdir命令。rmdir是常用的命令，该命令的功能是删除空目录，一个目录被删除之前必须是空的。（注意，rm - r dir命令可代替rmdir，但是有很大危险性。）删除某目录时也必须具有对父目录的写权限。","text":"今天学习一下linux中命令： rmdir命令。rmdir是常用的命令，该命令的功能是删除空目录，一个目录被删除之前必须是空的。（注意，rm - r dir命令可代替rmdir，但是有很大危险性。）删除某目录时也必须具有对父目录的写权限。 命令格式$ rmdir [选项]... 目录... 命令功能 该命令从一个目录中删除一个或多个子目录项，删除某目录时也必须具有对父目录的写权限。 命令参数 参数 描述 - p 递归删除目录dirname，当子目录删除后其父目录为空时，也一同被删除。如果整个路径被删除或者由于某种原因保留部分路径，则系统在标准输出上显示相应的信息 -v, –verbose 显示指令执行过程 命令实例例一：rmdir 不能删除非空目录 $ rmdir doc rmdir: doc: 目录非空 例二：rmdir -p 当子目录被删除后使它也成为空目录的话，则顺便一并删除 $ rmdir -p log/product","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"https://jiangxingye.github.io/tags/linux命令/"}]},{"title":"每天一个linux命令（5）: rm","slug":"linux-command（5）-rm","date":"2016-12-05T05:40:38.000Z","updated":"2019-09-02T13:03:00.030Z","comments":true,"path":"2016/12/05/linux-command（5）-rm/","link":"","permalink":"https://jiangxingye.github.io/2016/12/05/linux-command（5）-rm/","excerpt":"rm是常用的命令，该命令的功能为删除一个目录中的一个或多个文件或目录，它也可以将某个目录及其下的所有文件及子目录均删除。对于链接文件，只是删除了链接，原有文件均保持不变。rm是一个危险的命令，使用的时候要特别当心，尤其对于新手，否则整个系统就会毁在这个命令（比如在/（根目录）下执行rm * -rf）。所以，我们在执行rm之前最好先确认一下在哪个目录，到底要删除什么东西，操作时保持高度清醒的头脑。","text":"rm是常用的命令，该命令的功能为删除一个目录中的一个或多个文件或目录，它也可以将某个目录及其下的所有文件及子目录均删除。对于链接文件，只是删除了链接，原有文件均保持不变。rm是一个危险的命令，使用的时候要特别当心，尤其对于新手，否则整个系统就会毁在这个命令（比如在/（根目录）下执行rm * -rf）。所以，我们在执行rm之前最好先确认一下在哪个目录，到底要删除什么东西，操作时保持高度清醒的头脑。 命令格式$ rm [选项] 文件... 命令功能 参数 描述 -f, –force 忽略不存在的文件，从不给出提示 -i, –interactive 进行交互式删除 -r, -R, –recursive 指示rm将参数中列出的全部目录和子目录均递归地删除 -v, –verbose 详细显示进行的步骤 –help 显示此帮助信息并退出 –version 输出版本信息并退出 命令实例例一：删除文件file，系统会先询问是否删除 $ rm file 例二：强行删除file，系统不再提示 $ rm -f file 例三：删除任何.log文件；删除前逐一询问确认 $ rm -i *.log 例四：对test文件夹进行递归删除 $ rm -r test 例五：递归删除，系统不用一一确认 $ rm -rf test 例六：删除以 -f 开头的文件 $ rm -- -f 例七：自定义回收站功能 #下面的操作过程模拟了回收站的效果，即删除文件的时候只是把文件放到一个临时目录中，这样在需要的时候还可以恢复过来。 $ myrm(){ D=/tmp/$(date +%Y%m%d%H%M%S); mkdir -p $D; mv &quot;$@&quot; $D &amp;&amp; echo &quot;moved to $D ok&quot;; }","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"https://jiangxingye.github.io/tags/linux命令/"}]},{"title":"每天一个linux命令（4）: mkdir","slug":"linux-command（4）-mkdir","date":"2016-12-04T01:27:32.000Z","updated":"2019-09-02T13:03:00.025Z","comments":true,"path":"2016/12/04/linux-command（4）-mkdir/","link":"","permalink":"https://jiangxingye.github.io/2016/12/04/linux-command（4）-mkdir/","excerpt":"linux mkdir 命令用来创建指定的名称的目录，要求创建目录的用户在当前目录中具有写权限，并且指定的目录名不能是当前目录中已有的目录。","text":"linux mkdir 命令用来创建指定的名称的目录，要求创建目录的用户在当前目录中具有写权限，并且指定的目录名不能是当前目录中已有的目录。 命令格式$ mkdir [选项] 目录... 命令功能 通过 mkdir 命令可以实现在指定位置创建以 DirName(指定的文件名)命名的文件夹或目录。要创建文件夹或目录的用户必须对所创建的文件夹的父文件夹具有写权限。并且，所创建的文件夹(目录)不能与其父目录(即父文件夹)中的文件名重名，即同一个目录下不能有同名的(区分大小写)。 命令参数 参数 说明 -m, –mode=模式 设定权限&lt;模式&gt; (类似 chmod)，而不是 rwxrwxrwx 减 umask -p, –parents 可以是一个路径名称。此时若路径中的某些目录尚不存在,加上此选项后,系统将自动建立好那些尚不存在的目录,即一次可以建立多个目录 -v, –verbose 每次创建新目录都显示信息 –help 显示此帮助信息并退出 –version 输出版本信息并退出 命令是实例例一：创建一个空目录 $ mkdir test 例二：递归创建多个目录 #在当前目录创建一个嵌套文件夹test1/test11 $ mkdir -p test1/test11 例三：创建权限为777的目录 $ mkdir -m 777 test 例四：创建新目录都显示信息 $ mkdir -v test 例五：一个命令创建项目的目录结构 $ mkdir -vp scf/{lib/,bin/,doc/{info,product},logs/{info,product},service/deploy/{info,product}} mkdir: 已创建目录 “scf” mkdir: 已创建目录 “scf/lib” mkdir: 已创建目录 “scf/bin” mkdir: 已创建目录 “scf/doc” mkdir: 已创建目录 “scf/doc/info” mkdir: 已创建目录 “scf/doc/product” mkdir: 已创建目录 “scf/logs” mkdir: 已创建目录 “scf/logs/info” mkdir: 已创建目录 “scf/logs/product” mkdir: 已创建目录 “scf/service” mkdir: 已创建目录 “scf/service/deploy” mkdir: 已创建目录 “scf/service/deploy/info” mkdir: 已创建目录 “scf/service/deploy/product” [root@localhost test]# tree scf/ scf/ |-- bin |-- doc | |-- info | `-- product |-- lib |-- logs | |-- info | `-- product `-- service `-- deploy |-- info `-- product 12 directories, 0 files","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"https://jiangxingye.github.io/tags/linux命令/"}]},{"title":"每天一个linux命令（3）: pwd","slug":"linux-command（3）-pwd","date":"2016-12-03T01:15:52.000Z","updated":"2019-09-02T13:03:00.018Z","comments":true,"path":"2016/12/03/linux-command（3）-pwd/","link":"","permalink":"https://jiangxingye.github.io/2016/12/03/linux-command（3）-pwd/","excerpt":"Linux中用 pwd 命令来查看”当前工作目录“的完整路径。 简单得说，每当你在终端进行操作时，你都会有一个当前工作目录。 在不太确定当前位置时，就会使用pwd来判定当前目录在文件系统内的确切位置。","text":"Linux中用 pwd 命令来查看”当前工作目录“的完整路径。 简单得说，每当你在终端进行操作时，你都会有一个当前工作目录。 在不太确定当前位置时，就会使用pwd来判定当前目录在文件系统内的确切位置。 命令格式$ pwd [选项] 命令功能 查看”当前工作目录“的完整路径 常用参数一般情况下不带任何参数如果目录是链接时：格式：pwd -P 显示出实际路径，而非使用链接（link） 的路径 实用实例例一：用 pwd 命令查看当前工作目录的完整路径 $ pwd /home/faker 例二：目录连接链接时，pwd -P 显示出实际路径，而非使用连接（link）路径；pwd显示的是连接路径 #目录为链接时，输出链接路径 $ pwd -L #目录为链接时，输出物理路径 $ pwd -P /home/faker 例三：当前目录被删除了，而pwd命令仍然显示那个目录 $ cd /opt/soft $ rm ../soft -rf $ pwd /opt/soft $ /bin/pwd /bin/pwd: couldnt find directory entry in “..” with matching i-node /home/faker","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"https://jiangxingye.github.io/tags/linux命令/"}]},{"title":"每天一个linux命令（2）: cd","slug":"linux-command（2）-cd","date":"2016-12-02T03:04:55.000Z","updated":"2019-09-02T13:03:00.012Z","comments":true,"path":"2016/12/02/linux-command（2）-cd/","link":"","permalink":"https://jiangxingye.github.io/2016/12/02/linux-command（2）-cd/","excerpt":"Linux cd 命令可以说是Linux中最基本的命令语句，其他的命令语句要进行操作，都是建立在使用 cd 命令上的。所以，学习Linux 常用命令，首先就要学好 cd 命令的使用方法技巧。","text":"Linux cd 命令可以说是Linux中最基本的命令语句，其他的命令语句要进行操作，都是建立在使用 cd 命令上的。所以，学习Linux 常用命令，首先就要学好 cd 命令的使用方法技巧。 命令格式$ cd [目录名] 命令功能 切换当前目录至目标目录 常用范例例一：进入系统根目录 $ cd / 例二：进入父级目录 $ cd .. $ cd ..// 例三：使用 cd 命令进入当前用户主目录 $ cd $ cd ~ 例四：跳转到指定目录 $ cd /usr/bin 例五：返回进入此目录之前所在的目录 $ cd - 例六：把上个命令的参数作为cd参数使用 $ cd !$","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"https://jiangxingye.github.io/tags/linux命令/"}]},{"title":"每天一个linux命令（1）: ls","slug":"linux-command（1）-ls","date":"2016-12-01T01:38:59.000Z","updated":"2019-09-02T13:03:00.006Z","comments":true,"path":"2016/12/01/linux-command（1）-ls/","link":"","permalink":"https://jiangxingye.github.io/2016/12/01/linux-command（1）-ls/","excerpt":"ls命令是linux下最常用的命令。ls命令就是list的缩写，缺省下ls用来打印出当前目录的清单，如果ls指定其他目录，那么就会显示指定目录里的文件及文件夹清单。 通过ls命令不仅可以查看linux文件夹包含的文件，而且可以查看文件权限(包括目录、文件夹、文件权限)、查看目录信息等等。ls命令在日常的linux操作中用的很多!","text":"ls命令是linux下最常用的命令。ls命令就是list的缩写，缺省下ls用来打印出当前目录的清单，如果ls指定其他目录，那么就会显示指定目录里的文件及文件夹清单。 通过ls命令不仅可以查看linux文件夹包含的文件，而且可以查看文件权限(包括目录、文件夹、文件权限)、查看目录信息等等。ls命令在日常的linux操作中用的很多! 命令格式$ ls [选项] [目录名] 命令功能列出目标目录中所有的子目录和文件。 常用参数 参数 说明 -a,–all 列出目录下的所有文件，包括以 . 开头的隐含文件 -A 同-a，但不列出“.”(表示当前目录)和“..”(表示当前目录的父目录)。 -c 配合 -lt 根据 ctime 排序及显示 ctime (文件状态最后更改的时间)配合 -lt：显示 ctime 但根据名称排序否则：根据 ctime 排序 -C 每栏由上至下列出项目 -color[=WHEN] 控制是否使用色彩分辨文件。WHEN 可以是’never’、’always’或’auto’其中之一 -d,–directory 将目录象文件一样显示，而不是显示其下的文件。 -D,–dired 产生适合 Emacs 的 dired 模式使用的结果 -f 对输出的文件不进行排序，-aU 选项生效，-lst 选项失效 -g 类似 -l,但不列出所有者 -G, –no-group 不列出任何有关组的信息 -h,–human-readable 以容易理解的格式列出文件大小 (例如 1K 234M 2G) –si 类似 -h,但文件大小取 1000 的次方而不是 1024 -H, –dereference-command-line 使用命令列中的符号链接指示的真正目的地 –indicator-style=&lt;方式&gt; 指定在每个项目名称后加上指示符号&lt;方式&gt;：none (默认)，classify (-F)，file-type (-p) -i, –inode 印出每个文件的 inode 号 -I,–ignore=样式 不印出任何符合 shell 万用字符&lt;样式&gt;的项目 -k 即 –block-size=1K,以 k 字节的形式表示文件的大小 -l 除了文件名之外，还将文件的权限、所有者、文件大小等信息详细列出来。 -L, –dereference -m 所有项目以逗号分隔，并填满整行行宽 -o 类似 -l,显示文件的除组信息外的详细信息。 -r, –reverse 依相反次序排列 -R, –recursive 同时列出所有子目录层 -s,–size 以块大小为单位列出所有文件的大小 -S 根据文件大小排序 –sort=WORD 可选用的 WORD 和它们代表的相应选项： extension -X status -cnone -U time -tsize -S atime -utime -t access -uversion -v use -u -t 以文件修改时间排序 -u 配合 -lt:显示访问时间而且依访问时间排序配合 -l:显示访问时间但根据名称排序否则：根据访问时间排序 -U 不进行排序;依文件系统原有的次序列出项目 -v 根据版本进行排序 -w, –width=COLS 自行指定屏幕宽度而不使用目前的数值 -x 逐行列出项目而不是逐栏列出 -X 根据扩展名排序 -1 每行只列出一个文件 –help 显示此帮助信息并离开 –version 显示版本信息并离开 常用范例例一：列出/home/faker/ 文件夹下的所有文件和目录的详细资料 $ ls -l -R /home/faker $ ls -lR /home/faker 例二：列出当前目录中所有以“t”开头的目录的详细内容，可以使用如下命令 $ ls -l t* 例三：只列出文件下的子目录 $ ls -F /opt/soft |grep /$ 例四：列出文件下的子目录详细情况 $ ls -l /opt/soft | grep &quot;^d&quot; 例五：列出目前工作目录下所有名称是s 开头的文件，愈新的排愈后面，可以使用如下命令 $ ls -ltr s* 例六：列出目前工作目录下所有档案及目录;目录于名称后加”/“, 可执行档于名称后加* $ ls -AF 例七：计算当前目录下的文件数和目录数 $ ls -l * |grep &quot;^-&quot;|wc -l ---文件个数 $ ls -l * |grep &quot;^d&quot;|wc -l ---目录个数 例八：在ls中列出文件的绝对路径 $ ls | sed &quot;s:^:`pwd`/:&quot; 例九：列出当前目录下的所有文件（包括隐藏文件）的绝对路径， 对目录不做递归 $ find $PWD -maxdepth 1 | xargs ls -ld 例十：列出当前目录下的所有文件（包括隐藏文件）的绝对路径， 对目录不做递归 $ find $PWD -maxdepth 1 | xargs ls -ld 例十：递归列出当前目录下的所有文件（包括隐藏文件）的绝对路径 $ find $PWD | xargs ls -ld 例十：指定文件时间输出格式 $ ls -tl --time-style=full-iso $ ls -ctl --time-style=long-iso 2016-08-05 22:17:06.020535551 +0800 2016-10-29 12:03","categories":[{"name":"运维","slug":"运维","permalink":"https://jiangxingye.github.io/categories/运维/"}],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"https://jiangxingye.github.io/tags/linux命令/"}]},{"title":"jQuery之checkbox|radio|select操作","slug":"jQuery-checkbox-radio-select","date":"2016-11-23T08:19:34.000Z","updated":"2019-09-02T13:02:59.984Z","comments":true,"path":"2016/11/23/jQuery-checkbox-radio-select/","link":"","permalink":"https://jiangxingye.github.io/2016/11/23/jQuery-checkbox-radio-select/","excerpt":"jQuery1.6中添加了prop方法,看起来和用起来都和attr方法一样,但是在一些特殊情况下,attribute和properties的区别非常大,在jQuery1.6之前，.attr()方法在获取一些attributes的时候使用了property值，这样会导致一些不一致的行为。在jQuery1.6中，.prop()方法提供了一中明确的获取property值得方式，这样.attr()方法仅返回attributes。 –摘自jQuery API文档","text":"jQuery1.6中添加了prop方法,看起来和用起来都和attr方法一样,但是在一些特殊情况下,attribute和properties的区别非常大,在jQuery1.6之前，.attr()方法在获取一些attributes的时候使用了property值，这样会导致一些不一致的行为。在jQuery1.6中，.prop()方法提供了一中明确的获取property值得方式，这样.attr()方法仅返回attributes。 –摘自jQuery API文档 checkbox&lt;input type=&#39;checkbox&#39; value=&#39;1&#39;/&gt; &lt;input type=&#39;checkbox&#39; value=&#39;2&#39;/&gt; &lt;input type=&#39;checkbox&#39; value=&#39;3&#39;/&gt; $(&quot;input[type=checkbox]&quot;) //获取所有的checkbox $(&quot;input[type=checkbox]:checked&quot;) //获取所有的被选中的checkbox $(&quot;input[type=checkbox]:not(:checked)&quot;) //获取所有未被选中的checkbox $(&quot;input[type=checkbox]&quot;).not(&quot;:checked&quot;) //获取所有未被选中的checkbox $(&quot;input[type=checkbox]:first&quot;) //获取第一个checkbox的value值 $(&quot;input[type=checkbox]:checked&quot;).length //获取被选中checkbox的数量 $(&quot;input[type=checkbox]:first&quot;).prop(&quot;checked&quot;) //判断第一个checkbox是否被选中 $(&quot;input[type=checkbox]:first&quot;).prop(&quot;checkbox&quot;,true) //选中第一个checkbox $(&quot;input[type=checkbox]:not(:checked)&quot;).prop(&quot;checked&quot;,true) //全选 $(&quot;input[type=checkbox]:checkbox&quot;).prop(&quot;checked&quot;,false) //都不选中 //反选 $(&quot;input[type=checkbox]&quot;).each(function(){ if($(this).prop(&quot;checked&quot;)){ $(this).prop(&quot;checked&quot;,false); }else{ $(this).prop(&quot;checked&quot;,true); } }) radio&lt;input type=&#39;radio&#39; name=&#39;rank&#39; value=&#39;1&#39; /&gt; &lt;input type=&#39;radio&#39; name=&#39;rank&#39; value=&#39;2&#39; /&gt; &lt;input type=&#39;radio&#39; name=&#39;rank&#39; value=&#39;3&#39; /&gt; $(&quot;input[type=radio]&quot;) //获取所有的radio $(&quot;input[type=radio]:checked&quot;) //获取被选中的radio $(&quot;input[type=radio]:not(:checkbox)&quot;) //获取所有没有被选中的radio $(&quot;input[type=radio]:checked&quot;).val() //获取被选中的radio的value值 $(&quot;input[type=radio]:first&quot;).prop(&quot;checked&quot;) //判断第一个radio是否被选中 $(&quot;input[type=radio]:first&quot;).prop(&quot;checked&quot;,true) //选中第一个radio select&lt;select&gt; &lt;option value=&#39;1&#39;&gt;1&lt;/option&gt; &lt;option value=&#39;2&#39;&gt;2&lt;/option&gt; &lt;option value=&#39;4&#39;&gt;3&lt;/option&gt; &lt;/select&gt; $(&quot;select option:selected&quot;) //获取被选中的option $(&quot;select&quot;).val() //获取选中option的value值 $(&quot;select option:selected&quot;).text() //获取被选中的option的text值 $(&quot;select option:first&quot;).prop(&quot;selected&quot;) //判断第一个option是否被选中 $(&quot;select option:first&quot;).prop(&quot;selected&quot;,true) //选中第一个option $(&quot;select option:selected&quot;).prop(&quot;selected&quot;,false) //取消当前选中,然后默认选中第一个","categories":[{"name":"大前端","slug":"大前端","permalink":"https://jiangxingye.github.io/categories/大前端/"}],"tags":[{"name":"jQuery","slug":"jQuery","permalink":"https://jiangxingye.github.io/tags/jQuery/"}]},{"title":"jQuery选择器与节点操作","slug":"jQuery-selector","date":"2016-11-22T09:11:48.000Z","updated":"2019-09-02T13:02:59.988Z","comments":true,"path":"2016/11/22/jQuery-selector/","link":"","permalink":"https://jiangxingye.github.io/2016/11/22/jQuery-selector/","excerpt":"jQuery 是一个 JavaScript 函数库。jQuery的语法设计使得许多操作变得容易，如操作文档对象（document）、选择文档对象模型（DOM）元素、创建动画效果、处理事件、以及开发Ajax程序。jQuery也提供了给开发人员在其上创建插件的能力。这使开发人员可以对底层交互与动画、高级效果和高级主题化的组件进行抽象化。","text":"jQuery 是一个 JavaScript 函数库。jQuery的语法设计使得许多操作变得容易，如操作文档对象（document）、选择文档对象模型（DOM）元素、创建动画效果、处理事件、以及开发Ajax程序。jQuery也提供了给开发人员在其上创建插件的能力。这使开发人员可以对底层交互与动画、高级效果和高级主题化的组件进行抽象化。 jQuery获取元素元素选择器//元素选择器 &lt;div &gt; $(&quot;div&quot;) id选择器//id选择器 &lt;div id=&#39;id&#39;&gt; $(&quot;#id&quot;) $(&quot;div#id&quot;) class选择器//class选择器 &lt;div class=&#39;class&#39;&gt; $(&quot;.class&quot;) $(&quot;div.class&quot;) 属性过滤选择器&lt;li class=&#39;check&#39; type=&#39;li_01&#39;&gt;&lt;/li&gt; &lt;li type=&#39;li_02&#39;&gt;&lt;/li&gt; &lt;li type=&#39;li_03&#39;&gt;&lt;/li&gt; //通过属性获取 如果属性值为有特殊字符，一定要加引号 $(&quot;[type]&quot;) //获取有type属性的元素 $(&quot;[type=&#39;li_01&#39;]&quot;) //获取type值等于&#39;li_01&#39;的元素 $(&quot;[type!=&#39;li_01&#39;]&quot;) //获取type值不等于&#39;li_01&#39;的元素 $(&quot;[type*=&#39;li&#39;]&quot;) //模糊匹配 获取type值包含&#39;li&#39;的元素 $(&quot;[type^=&#39;li&#39;]&quot;) //模糊匹配 获取type值以&#39;li&#39;开始的元素 $(&quot;[type$=&#39;01&#39;]&quot;) //模糊匹配 获取type值以&#39;01&#39;结尾的元素 $(&quot;li[class=&#39;check&#39;][type]&quot;) //获取多个条件同时满足的元素 * 选择器//遍历form下的所有元素,将其margin设置0 $(&#39;form *&#39;).css(&#39;margin&#39;,&#39;0px&#39;) 并列选择器$(&#39;p, div&#39;).css(&#39;color&#39;,&#39;red&#39;); //将p元素和div元素的字体颜色设置为red 层叠选择器&lt;div class=&#39;a&#39;&gt; &lt;!-- 父级div --&gt; &lt;div class=&#39;a1&#39;&gt; &lt;!-- 子级div1 --&gt; &lt;div class=&#39;a11&#39;&gt;&lt;/div&gt; &lt;!-- 孙级div1 --&gt; &lt;/div&gt; &lt;div class=&#39;a2&#39;&gt;&lt;/div&gt; &lt;!-- 子级div2 --&gt; &lt;div class=&#39;a3&#39;&gt;&lt;/div&gt; &lt;!-- 子级div3 --&gt; &lt;span&gt;&lt;/span&gt; &lt;!-- 子级span1 --&gt; &lt;/div&gt; $(&quot;.a div&quot;) //选择class=a的元素下所有的div 即选择到子级div1,2,3 孙级div1 $(&quot;.a &gt; div&quot;) //选择class=a的元素的所有子div元素, 即选择到子级div1,2,3; $(&quot;div + span&quot;) //选择所有的div元素的下一个input元素节点,即选择到:子级div3 $(&quot;.a1 ~ div&quot;) //同胞选择器,返回class为a2的标签元素的所有属于同一个父元素的div标签,即div1,2,3 基本过滤选择器&lt;ul&gt; &lt;li&gt;&lt;/li&gt; &lt;li&gt;&lt;/li&gt; &lt;li&gt;&lt;/li&gt; &lt;li&gt;&lt;/li&gt; &lt;li&gt;&lt;/li&gt; &lt;/ul&gt; $(&quot;li:first&quot;) //选择所有li元素的第一个 $(&quot;li:last&quot;) //选择所有li元素的最后一个 $(&quot;li:even&quot;) //选择所有li元素的第0,2,4... ...个元素(序号从0开始) $(&quot;li:odd&quot;) //选择所有li元素的第1,3,5... ...个元素 $(&quot;li:eq(2)&quot;) //选择所有li元素中的第三个(即序号为2) $(&quot;li:gt(3)&quot;) //选择所有li元素中序号大于3的li元素 $(&quot;li:ll(2)&quot;) //选择所有li元素中序号小于2的li元素 &lt;input type=&quot;checkbox&quot; /&gt; &lt;input type=&quot;checkbox&quot; /&gt; $(&quot;input[type=&#39;checkbox&#39;]:checked&quot;) //获取所有已被选中的type等于checkbox的input元素 $(&quot;input[type=&#39;checkbox&#39;]:not(:checked)&quot;) //获取所有未被选中的type等于checkbox的input元素 内容过滤器$(&quot;div:contains(&#39;Faker&#39;)&quot;) //选择所有div中含有Faker文本的元素 $(&quot;div:empty&quot;) //选择所有div中为空(不包含任何元素/文本)的元素 $(&quot;div:has(&#39;p&#39;)&quot;) //选择所有div中包含p元素的元素 $(&quot;div:parent&quot;) //选择所有的含有子元素或文本的div 可视化过滤器$(&quot;div:hidden&quot;) //选择所有被hidden的div元素 $(&quot;div:not(:hidden)&quot;) //选择所有没有被hidden的div元素 $(&quot;div:visible&quot;) //所有可视化的div元素 $(&quot;div:not(:visible)&quot;) //所有非可视化的div元素 子元素过滤器&lt;body&gt; &lt;div class=&#39;d1&#39;&gt; &lt;div class=&#39;d11&#39;&gt; &lt;div class=&#39;d111&#39;&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/body&gt; $(&quot;body div:first-child&quot;) //返回所有的body元素下 所有div 为父元素的第一个元素 的元素. //:first 与 :first-child 的区别用法 //$(&quot;body div:first&quot;)只匹配到第一个合适的元素 即只匹配到 d1 //$(&quot;body div:first-child&quot;) 匹配所有合适的元素:d1是body的第一个元素,d11是d1的第一个元素.. //所以匹配到d1,d11,d111 $(&quot;div span:last-child&quot;) //返回所有的body元素下 所有div 为父元素的最后一个元素 的元素. //:last 与 :last-child 的区别参考first $(&quot;div button:only-child&quot;) //如果button是它父级元素的唯一子元素,此button将会被匹配 表单元素选择器$(&quot;:input&quot;) //选择所有的表单输入元素，包括input, textarea, select 和 button $(&quot;:text&quot;) //选择所有的text input元素 $(&quot;:password&quot;) //选择所有的password input元素 $(&quot;:radio&quot;) //选择所有的radio input元素 $(&quot;:checkbox&quot;) //选择所有的checkbox input元素 $(&quot;:submit&quot;) //选择所有的submit input元素 $(&quot;:image&quot;) //选择所有的image input元素 $(&quot;:reset&quot;) //选择所有的reset input元素 $(&quot;:button&quot;) //选择所有的button input元素 $(&quot;:file&quot;) //选择所有的file input元素 $(&quot;:hidden&quot;) //选择所有类型为hidden的input元素或表单的隐藏域 表单元素过滤器$(&quot;:enabled&quot;) //选择所有的可操作的表单元素 $(&quot;:disabled&quot;) //选择所有的不可操作的表单元素 $(&quot;:checked&quot;) //选择所有的被checked的表单元素 $(&quot;select option:selected&quot;) //选择所有的select 的子元素中被selected的元素 节点操作获取和操作节点属性&lt;a href=&#39;index.html&#39; data-type=&#39;a&#39; style=&quot;color:red;&quot;&gt;index&lt;/a&gt; &lt;input value=&#39;user&#39; /&gt; $(&quot;a&quot;).attr(&quot;href&quot;); //获取href属性值 $(&quot;a&quot;).attr(&quot;href&quot;,&quot;about.html&quot;); //设置href属性值 $(&quot;a&quot;).data(&quot;type&quot;); //获取data-type属性值 $(&quot;a&quot;).css(&quot;color&quot;); //通过key(color/display/....)获取css值 $(&quot;a&quot;).css(&quot;color&quot;,&quot;black&quot;); //通过key/value 设置css属性 $(&quot;a&quot;).text(); //获取a的文本节点值 $(&quot;a&quot;).text(&quot;Index.html&quot;); //设置a的文本节点值 $(&quot;input&quot;).val(); //获取input的value值 $(&quot;input&quot;).val(&quot;username&quot;); //设置input的value值 插入节点的方法&lt;div class=&quot;head&quot;&gt; &lt;span&gt;Faker&lt;span&gt; &lt;/div&gt; $(&quot;.head&quot;).append(&quot;&lt;span&gt;hello&lt;/span&gt;&quot;) //在.head中的最后插入一段html //结果: &lt;div class=&quot;head&quot;&gt;&lt;span&gt;Faker&lt;/span&gt;&lt;span&gt;hello&lt;/span&gt;&lt;/div&gt; $(&quot;&lt;span&gt;hello&lt;/span&gt;&quot;).appendTo(&quot;.head&quot;) //在.head中的最后插入一段html, //结果: &lt;div class=&quot;head&quot;&gt;&lt;span&gt;Faker&lt;/span&gt;&lt;span&gt;hello&lt;/span&gt;&lt;/div&gt; $(&quot;.head&quot;).prepend(&quot;&lt;span&gt;hello&lt;/span&gt;&quot;) //在.head中的开始插入一段html, //结果: &lt;div class=&quot;head&quot;&gt;&lt;span&gt;hello&lt;/span&gt;&lt;span&gt;Faker&lt;/span&gt;&lt;/div&gt; $(&quot;&lt;span&gt;hello&lt;/span&gt;&quot;).prependTo(&quot;.head&quot;) //在.head中的开始插入一段html, //结果: &lt;div class=&quot;head&quot;&gt;&lt;span&gt;hello&lt;/span&gt;&lt;span&gt;Faker&lt;/span&gt;&lt;/div&gt; $(&quot;.head *:first&quot;).after(&quot;&lt;span&gt;hello&lt;/span&gt;&quot;) //在.head中的第一个元素后插入一段html, //结果: &lt;div class=&quot;head&quot;&gt;&lt;span&gt;Faker&lt;/span&gt;&lt;span&gt;hello&lt;/span&gt;&lt;/div&gt; $(&quot;&lt;span&gt;hello&lt;/span&gt;&quot;).insertAfter(&quot;.head *:first&quot;) //在.head中的第一个元素后插入一段html, //结果: &lt;div class=&quot;head&quot;&gt;&lt;span&gt;Faker&lt;/span&gt;&lt;span&gt;hello&lt;/span&gt;&lt;/div&gt; $(&quot;.head *:first&quot;).before(&quot;&lt;span&gt;hello&lt;/span&gt;&quot;) //在.head中的第一个元素前插入一段html, //结果: &lt;div class=&quot;head&quot;&gt;&lt;span&gt;hello&lt;/span&gt;&lt;span&gt;Faker&lt;/span&gt;&lt;/div&gt; $(&quot;&lt;span&gt;hello&lt;/span&gt;&quot;).insertBefore(&quot;.head *:first&quot;) //在.head中的第一个元素后插入一段html, //结果: &lt;div class=&quot;head&quot;&gt;&lt;span&gt;hello&lt;/span&gt;&lt;span&gt;Faker&lt;/span&gt;&lt;/div&gt; $.load()方法 在指定位置加载请求回来的html页面 &lt;div class=&quot;head&quot;&gt; &lt;/div&gt; $(&quot;.head&quot;).load(url[,data][,callback]) url: 请求HTML页面的URL地址 data(可选): 请求的key/value参数 callback(可选) 请求完成的回调函数","categories":[{"name":"大前端","slug":"大前端","permalink":"https://jiangxingye.github.io/categories/大前端/"}],"tags":[{"name":"jQuery","slug":"jQuery","permalink":"https://jiangxingye.github.io/tags/jQuery/"}]},{"title":"web.xml详解","slug":"web-xml","date":"2016-10-24T02:10:45.000Z","updated":"2019-09-02T13:02:59.977Z","comments":true,"path":"2016/10/24/web-xml/","link":"","permalink":"https://jiangxingye.github.io/2016/10/24/web-xml/","excerpt":"web.xml文件是用来配置:欢迎页、servlet、filter、listener等的. 当你的web项目工程没用到这些时,你可以不用web.xml文件来配置你的web工程。如果项目中有多项标签,其加载顺序依次是:context-param &gt;&gt; listener &gt;&gt; filter &gt;&gt; servlet(同类多个节点出现顺序依次加载)","text":"web.xml文件是用来配置:欢迎页、servlet、filter、listener等的. 当你的web项目工程没用到这些时,你可以不用web.xml文件来配置你的web工程。如果项目中有多项标签,其加载顺序依次是:context-param &gt;&gt; listener &gt;&gt; filter &gt;&gt; servlet(同类多个节点出现顺序依次加载) ​web.xml先读取context-param和listener这两种节点； 然后容器创建一个ServletContext(上下文)，应用于整个项目； 容器会将读取到的context-param转化为键值对并存入servletContext； 根据listener创建监听； 容器会读取，根据指定的类路径来实例化过滤器； 此时项目初始化完成； 在发起第一次请求是，servlet节点才会被加载实例化。 参数设置context-paramcontext-param节点是web.xml中用于配置应用于整个web项目的​上下文。包括两个子节点，其中param-name 设定上下文的参数名称。必须是唯一名称；param-value 设定的参数名称的值。 读取节点的方法如下： ${initParam.参数名} Servlet中String paramValue=getServletContext().getInitParameter(“参数名”)​ web.xml中配置spring必须使用listener节点，但context-param节点可有可无，如果缺省则默认contextConfigLocation路径为“/WEB-INF/applicationContext.xml”；如果有多个xml文件，使用”,“分隔 listener&lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.request.RequestContextListener&lt;/listener-class&gt; &lt;/listener&gt; 为web应用程序定义监听器，监听器用来监听各种事件，比如：application和session事件，所有的监听器按照相同的方式定义，功能取决去它们各自实现的接口，常用的Web事件接口有如下几个：ServletContextListener：用于监听Web应用的启动和关闭；ServletContextAttributeListener：用于监听ServletContext范围（application）内属性的改变；ServletRequestListener：用于监听用户的请求；ServletRequestAttributeListener：用于监听ServletRequest范围（request）内属性的改变；HttpSessionListener：用于监听用户session的开始和结束；HttpSessionAttributeListener：用于监听HttpSession范围（session）内属性的改变。 配置Listener只要向Web应用注册Listener实现类即可，无序配置参数之类的东西，因为Listener获取的是Web应用ServletContext（application）的配置参数。为Web应用配置Listener的两种方式： 使用@WebListener修饰Listener实现类即可。 在web.xml文档中使用进行配置。 servletservlet即配置所需用的servlet，用于处理及响应客户的请求。容器的Context对象对请求路径(URL)做出处理，去掉请求URL的上下文路径后，按路径映射规则和Servlet映射路径（）做匹配，如果匹配成功，则调用这个Servlet处理请求。 为Servlet命名：&lt;servlet&gt; &lt;servlet-name&gt;servlet&lt;/servlet-name&gt; &lt;servlet-class&gt;org.whatisjava.TestServlet&lt;/servlet-class&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; 为Servlet定制URL&lt;servlet-mapping&gt; &lt;servlet-name&gt;servlet&lt;/servlet-name&gt; &lt;url-pattern&gt;*.do&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; Load-on-startupLoad-on-startup 元素在web应用启动的时候指定了servlet被加载的顺序，它的值必须是一个整数。如果它的值是一个负整数或是这个元素不存在，那么容器会在该servlet被调用的时候，加载这个servlet 。如果值是正整数或零，容器在配置的时候就加载并初始化这个servlet，容器必须保证值小的先被加载。如果值相等，容器可以自动选择先加载谁。当值为0或者大于0时，表示容器在应用启动时就加载这个servlet；当是一个负数时或者没有指定时，则指示容器在该servlet被选择时才加载。正数的值越小，启动该servlet的优先级越高。 filter设置过滤器:如编码过滤器,过滤所有资源 &lt;filter&gt; &lt;filter-name&gt;encodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;UTF-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;forceEncoding&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;encodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; session设置会话(Session)过期时间,其中时间以分钟为单位,加入设置60分超时: &lt;session-config&gt; &lt;session-timeout&gt;60&lt;/session-timeout&gt; &lt;/session-config&gt; welcom-file-list&lt;welcome-file-list&gt; &lt;welcome-file&gt;index.jsp&lt;/welcome-file&gt; &lt;welcome-file&gt;index.html&lt;/welcome-file&gt; &lt;/welcome-file-list&gt; PS:指定了两个欢迎页面,显示时按顺序从第一个找起，如果第一个存在，就显示第一个，后面的不起作用。如果第一个不存在，就找第二个，以此类推。如果都没有就404. 关于欢迎页面：访问一个网站时，默认看到的第一个页面就叫欢迎页，一般情况下是由首页来充当欢迎页的。一般情况下，我们会在web.xml中指定欢迎页。但 web.xml并不是一个Web的必要文件，没有web.xml，网站仍然是可以正常工作的。只不过网站的功能复杂起来后，web.xml的确有非常大用处，所以，默认创建的动态web工程在WEB-INF文件夹下面都有一个web.xml文件。 error-page&lt;!-- 错误码 --&gt; &lt;error-page&gt; &lt;error-code&gt;404&lt;/error-code&gt; &lt;location&gt;/error404.jsp&lt;/location&gt; &lt;/error-page&gt; &lt;!-- 错误类型 --&gt; &lt;error-page&gt; &lt;exception-type&gt;java.lang.Exception&lt;exception-type&gt; &lt;location&gt;/exception.jsp&lt;location&gt; &lt;/error-page&gt;","categories":[{"name":"后端","slug":"后端","permalink":"https://jiangxingye.github.io/categories/后端/"}],"tags":[{"name":"java","slug":"java","permalink":"https://jiangxingye.github.io/tags/java/"},{"name":"javaee","slug":"javaee","permalink":"https://jiangxingye.github.io/tags/javaee/"}]},{"title":"PostgreSQL常用操作","slug":"PostgreSQL-2","date":"2016-10-12T12:27:07.000Z","updated":"2019-09-02T13:02:59.981Z","comments":true,"path":"2016/10/12/PostgreSQL-2/","link":"","permalink":"https://jiangxingye.github.io/2016/10/12/PostgreSQL-2/","excerpt":"控制台命令\\h: #查看SQL命令的解释，比如\\h select。 \\?: #查看psql命令列表。 \\l: #列出所有数据库。 \\c [database_name]: #连接其他数据库。 \\d: #列出当前数据库的所有表格。 \\d [table_name]: #列出某一张表格的结构。 \\du: #列出所有用户。 \\e: #打开文本编辑器。 \\conninfo: #列出当前数据库和连接的信息。","text":"控制台命令\\h: #查看SQL命令的解释，比如\\h select。 \\?: #查看psql命令列表。 \\l: #列出所有数据库。 \\c [database_name]: #连接其他数据库。 \\d: #列出当前数据库的所有表格。 \\d [table_name]: #列出某一张表格的结构。 \\du: #列出所有用户。 \\e: #打开文本编辑器。 \\conninfo: #列出当前数据库和连接的信息。 数据库操作基本的数据库操作，就是使用一般的SQL语言 # 创建新表 CREATE TABLE user_tbl(name VARCHAR(20), signup_date DATE); # 插入数据 INSERT INTO user_tbl(name, signup_date) VALUES(&#39;张三&#39;, &#39;2013-12-22&#39;); # 选择记录 SELECT * FROM user_tbl; # 更新数据 UPDATE user_tbl set name = &#39;李四&#39; WHERE name = &#39;张三&#39;; # 删除记录 DELETE FROM user_tbl WHERE name = &#39;李四&#39; ; # 添加栏位 ALTER TABLE user_tbl ADD email VARCHAR(40); # 更新结构 ALTER TABLE user_tbl ALTER COLUMN signup_date SET NOT NULL; # 更名栏位 ALTER TABLE user_tbl RENAME COLUMN signup_date TO signup; # 删除栏位 ALTER TABLE user_tbl DROP COLUMN email; # 表格更名 ALTER TABLE user_tbl RENAME TO backup_tbl; # 删除表格 DROP TABLE IF EXISTS backup_tbl;","categories":[{"name":"数据库","slug":"数据库","permalink":"https://jiangxingye.github.io/categories/数据库/"}],"tags":[{"name":"PostgreSQL","slug":"PostgreSQL","permalink":"https://jiangxingye.github.io/tags/PostgreSQL/"}]},{"title":"PostgreSQL初体验","slug":"PostgreSQL-1","date":"2016-10-12T11:49:40.000Z","updated":"2019-09-02T13:02:59.980Z","comments":true,"path":"2016/10/12/PostgreSQL-1/","link":"","permalink":"https://jiangxingye.github.io/2016/10/12/PostgreSQL-1/","excerpt":"创建操作系统用户创建一个新的Linux用户：dbuser $sudo adduser dbuser #创建一个新的Linux用户：dbuser","text":"创建操作系统用户创建一个新的Linux用户：dbuser $sudo adduser dbuser #创建一个新的Linux用户：dbuser 登录PostgreSQL控制台切换到postgres用户 $sudo su - postgres #切换到postgres用户 系统用户postgres以同名数据库用户的身份，登录数据库 $psql #系统用户postgres以同名数据库用户的身份，登录数据库 成功登录到控制台后，显示 postgres=# 注意：后面分号不能省略 \\password postgres #给postgres用户设置密码 创建数据库用户dbuser CREATE USER dbuser WITH PASSWORD &#39;dbuser&#39;; #创建数据库用户dbuser 创建用户数据库，这里为exampledb，并指定所有者为dbuser。 CREATE DATABASE exampledb OWNER dbuser; #创建用户数据库，这里为exampledb，并指定所有者为dbuser。 将exampledb数据库的所有权限都赋予dbuser GRANT ALL PRIVILEGES ON DATABASE exampledb to dbuser; #将exampledb数据库的所有权限都赋予dbuser 推出控制台（也可以直接按ctrl+D） \\q #退出控制台","categories":[{"name":"数据库","slug":"数据库","permalink":"https://jiangxingye.github.io/categories/数据库/"}],"tags":[{"name":"PostgreSQL","slug":"PostgreSQL","permalink":"https://jiangxingye.github.io/tags/PostgreSQL/"}]},{"title":"PostgreSQL的介绍与安装","slug":"PostgreSQL-3","date":"2016-10-12T07:44:16.000Z","updated":"2019-09-02T13:02:59.982Z","comments":true,"path":"2016/10/12/PostgreSQL-3/","link":"","permalink":"https://jiangxingye.github.io/2016/10/12/PostgreSQL-3/","excerpt":"由于工作认识了PostgreSQL，在此系统学习一下这个数据库，本文除博主实践所得以外，大量译于 官方文档 PostgreSQL是什么 PostgreSQL 是一个基于 POSTGRES, Version 4.2 的对象关系数据库系统（ORDBMS），由加州大学伯克利分校计算机科学系开发。PostgreSQL 是一个开源的数据库，因为自由许可，任何人都可以免费的使用、修改、分发 PostgreSQL 数据库用于任何目的。","text":"由于工作认识了PostgreSQL，在此系统学习一下这个数据库，本文除博主实践所得以外，大量译于 官方文档 PostgreSQL是什么 PostgreSQL 是一个基于 POSTGRES, Version 4.2 的对象关系数据库系统（ORDBMS），由加州大学伯克利分校计算机科学系开发。PostgreSQL 是一个开源的数据库，因为自由许可，任何人都可以免费的使用、修改、分发 PostgreSQL 数据库用于任何目的。 它支持大部分的SQL标准并提供了许多流行的功能： 复杂查询（complex queries） 外键（foreign keys） 触发器（triggers） 可更新的视图（updatable views） 事务完整性（transactional integrity） 多版本并发控制（multiversion concurrency control） 用户也可以给PostgreSQL扩展很多东西，比如： 数据类型（data types） 函数（functions） 运算符（operators） 聚合函数（aggregate functions） 索引方法（index methods） 安装博主开发环境： 系统 ：深度Linux 15.3 桌面版 PostgreSQL ：9.4 通过apt-get安装$ apt-get install postgresql-9.4 仓库有许多不同的包（包括第三方插件），最常见、最重要的包（根据需要替换版本号）： postgresql-client-9.4 - 客户端库和二进制文件 postgresql-9.4 - 核心数据库服务器 postgresql-contrib-9.4 - 提供额外的模块 libpq-dev - C语言前端开发库和头文件 postgresql-server-dev-9.4 - C语言后端开发库和头文件 pgadmin3 - pgAdmin III 图形化管理工具","categories":[{"name":"数据库","slug":"数据库","permalink":"https://jiangxingye.github.io/categories/数据库/"}],"tags":[{"name":"PostgreSQL","slug":"PostgreSQL","permalink":"https://jiangxingye.github.io/tags/PostgreSQL/"}]},{"title":"FreeMarker语法详解","slug":"FreeMarker","date":"2016-10-05T03:58:50.000Z","updated":"2019-09-02T13:02:59.984Z","comments":true,"path":"2016/10/05/FreeMarker/","link":"","permalink":"https://jiangxingye.github.io/2016/10/05/FreeMarker/","excerpt":"FreeMarker是一款 模板引擎 :即一种基于模板和要改变的数据，并用来生成输出文本（HTML网页、电子邮件、配置文件、源代码等）的通用工具。FreeMarker模板文件主要有4部分组成 文本，直接输出的部分 注释，即&lt;#–…–&gt;格式不会输出 插值（Interpolation）：即${..}或者#{..}格式的部分,将使用数据模型中的部分替代输出 FTL指令：FreeMarker指令，和HTML标记类似，名字前加#予以区分，不会输出。","text":"FreeMarker是一款 模板引擎 :即一种基于模板和要改变的数据，并用来生成输出文本（HTML网页、电子邮件、配置文件、源代码等）的通用工具。FreeMarker模板文件主要有4部分组成 文本，直接输出的部分 注释，即&lt;#–…–&gt;格式不会输出 插值（Interpolation）：即${..}或者#{..}格式的部分,将使用数据模型中的部分替代输出 FTL指令：FreeMarker指令，和HTML标记类似，名字前加#予以区分，不会输出。 一些规则FTL指令规则FreeMarker有三种FTL标签，这和HTML的标签是完全类似的 开始标签：&lt;#directivename parameters&gt; 结束标签：&lt;/#directivename&gt; 空标签： &lt;#directivename parameters /&gt; 实际上，使用标签时前面的#符号也可能变成@，如果该指令是一个用户指令而不是系统内建指令时，应将#符号改为@符号 插值规则FreeMarker的插值有如下两种类型 1、通用插值：${expr} 2、数字格式化插值：#{expr}或者#{expr;format}通用插值，有可以分为四种情况 a、插值结果为字符串值：直接输出表达式结果 b、插值结果为数字值：根据默认格式(#setting 指令设置)将表达式结果转换成文本输出。可以使用内建的字符串函数格式单个插值，例如 &lt;#setting number_format = &quot;currency&quot; /&gt; &lt;#assign str = 42 /&gt; ${str} ${str?string} ${str?string.number} ${str?string.currency} ${str?string.percent} ${str?string.computer} 日期处理 ${openingTime?string.short} ${openingTime?string.medium} ${openingTime?string.long} ${openingTime?string.full} ${nextDiscountDay?string.short} ${nextDiscountDay?string.medium} ${nextDiscountDay?string.long} ${nextDiscountDay?string.full} ${lastUpdated?string.short} ${lastUpdated?string.medium} ${lastUpdated?string.long} ${lastUpdated?string.full} ${lastUpdated?string(&quot;yyyy-MM-dd HH:mm:ss zzzz&quot;)} ${lastUpdated?string(&quot;EEE, MMM d, &#39;&#39;yy&quot;)} ${lastUpdated?string(&quot;EEEE, MMMM dd, yyyy, hh:mm:ss a &#39;(&#39;zzz&#39;)&#39;&quot;)} if,elseif,elseif&lt;#if condition&gt; …… &lt;#elseif condition2&gt; …… &lt;#else&gt; …… &lt;/#if&gt; switch,case&lt;#switch value&gt; &lt;#case refValue1&gt; ... &lt;#break&gt; &lt;#case refValue2&gt; ... &lt;#break&gt; ... &lt;#case refValueN&gt; ... &lt;#break&gt; &lt;#default&gt; ... &lt;/#switch&gt; &lt;#t&gt; 去掉左右空白和回车换行 &lt;#lt&gt;去掉左边空白和回车换行 &lt;#rt&gt;去掉右边空白和回车换行 &lt;#nt&gt;取消上面的效果 list&lt;#list sequence as item&gt; ... &lt;#if item = &quot;spring&quot;&gt; &lt;#break&gt; &lt;/#if&gt; ... &lt;/#list&gt; iterm_index:当前值得下标，从0开始item_has_next:判断list是否还有值 include&lt;#include filename [options]&gt; options 包含两个属性encoding=”GBK”parse=”true” 是否作为ftl语法解析，默认是true示例：&lt;#include “/common/copyright.ftl” encoding=”GBK” parse=”true”&gt; import&lt;#import path as hash&gt; 类似于java里的import,它导入文件，然后就可以在当前文件里使用被导入文件里的宏组件 compress&lt;#compress&gt; ... &lt;/#compress&gt; escape, noescape&lt;#escape identifier as expression&gt; ... &lt;#noescape&gt;...&lt;/#noescape&gt; ... &lt;/#escape&gt; 主要使用在相似的字符串变量输出，比如某一个模块的所有字符串输出都必须是html安全的，这个时候就可以使用该表达式示例： &lt;#escape x as x?html&gt; First name: ${firstName} &lt;#noescape&gt;Last name: ${lastName}&lt;/#noescape&gt; Maiden name: ${maidenName} &lt;/#escape&gt; 相同表达式 First name: ${firstName?html} Last name: ${lastName } Maiden name: ${maidenName?html} assign&lt;#assign name=value&gt; &lt;#-- 或则 --&gt; &lt;#assign name1=value1 name2=value2 ... nameN=valueN&gt; &lt;#-- 或则 --&gt; &lt;#assign same as above... in namespacehash&gt; &lt;#-- 或则 --&gt; &lt;#assign name&gt; capture this &lt;/#assign&gt; &lt;#-- 或则 --&gt; &lt;#assign name in namespacehash&gt; capture this &lt;/#assign&gt; 生成变量,并且给变量赋值 global&lt;#global name=value&gt; &lt;#--或则--&gt; &lt;#global name1=value1 name2=value2 ... nameN=valueN&gt; &lt;#--或则--&gt; &lt;#global name&gt; capture this &lt;/#global&gt; 全局赋值语法，利用这个语法给变量赋值，那么这个变量在所有的namespace [A1] 中是可见的, 如果这个变量被当前的assign 语法覆盖 如&lt;#global x=2&gt; &lt;#assign x=1&gt; 在当前页面里x=2 将被隐藏，或者通过${.global.x} 来访问 setting&lt;#setting name=value&gt; 用来设置整个系统的一个环境localenumber_formatboolean_formatdate_format , time_format , datetime_formattime_zoneclassic_compatible macro, nested, return&lt;#macro name param1 param2 ... paramN&gt; ... &lt;#nested loopvar1, loopvar2, ..., loopvarN&gt; ... &lt;#return&gt; ... &lt;/#macro&gt; t, lt, rt&lt;#t&gt; 去掉左右空白和回车换行 &lt;#lt&gt;去掉左边空白和回车换行 &lt;#rt&gt;去掉右边空白和回车换行 &lt;#nt&gt;取消上面的效果","categories":[{"name":"大前端","slug":"大前端","permalink":"https://jiangxingye.github.io/categories/大前端/"}],"tags":[{"name":"java","slug":"java","permalink":"https://jiangxingye.github.io/tags/java/"},{"name":"freemarker","slug":"freemarker","permalink":"https://jiangxingye.github.io/tags/freemarker/"}]}]}